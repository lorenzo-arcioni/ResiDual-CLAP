{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189dca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import from your codebase\n",
    "from CLAPWrapper import CLAPWrapper\n",
    "from datasets.esc50 import ESC50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48fa266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loading ESC50 Dataset\n",
      "================================================================================\n",
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 16849.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: 2000 samples\n",
      "   Classes: 50 categories\n",
      "   Sample classes: ['airplane', 'breathing', 'brushing teeth', 'can opening', 'car horn']\n",
      "\n",
      "üìù Text prompts: 50 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading ESC50 Dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "root_path = \"./data\"\n",
    "dataset = ESC50(root=root_path, download=True)\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"   Classes: {len(dataset.classes)} categories\")\n",
    "print(f\"   Sample classes: {dataset.classes[:5]}\")\n",
    "\n",
    "# Prepare text prompts\n",
    "prompt = 'this is the sound of '\n",
    "text_labels = [prompt + x for x in dataset.classes]\n",
    "print(f\"\\nüìù Text prompts: {len(text_labels)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc7cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Initializing Models\n",
      "================================================================================\n",
      "\n",
      "üîß Loading CLAP Standard...\n",
      "\n",
      "üîß Loading ResiDualCLAP...\n",
      "[2, 2, 6, 2]\n",
      "üîç Detecting layer dimensions...\n",
      "  ‚úì 0: torch.Size([1, 1024, 192])\n",
      "  ‚úì 1: torch.Size([1, 256, 384])\n",
      "  ‚úì 2: torch.Size([1, 64, 768])\n",
      "  ‚úì 3: torch.Size([1, 64, 768])\n",
      "  ‚úì layer_0: 192D ‚Üí 19 PCs\n",
      "  ‚úì layer_1: 384D ‚Üí 38 PCs\n",
      "  ‚úì layer_2: 768D ‚Üí 76 PCs\n",
      "  ‚úì layer_3: 768D ‚Üí 76 PCs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Initialize Models\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Initializing Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Residual config con pc_weights = 1.0 (identit√†)\n",
    "residual_config = {\n",
    "    'n_components_ratio': .1,\n",
    "    'reweight_factor': 2.0,\n",
    "    'target_layers': [0, 1, 2, 3],  # Layers dove applicare reweighting\n",
    "    'analysis_mode': True\n",
    "}\n",
    "\n",
    "print(\"\\nüîß Loading CLAP Standard...\")\n",
    "clap_standard = CLAPWrapper(\n",
    "    version='2023',  # or '2022'\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    "    type='classic'\n",
    ")\n",
    "\n",
    "print(\"\\nüîß Loading ResiDualCLAP...\")\n",
    "clap_residual = CLAPWrapper(\n",
    "    version='2023',\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    "    type='residual',\n",
    "    residual_config=residual_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ed051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Fitting PCA Components\n",
      "================================================================================\n",
      "Collecting samples for PCA fitting (max 200 samples)...\n",
      "\n",
      "üî¨ PRE-FLIGHT CHECK:\n",
      "\n",
      "üîç Collecting data for rank check...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb5f2b8b9db4629acbd3bb6cbe7a752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RANK ANALYSIS PER LAYER\n",
      "======================================================================\n",
      "\n",
      "LAYER_0: 51,200 samples √ó 192 features\n",
      "  Rank numerico: 192\n",
      "  Componenti richieste: 19\n",
      "  ‚úì OK: rank sufficiente\n",
      "  Top 10 singular values:\n",
      "     1: 3.07e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2: 2.29e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3: 1.82e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4: 1.42e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5: 1.30e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6: 1.23e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7: 1.12e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8: 1.11e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9: 1.08e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10: 9.82e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Varianza con 19 comp: 77.14%\n",
      "\n",
      "LAYER_1: 12,800 samples √ó 384 features\n",
      "  Rank numerico: 384\n",
      "  Componenti richieste: 38\n",
      "  ‚úì OK: rank sufficiente\n",
      "  Top 10 singular values:\n",
      "     1: 3.56e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2: 2.68e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3: 2.44e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4: 1.95e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5: 1.73e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6: 1.54e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7: 1.36e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8: 1.28e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9: 1.23e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10: 1.15e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Varianza con 38 comp: 85.25%\n",
      "\n",
      "LAYER_2: 3,200 samples √ó 768 features\n",
      "  Rank numerico: 768\n",
      "  Componenti richieste: 76\n",
      "  ‚úì OK: rank sufficiente\n",
      "  Top 10 singular values:\n",
      "     1: 2.34e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2: 1.19e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3: 9.72e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4: 8.98e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5: 7.71e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6: 7.06e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7: 6.91e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8: 6.16e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9: 5.74e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10: 5.64e+01 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Varianza con 76 comp: 88.06%\n",
      "\n",
      "LAYER_3: 3,200 samples √ó 768 features\n",
      "  Rank numerico: 768\n",
      "  Componenti richieste: 76\n",
      "  ‚úì OK: rank sufficiente\n",
      "  Top 10 singular values:\n",
      "     1: 6.52e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2: 3.76e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3: 3.11e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4: 3.01e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5: 2.62e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6: 2.43e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7: 2.41e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8: 2.20e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9: 2.11e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10: 2.04e+02 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Varianza con 76 comp: 94.80%\n",
      "Fitting PCA on 50 samples...\n",
      "\n",
      "================================================================================\n",
      "üîç PHASE 1: Collecting Hidden States from HTSAT Layers\n",
      "================================================================================\n",
      "Target layers: ['layer_0', 'layer_1', 'layer_2', 'layer_3']\n",
      "Max samples to collect: 50\n",
      "Batches in dataloader: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting samples: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:11<00:00,  2.76s/batch, samples=50/50, layers=4/4, failed=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Collection completed in 11.03s\n",
      "  ‚Ä¢ Total samples processed: 50\n",
      "  ‚Ä¢ Successful batches: 4\n",
      "  ‚Ä¢ Failed batches: 0\n",
      "  ‚Ä¢ Samples per second: 4.5\n",
      "\n",
      "üì¶ Collected data per layer:\n",
      "  ‚Ä¢ layer_0: 4 batches, 51,200 tokens\n",
      "  ‚Ä¢ layer_1: 4 batches, 12,800 tokens\n",
      "  ‚Ä¢ layer_2: 4 batches, 3,200 tokens\n",
      "  ‚Ä¢ layer_3: 4 batches, 3,200 tokens\n",
      "\n",
      "================================================================================\n",
      "üìä PHASE 2: Fitting PCA Components\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PCA:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  8.53layer/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Processing layer_0:\n",
      "  ‚Ä¢ Concatenating 4 batches...\n",
      "  ‚Ä¢ Combined shape: torch.Size([51200, 192]) (51,200 samples)\n",
      "  ‚Ä¢ Memory usage: 37.5 MB\n",
      "  ‚Ä¢ Running PCA decomposition...\n",
      "  ‚Ä¢ PCA completed in 0.11s\n",
      "\n",
      "  üìà Variance Analysis:\n",
      "     ‚Ä¢ Total components: 19\n",
      "     ‚Ä¢ Top 5 variances: ['0.2265', '0.0879', '0.0663', '0.0481', '0.0433']\n",
      "     ‚Ä¢ Cumulative variance:\n",
      "        - 50% variance: 6/19 components (31.6%)\n",
      "        - 70% variance: 14/19 components (73.7%)\n",
      "        - 80% variance: 20/19 components (105.3%)\n",
      "        - 90% variance: 20/19 components (105.3%)\n",
      "        - 95% variance: 20/19 components (105.3%)\n",
      "\n",
      "     Top 10 components bar:\n",
      "        PC 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.2265\n",
      "        PC 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0879\n",
      "        PC 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0663\n",
      "        PC 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0481\n",
      "        PC 5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0433\n",
      "        PC 6: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0381\n",
      "        PC 7: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0330\n",
      "        PC 8: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0316\n",
      "        PC 9: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0291\n",
      "        PC10: ‚ñà‚ñà‚ñà‚ñà 0.0250\n",
      "\n",
      "üîß Processing layer_1:\n",
      "  ‚Ä¢ Concatenating 4 batches...\n",
      "  ‚Ä¢ Combined shape: torch.Size([12800, 384]) (12,800 samples)\n",
      "  ‚Ä¢ Memory usage: 18.8 MB\n",
      "  ‚Ä¢ Running PCA decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PCA:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  7.69layer/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ PCA completed in 0.10s\n",
      "\n",
      "  üìà Variance Analysis:\n",
      "     ‚Ä¢ Total components: 38\n",
      "     ‚Ä¢ Top 5 variances: ['0.1763', '0.1089', '0.0752', '0.0540', '0.0490']\n",
      "     ‚Ä¢ Cumulative variance:\n",
      "        - 50% variance: 6/38 components (15.8%)\n",
      "        - 70% variance: 16/38 components (42.1%)\n",
      "        - 80% variance: 28/38 components (73.7%)\n",
      "        - 90% variance: 39/38 components (102.6%)\n",
      "        - 95% variance: 39/38 components (102.6%)\n",
      "\n",
      "     Top 10 components bar:\n",
      "        PC 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.1763\n",
      "        PC 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.1089\n",
      "        PC 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0752\n",
      "        PC 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0540\n",
      "        PC 5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0490\n",
      "        PC 6: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0406\n",
      "        PC 7: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0308\n",
      "        PC 8: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0276\n",
      "        PC 9: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0241\n",
      "        PC10: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0231\n",
      "\n",
      "üîß Processing layer_2:\n",
      "  ‚Ä¢ Concatenating 4 batches...\n",
      "  ‚Ä¢ Combined shape: torch.Size([3200, 768]) (3,200 samples)\n",
      "  ‚Ä¢ Memory usage: 9.4 MB\n",
      "  ‚Ä¢ Running PCA decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PCA:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  1.16layer/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ PCA completed in 1.70s\n",
      "\n",
      "  üìà Variance Analysis:\n",
      "     ‚Ä¢ Total components: 76\n",
      "     ‚Ä¢ Top 5 variances: ['0.2302', '0.0595', '0.0550', '0.0432', '0.0343']\n",
      "     ‚Ä¢ Cumulative variance:\n",
      "        - 50% variance: 8/76 components (10.5%)\n",
      "        - 70% variance: 26/76 components (34.2%)\n",
      "        - 80% variance: 46/76 components (60.5%)\n",
      "        - 90% variance: 77/76 components (101.3%)\n",
      "        - 95% variance: 77/76 components (101.3%)\n",
      "\n",
      "     Top 10 components bar:\n",
      "        PC 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.2302\n",
      "        PC 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0595\n",
      "        PC 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0550\n",
      "        PC 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0432\n",
      "        PC 5: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0343\n",
      "        PC 6: ‚ñà‚ñà‚ñà‚ñà‚ñà 0.0305\n",
      "        PC 7: ‚ñà‚ñà‚ñà‚ñà 0.0240\n",
      "        PC 8: ‚ñà‚ñà‚ñà‚ñà 0.0234\n",
      "        PC 9: ‚ñà‚ñà‚ñà 0.0200\n",
      "        PC10: ‚ñà‚ñà 0.0168\n",
      "\n",
      "üîß Processing layer_3:\n",
      "  ‚Ä¢ Concatenating 4 batches...\n",
      "  ‚Ä¢ Combined shape: torch.Size([3200, 768]) (3,200 samples)\n",
      "  ‚Ä¢ Memory usage: 9.4 MB\n",
      "  ‚Ä¢ Running PCA decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting PCA: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.23layer/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ PCA completed in 1.16s\n",
      "\n",
      "  üìà Variance Analysis:\n",
      "     ‚Ä¢ Total components: 76\n",
      "     ‚Ä¢ Top 5 variances: ['0.1211', '0.0795', '0.0751', '0.0657', '0.0530']\n",
      "     ‚Ä¢ Cumulative variance:\n",
      "        - 50% variance: 8/76 components (10.5%)\n",
      "        - 70% variance: 16/76 components (21.1%)\n",
      "        - 80% variance: 24/76 components (31.6%)\n",
      "        - 90% variance: 44/76 components (57.9%)\n",
      "        - 95% variance: 77/76 components (101.3%)\n",
      "\n",
      "     Top 10 components bar:\n",
      "        PC 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.1211\n",
      "        PC 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0795\n",
      "        PC 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0751\n",
      "        PC 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0657\n",
      "        PC 5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0530\n",
      "        PC 6: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0476\n",
      "        PC 7: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0397\n",
      "        PC 8: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0366\n",
      "        PC 9: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0344\n",
      "        PC10: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 0.0331\n",
      "\n",
      "================================================================================\n",
      "‚úì PCA Fitting Completed Successfully\n",
      "================================================================================\n",
      "Total time: 14.29s\n",
      "\n",
      "Spectral layers ready for reweighting:\n",
      "  ‚Ä¢ layer_0: ‚úì FITTED\n",
      "  ‚Ä¢ layer_1: ‚úì FITTED\n",
      "  ‚Ä¢ layer_2: ‚úì FITTED\n",
      "  ‚Ä¢ layer_3: ‚úì FITTED\n",
      "\n",
      "üìä PCA Variance Ratios:\n",
      "   layer_0: Top 5 components = [0.22651738 0.08794987 0.06626218 0.04814878 0.04326858]\n",
      "   layer_1: Top 5 components = [0.17630813 0.10885716 0.07518831 0.05396587 0.04902839]\n",
      "   layer_2: Top 5 components = [0.23018974 0.05952651 0.05498318 0.04315665 0.03426682]\n",
      "   layer_3: Top 5 components = [0.12111124 0.07946752 0.07508159 0.06570908 0.05304398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Fitting PCA Components\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare audio samples for PCA fitting\n",
    "print(\"Collecting samples for PCA fitting (max 200 samples)...\")\n",
    "\n",
    "# Create a simple dataloader wrapper per PCA fitting\n",
    "class SimpleAudioDataset:\n",
    "    def __init__(self, wrapper, esc50_dataset, max_samples=1000):\n",
    "        self.wrapper = wrapper\n",
    "        self.audio_paths = []\n",
    "        for i in range(min(max_samples, len(esc50_dataset))):\n",
    "            audio_path, _, _ = esc50_dataset[i]\n",
    "            self.audio_paths.append(audio_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_tensor = self.wrapper.load_audio_into_tensor(\n",
    "            self.audio_paths[idx],\n",
    "            self.wrapper.args.duration,\n",
    "            resample=True\n",
    "        )\n",
    "        # ‚úÖ Assicurati sia 1D\n",
    "        if audio_tensor.dim() > 1:\n",
    "            audio_tensor = audio_tensor.squeeze()\n",
    "        \n",
    "        return audio_tensor\n",
    "\n",
    "# Create dataset and loader\n",
    "pca_dataset = SimpleAudioDataset(clap_residual, dataset, max_samples=50)\n",
    "pca_loader = DataLoader(\n",
    "    pca_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Start with 0 for debugging\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# Fit PCA\n",
    "print(f\"Fitting PCA on {len(pca_dataset)} samples...\")\n",
    "variance_ratios = clap_residual.clap.audio_encoder.base.htsat.fit_spectral_layers(\n",
    "    pca_loader,\n",
    "    max_samples=50\n",
    ")\n",
    "\n",
    "print(\"\\nüìä PCA Variance Ratios:\")\n",
    "for layer_name, ratios in variance_ratios.items():\n",
    "    print(f\"   {layer_name}: Top 5 components = {ratios[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbbbe5fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collected_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dopo aver fatto la collection\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, outputs \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcollected_outputs\u001b[49m.items():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outputs:\n\u001b[32m      4\u001b[39m         X = torch.cat(outputs, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'collected_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Dopo aver fatto la collection\n",
    "for layer_name, outputs in collected_outputs.items():\n",
    "    if outputs:\n",
    "        X = torch.cat(outputs, dim=0)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Checking {layer_name}\")\n",
    "        quick_rank_check(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Text embeddings shape: torch.Size([50, 1024])\n",
      "\n",
      "üìä Testing on 100 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89dcba842e54e83be19d1a5af20655f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baseline:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Baseline Accuracy: 0.920 (92.0%)\n"
     ]
    }
   ],
   "source": [
    "# Get text embeddings ONCE for all classes\n",
    "text_embeddings = clap_standard.get_text_embeddings(text_labels)\n",
    "print(f\"   Text embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "# Test on subset first (use full dataset later)\n",
    "test_size = 100  # Start with 200 samples for speed\n",
    "print(f\"\\nüìä Testing on {test_size} samples...\")\n",
    "\n",
    "y_preds_baseline, y_labels = [], []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"Baseline\"):\n",
    "    # Get audio file path and label\n",
    "    audio_path, target, one_hot_target = dataset[-(i+1)]\n",
    "    \n",
    "    # Get audio embedding\n",
    "    audio_embedding = clap_standard.get_audio_embeddings([audio_path], resample=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = clap_standard.compute_similarity(audio_embedding, text_embeddings)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_baseline.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "y_labels_array = np.concatenate(y_labels, axis=0)\n",
    "y_preds_baseline_array = np.concatenate(y_preds_baseline, axis=0)\n",
    "\n",
    "baseline_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_baseline_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline Accuracy: {baseline_acc:.3f} ({baseline_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e60c8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Text embeddings shape: torch.Size([50, 1024])\n",
      "\n",
      "üìä Testing on 100 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677ec485bce84a958ae0f585bf7381d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "residual:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Residual Accuracy: 0.920 (92.0%)\n"
     ]
    }
   ],
   "source": [
    "# Get text embeddings ONCE for all classes\n",
    "text_embeddings = clap_residual.get_text_embeddings(text_labels)\n",
    "print(f\"   Text embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "# Test on subset first (use full dataset later)\n",
    "test_size = 100  # Start with 200 samples for speed\n",
    "print(f\"\\nüìä Testing on {test_size} samples...\")\n",
    "\n",
    "y_preds_residual, y_labels = [], []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"residual\"):\n",
    "    # Get audio file path and label\n",
    "    audio_path, target, one_hot_target = dataset[-(i+1)]\n",
    "    \n",
    "    # Get audio embedding\n",
    "    audio_embedding = clap_residual.get_audio_embeddings([audio_path], resample=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = clap_residual.compute_similarity(audio_embedding, text_embeddings)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_residual.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "y_labels_array = np.concatenate(y_labels, axis=0)\n",
    "y_preds_residual_array = np.concatenate(y_preds_residual, axis=0)\n",
    "\n",
    "baseline_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_baseline_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Residual Accuracy: {baseline_acc:.3f} ({baseline_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726a89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path, target, one_hot_target = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d03d337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8840,  0.3185, -0.6708,  ...,  2.1432,  1.0298, -0.1217]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clap_residual.get_audio_embeddings([audio_path], resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2aa61e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7623,  0.2343, -0.5101,  ...,  1.8940,  0.9414, -0.0119]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clap_standard.get_audio_embeddings([audio_path], resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee6592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
