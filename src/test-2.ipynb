{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189dca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import from your codebase\n",
    "from CLAPWrapper import CLAPWrapper\n",
    "from datasets.esc50 import ESC50\n",
    "from datasets.tinysol import TinySOL\n",
    "\n",
    "DATASET = TinySOL\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48fa266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loading TinySOL Dataset\n",
      "================================================================================\n",
      "Dataset giÃ  presente in ../data/TinySOL\n",
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2913it [00:00, 17117.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded: 2913 samples\n",
      "   Classes: 14 categories\n",
      "   Sample classes: ['Accordion', 'Bass Tuba', 'Bassoon', 'Clarinet Bb', 'Contrabass']\n",
      "\n",
      "ðŸ“ Text prompts: 14 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Loading {DATASET.__name__} Dataset\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "root_path = \"../data\"\n",
    "dataset = DATASET(root=root_path, download=False)\n",
    "print(f\"âœ… Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"   Classes: {len(dataset.classes)} categories\")\n",
    "print(f\"   Sample classes: {dataset.classes[:5]}\")\n",
    "\n",
    "# Prepare text prompts\n",
    "prompt = 'this is the sound of '\n",
    "text_labels = [prompt + x for x in dataset.classes]\n",
    "print(f\"\\nðŸ“ Text prompts: {len(text_labels)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc7cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Initializing Models\n",
      "================================================================================\n",
      "\n",
      "ðŸ”§ Loading CLAP Standard...OK\n",
      "\n",
      "ðŸ”§ Loading ResiDualCLAP...\n",
      "\n",
      "================================================================================\n",
      "ðŸ”§ Setup ResiDual HTSAT\n",
      "================================================================================\n",
      "ModalitÃ : ATTENTION\n",
      "Target layers: [0, 1, 2, 3]\n",
      "PCA components ratio: 1.0\n",
      "Reweight factor: 0.0\n",
      "\n",
      "âœ“ layer_0:\n",
      "  ModalitÃ : PER-HEAD reweighting\n",
      "  Num blocks: 2\n",
      "  Heads per block: 4\n",
      "  Total heads: 8\n",
      "  Head dim: 24D â†’ 24 PCs\n",
      "\n",
      "âœ“ layer_1:\n",
      "  ModalitÃ : PER-HEAD reweighting\n",
      "  Num blocks: 2\n",
      "  Heads per block: 8\n",
      "  Total heads: 16\n",
      "  Head dim: 24D â†’ 24 PCs\n",
      "\n",
      "âœ“ layer_2:\n",
      "  ModalitÃ : PER-HEAD reweighting\n",
      "  Num blocks: 6\n",
      "  Heads per block: 16\n",
      "  Total heads: 96\n",
      "  Head dim: 24D â†’ 24 PCs\n",
      "\n",
      "âœ“ layer_3:\n",
      "  ModalitÃ : PER-HEAD reweighting\n",
      "  Num blocks: 2\n",
      "  Heads per block: 32\n",
      "  Total heads: 64\n",
      "  Head dim: 24D â†’ 24 PCs\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResiDualHTSAT(\n",
       "  (spectrogram_extractor): Spectrogram(\n",
       "    (stft): STFT(\n",
       "      (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "      (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (logmel_extractor): LogmelFilterBank()\n",
       "  (spec_augmenter): SpecAugmentation(\n",
       "    (time_dropper): DropStripes()\n",
       "    (freq_dropper): DropStripes()\n",
       "  )\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(1, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): BasicLayer(\n",
       "      dim=96, input_resolution=(64, 64), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=96, window_size=(8, 8), num_heads=4\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-3): 4 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(64, 64), num_heads=4, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=96, window_size=(8, 8), num_heads=4\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-3): 4 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(64, 64), dim=96\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=192, input_resolution=(32, 32), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=192, window_size=(8, 8), num_heads=8\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-7): 8 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(32, 32), num_heads=8, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=192, window_size=(8, 8), num_heads=8\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-7): 8 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(32, 32), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=384, input_resolution=(16, 16), depth=6\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(16, 16), num_heads=16, window_size=8, shift_size=4, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=384, window_size=(8, 8), num_heads=16\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-15): 16 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(16, 16), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=768, input_resolution=(8, 8), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0-1): 2 x SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttentionReweighting(\n",
       "            dim=768, window_size=(8, 8), num_heads=32\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (spectral_layers): ModuleList(\n",
       "              (0-31): 32 x SpectralReweightingLayer()\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (tscam_conv): Conv2d(768, 527, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "  (head): Linear(in_features=527, out_features=527, bias=True)\n",
       "  (spectral_layers): ModuleDict(\n",
       "    (layer_0): ModuleList(\n",
       "      (0-1): 2 x ModuleList(\n",
       "        (0-3): 4 x SpectralReweightingLayer()\n",
       "      )\n",
       "    )\n",
       "    (layer_1): ModuleList(\n",
       "      (0-1): 2 x ModuleList(\n",
       "        (0-7): 8 x SpectralReweightingLayer()\n",
       "      )\n",
       "    )\n",
       "    (layer_2): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0-15): 16 x SpectralReweightingLayer()\n",
       "      )\n",
       "    )\n",
       "    (layer_3): ModuleList(\n",
       "      (0-1): 2 x ModuleList(\n",
       "        (0-31): 32 x SpectralReweightingLayer()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Initialize Models\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Initializing Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Residual config con pc_weights = 1.0 (identitÃ )\n",
    "residual_config = {\n",
    "    'mode': 'attention',\n",
    "    'n_components_ratio': 1.0,\n",
    "    'reweight_factor': 0.0,\n",
    "    'target_layers': [0, 1, 2, 3],  # Layers dove applicare reweighting\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ”§ Loading CLAP Standard...\", end='')\n",
    "clap_standard = CLAPWrapper(\n",
    "    version='2023',  # or '2022'\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    "    type='classic'\n",
    ")\n",
    "clap_standard.clap.eval()\n",
    "clap_standard.clap.audio_encoder.base.htsat.eval()\n",
    "print(\"OK\")\n",
    "\n",
    "print(\"\\nðŸ”§ Loading ResiDualCLAP...\")\n",
    "clap_residual = CLAPWrapper(\n",
    "    version='2023',\n",
    "    use_cuda=torch.cuda.is_available(),\n",
    "    type='residual',\n",
    "    residual_config=residual_config\n",
    ")\n",
    "clap_residual.clap.eval()\n",
    "clap_residual.clap.audio_encoder.base.htsat.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07ed051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting samples for PCA fitting (200 samples)...OK\n"
     ]
    }
   ],
   "source": [
    "PCA_SAMPLES = 200\n",
    "\n",
    "# Prepare audio samples for PCA fitting\n",
    "print(f\"Collecting samples for PCA fitting ({PCA_SAMPLES} samples)...\", end='')\n",
    "\n",
    "# Create a simple dataloader wrapper per PCA fitting\n",
    "class SimpleAudioDataset:\n",
    "    def __init__(self, wrapper, esc50_dataset, max_samples=1000):\n",
    "        self.wrapper = wrapper\n",
    "        self.audio_paths = []\n",
    "        for i in range(min(max_samples, len(esc50_dataset))):\n",
    "            audio_path, _, _ = esc50_dataset[i]\n",
    "            self.audio_paths.append(audio_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_tensor = self.wrapper.load_audio_into_tensor(\n",
    "            self.audio_paths[idx],\n",
    "            self.wrapper.args.duration,\n",
    "            resample=True\n",
    "        )\n",
    "        # âœ… Assicurati sia 1D\n",
    "        if audio_tensor.dim() > 1:\n",
    "            audio_tensor = audio_tensor.squeeze()\n",
    "        \n",
    "        return audio_tensor\n",
    "\n",
    "# Create dataset and loader\n",
    "pca_dataset = SimpleAudioDataset(clap_residual, dataset, max_samples=PCA_SAMPLES)\n",
    "pca_loader = DataLoader(\n",
    "    pca_dataset, \n",
    "    batch_size=25, \n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Start with 0 for debugging\n",
    "    pin_memory=False\n",
    ")\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e2ba8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([308700])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea6b11aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 308700])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pca_loader)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ef5dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5a8ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Fitting PCA Components\n",
      "================================================================================\n",
      "Fitting PCA on 200 samples...\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š Fitting Spectral Layers\n",
      "================================================================================\n",
      "ModalitÃ : ATTENTION\n",
      "Target layers: [0, 1, 2, 3]\n",
      "Max samples: 200\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¦ Fase 1: Raccolta hidden states...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Raccolta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:35<00:00,  4.49s/it, samples=200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Raccolti 200 samples totali\n",
      "\n",
      "================================================================================\n",
      "ðŸ”¬ Fase 2: Calcolo PCA e inizializzazione pesi...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "layer_0:\n",
      "\n",
      "  Block 0:\n",
      "    âœ“ head_0: shape=torch.Size([819200, 24]), var=['0.879', '0.061', '0.051'], cum=0.991\n",
      "    âœ“ head_1: shape=torch.Size([819200, 24]), var=['0.782', '0.090', '0.076'], cum=0.948\n",
      "    âœ“ head_2: shape=torch.Size([819200, 24]), var=['0.883', '0.072', '0.035'], cum=0.989\n",
      "    âœ“ head_3: shape=torch.Size([819200, 24]), var=['0.836', '0.070', '0.037'], cum=0.943\n",
      "\n",
      "  Block 1:\n",
      "    âœ“ head_0: shape=torch.Size([819200, 24]), var=['0.345', '0.237', '0.149'], cum=0.730\n",
      "    âœ“ head_1: shape=torch.Size([819200, 24]), var=['0.750', '0.115', '0.042'], cum=0.907\n",
      "    âœ“ head_2: shape=torch.Size([819200, 24]), var=['0.620', '0.139', '0.116'], cum=0.875\n",
      "    âœ“ head_3: shape=torch.Size([819200, 24]), var=['0.538', '0.225', '0.105'], cum=0.868\n",
      "\n",
      "layer_1:\n",
      "\n",
      "  Block 0:\n",
      "    âœ“ head_0: shape=torch.Size([204800, 24]), var=['0.434', '0.158', '0.113'], cum=0.706\n",
      "    âœ“ head_1: shape=torch.Size([204800, 24]), var=['0.241', '0.158', '0.117'], cum=0.515\n",
      "    âœ“ head_2: shape=torch.Size([204800, 24]), var=['0.243', '0.146', '0.121'], cum=0.511\n",
      "    âœ“ head_3: shape=torch.Size([204800, 24]), var=['0.620', '0.144', '0.089'], cum=0.854\n",
      "    âœ“ head_4: shape=torch.Size([204800, 24]), var=['0.576', '0.113', '0.062'], cum=0.751\n",
      "    âœ“ head_5: shape=torch.Size([204800, 24]), var=['0.254', '0.140', '0.112'], cum=0.506\n",
      "    âœ“ head_6: shape=torch.Size([204800, 24]), var=['0.495', '0.246', '0.119'], cum=0.860\n",
      "    âœ“ head_7: shape=torch.Size([204800, 24]), var=['0.279', '0.186', '0.091'], cum=0.557\n",
      "\n",
      "  Block 1:\n",
      "    âœ“ head_0: shape=torch.Size([204800, 24]), var=['0.374', '0.278', '0.082'], cum=0.735\n",
      "    âœ“ head_1: shape=torch.Size([204800, 24]), var=['0.275', '0.225', '0.108'], cum=0.608\n",
      "    âœ“ head_2: shape=torch.Size([204800, 24]), var=['0.268', '0.154', '0.141'], cum=0.564\n",
      "    âœ“ head_3: shape=torch.Size([204800, 24]), var=['0.333', '0.198', '0.131'], cum=0.662\n",
      "    âœ“ head_4: shape=torch.Size([204800, 24]), var=['0.461', '0.152', '0.076'], cum=0.690\n",
      "    âœ“ head_5: shape=torch.Size([204800, 24]), var=['0.251', '0.165', '0.128'], cum=0.544\n",
      "    âœ“ head_6: shape=torch.Size([204800, 24]), var=['0.391', '0.188', '0.121'], cum=0.700\n",
      "    âœ“ head_7: shape=torch.Size([204800, 24]), var=['0.275', '0.250', '0.141'], cum=0.666\n",
      "\n",
      "layer_2:\n",
      "\n",
      "  Block 0:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.338', '0.208', '0.110'], cum=0.655\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.368', '0.145', '0.124'], cum=0.637\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.383', '0.156', '0.071'], cum=0.611\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.401', '0.160', '0.143'], cum=0.704\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.292', '0.230', '0.170'], cum=0.692\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.391', '0.229', '0.156'], cum=0.775\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.379', '0.243', '0.128'], cum=0.750\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.444', '0.267', '0.078'], cum=0.790\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.295', '0.151', '0.130'], cum=0.576\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.306', '0.147', '0.118'], cum=0.570\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.338', '0.190', '0.152'], cum=0.680\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.406', '0.178', '0.137'], cum=0.720\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.374', '0.178', '0.143'], cum=0.695\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.282', '0.238', '0.130'], cum=0.650\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.358', '0.142', '0.091'], cum=0.591\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.429', '0.140', '0.097'], cum=0.666\n",
      "\n",
      "  Block 1:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.327', '0.193', '0.116'], cum=0.636\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.328', '0.208', '0.083'], cum=0.619\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.178', '0.150', '0.106'], cum=0.434\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.258', '0.175', '0.133'], cum=0.566\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.357', '0.163', '0.123'], cum=0.643\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.316', '0.156', '0.141'], cum=0.613\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.269', '0.220', '0.111'], cum=0.599\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.372', '0.143', '0.085'], cum=0.600\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.240', '0.131', '0.100'], cum=0.470\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.462', '0.147', '0.090'], cum=0.699\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.278', '0.154', '0.123'], cum=0.555\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.258', '0.206', '0.148'], cum=0.612\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.275', '0.214', '0.143'], cum=0.631\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.322', '0.191', '0.101'], cum=0.614\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.286', '0.185', '0.141'], cum=0.612\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.270', '0.255', '0.154'], cum=0.679\n",
      "\n",
      "  Block 2:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.298', '0.207', '0.121'], cum=0.626\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.297', '0.182', '0.110'], cum=0.589\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.326', '0.111', '0.096'], cum=0.533\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.334', '0.175', '0.089'], cum=0.599\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.247', '0.133', '0.105'], cum=0.485\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.307', '0.242', '0.117'], cum=0.666\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.338', '0.307', '0.087'], cum=0.732\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.324', '0.126', '0.120'], cum=0.570\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.301', '0.136', '0.106'], cum=0.543\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.236', '0.166', '0.115'], cum=0.517\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.332', '0.187', '0.103'], cum=0.622\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.294', '0.206', '0.138'], cum=0.637\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.360', '0.135', '0.125'], cum=0.619\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.333', '0.125', '0.112'], cum=0.570\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.320', '0.155', '0.115'], cum=0.590\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.317', '0.140', '0.095'], cum=0.552\n",
      "\n",
      "  Block 3:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.360', '0.228', '0.104'], cum=0.692\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.253', '0.149', '0.111'], cum=0.512\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.271', '0.174', '0.129'], cum=0.573\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.258', '0.153', '0.115'], cum=0.527\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.212', '0.122', '0.101'], cum=0.436\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.289', '0.110', '0.101'], cum=0.501\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.225', '0.191', '0.152'], cum=0.568\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.204', '0.183', '0.158'], cum=0.544\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.241', '0.144', '0.122'], cum=0.508\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.332', '0.111', '0.096'], cum=0.539\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.197', '0.151', '0.114'], cum=0.462\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.224', '0.181', '0.118'], cum=0.523\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.350', '0.118', '0.083'], cum=0.552\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.190', '0.136', '0.112'], cum=0.437\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.278', '0.153', '0.103'], cum=0.534\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.171', '0.123', '0.102'], cum=0.395\n",
      "\n",
      "  Block 4:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.286', '0.169', '0.120'], cum=0.575\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.214', '0.164', '0.119'], cum=0.497\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.339', '0.140', '0.088'], cum=0.568\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.249', '0.110', '0.104'], cum=0.463\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.198', '0.144', '0.097'], cum=0.438\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.210', '0.124', '0.098'], cum=0.432\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.245', '0.176', '0.112'], cum=0.534\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.209', '0.181', '0.077'], cum=0.468\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.234', '0.149', '0.125'], cum=0.508\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.229', '0.152', '0.112'], cum=0.493\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.368', '0.114', '0.094'], cum=0.575\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.305', '0.161', '0.100'], cum=0.566\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.274', '0.114', '0.105'], cum=0.493\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.330', '0.148', '0.086'], cum=0.564\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.210', '0.152', '0.119'], cum=0.481\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.233', '0.162', '0.092'], cum=0.487\n",
      "\n",
      "  Block 5:\n",
      "    âœ“ head_0: shape=torch.Size([51200, 24]), var=['0.175', '0.136', '0.095'], cum=0.406\n",
      "    âœ“ head_1: shape=torch.Size([51200, 24]), var=['0.199', '0.137', '0.111'], cum=0.447\n",
      "    âœ“ head_2: shape=torch.Size([51200, 24]), var=['0.158', '0.145', '0.112'], cum=0.414\n",
      "    âœ“ head_3: shape=torch.Size([51200, 24]), var=['0.274', '0.161', '0.136'], cum=0.571\n",
      "    âœ“ head_4: shape=torch.Size([51200, 24]), var=['0.265', '0.157', '0.112'], cum=0.535\n",
      "    âœ“ head_5: shape=torch.Size([51200, 24]), var=['0.261', '0.137', '0.103'], cum=0.502\n",
      "    âœ“ head_6: shape=torch.Size([51200, 24]), var=['0.296', '0.139', '0.097'], cum=0.532\n",
      "    âœ“ head_7: shape=torch.Size([51200, 24]), var=['0.193', '0.136', '0.114'], cum=0.442\n",
      "    âœ“ head_8: shape=torch.Size([51200, 24]), var=['0.336', '0.094', '0.091'], cum=0.522\n",
      "    âœ“ head_9: shape=torch.Size([51200, 24]), var=['0.227', '0.192', '0.105'], cum=0.524\n",
      "    âœ“ head_10: shape=torch.Size([51200, 24]), var=['0.306', '0.138', '0.105'], cum=0.549\n",
      "    âœ“ head_11: shape=torch.Size([51200, 24]), var=['0.235', '0.125', '0.099'], cum=0.459\n",
      "    âœ“ head_12: shape=torch.Size([51200, 24]), var=['0.224', '0.152', '0.106'], cum=0.483\n",
      "    âœ“ head_13: shape=torch.Size([51200, 24]), var=['0.330', '0.132', '0.097'], cum=0.558\n",
      "    âœ“ head_14: shape=torch.Size([51200, 24]), var=['0.196', '0.114', '0.097'], cum=0.407\n",
      "    âœ“ head_15: shape=torch.Size([51200, 24]), var=['0.188', '0.135', '0.099'], cum=0.423\n",
      "\n",
      "layer_3:\n",
      "\n",
      "  Block 0:\n",
      "    âœ“ head_0: shape=torch.Size([12800, 24]), var=['0.319', '0.178', '0.108'], cum=0.606\n",
      "    âœ“ head_1: shape=torch.Size([12800, 24]), var=['0.304', '0.187', '0.091'], cum=0.583\n",
      "    âœ“ head_2: shape=torch.Size([12800, 24]), var=['0.364', '0.127', '0.125'], cum=0.616\n",
      "    âœ“ head_3: shape=torch.Size([12800, 24]), var=['0.248', '0.188', '0.114'], cum=0.550\n",
      "    âœ“ head_4: shape=torch.Size([12800, 24]), var=['0.331', '0.231', '0.107'], cum=0.669\n",
      "    âœ“ head_5: shape=torch.Size([12800, 24]), var=['0.613', '0.134', '0.066'], cum=0.812\n",
      "    âœ“ head_6: shape=torch.Size([12800, 24]), var=['0.207', '0.157', '0.136'], cum=0.499\n",
      "    âœ“ head_7: shape=torch.Size([12800, 24]), var=['0.381', '0.146', '0.079'], cum=0.606\n",
      "    âœ“ head_8: shape=torch.Size([12800, 24]), var=['0.320', '0.180', '0.109'], cum=0.610\n",
      "    âœ“ head_9: shape=torch.Size([12800, 24]), var=['0.518', '0.107', '0.076'], cum=0.701\n",
      "    âœ“ head_10: shape=torch.Size([12800, 24]), var=['0.424', '0.132', '0.119'], cum=0.675\n",
      "    âœ“ head_11: shape=torch.Size([12800, 24]), var=['0.284', '0.152', '0.133'], cum=0.568\n",
      "    âœ“ head_12: shape=torch.Size([12800, 24]), var=['0.469', '0.129', '0.080'], cum=0.679\n",
      "    âœ“ head_13: shape=torch.Size([12800, 24]), var=['0.264', '0.217', '0.098'], cum=0.578\n",
      "    âœ“ head_14: shape=torch.Size([12800, 24]), var=['0.317', '0.255', '0.100'], cum=0.672\n",
      "    âœ“ head_15: shape=torch.Size([12800, 24]), var=['0.252', '0.161', '0.102'], cum=0.515\n",
      "    âœ“ head_16: shape=torch.Size([12800, 24]), var=['0.485', '0.157', '0.104'], cum=0.745\n",
      "    âœ“ head_17: shape=torch.Size([12800, 24]), var=['0.232', '0.154', '0.114'], cum=0.500\n",
      "    âœ“ head_18: shape=torch.Size([12800, 24]), var=['0.341', '0.193', '0.128'], cum=0.662\n",
      "    âœ“ head_19: shape=torch.Size([12800, 24]), var=['0.333', '0.135', '0.118'], cum=0.586\n",
      "    âœ“ head_20: shape=torch.Size([12800, 24]), var=['0.323', '0.166', '0.161'], cum=0.650\n",
      "    âœ“ head_21: shape=torch.Size([12800, 24]), var=['0.253', '0.153', '0.119'], cum=0.526\n",
      "    âœ“ head_22: shape=torch.Size([12800, 24]), var=['0.373', '0.165', '0.086'], cum=0.624\n",
      "    âœ“ head_23: shape=torch.Size([12800, 24]), var=['0.274', '0.158', '0.128'], cum=0.560\n",
      "    âœ“ head_24: shape=torch.Size([12800, 24]), var=['0.318', '0.186', '0.074'], cum=0.578\n",
      "    âœ“ head_25: shape=torch.Size([12800, 24]), var=['0.306', '0.186', '0.109'], cum=0.600\n",
      "    âœ“ head_26: shape=torch.Size([12800, 24]), var=['0.265', '0.165', '0.131'], cum=0.562\n",
      "    âœ“ head_27: shape=torch.Size([12800, 24]), var=['0.277', '0.164', '0.092'], cum=0.533\n",
      "    âœ“ head_28: shape=torch.Size([12800, 24]), var=['0.366', '0.175', '0.123'], cum=0.664\n",
      "    âœ“ head_29: shape=torch.Size([12800, 24]), var=['0.268', '0.148', '0.136'], cum=0.552\n",
      "    âœ“ head_30: shape=torch.Size([12800, 24]), var=['0.373', '0.204', '0.148'], cum=0.726\n",
      "    âœ“ head_31: shape=torch.Size([12800, 24]), var=['0.300', '0.248', '0.088'], cum=0.636\n",
      "\n",
      "  Block 1:\n",
      "    âœ“ head_0: shape=torch.Size([12800, 24]), var=['0.310', '0.190', '0.113'], cum=0.613\n",
      "    âœ“ head_1: shape=torch.Size([12800, 24]), var=['0.287', '0.169', '0.121'], cum=0.577\n",
      "    âœ“ head_2: shape=torch.Size([12800, 24]), var=['0.258', '0.181', '0.125'], cum=0.564\n",
      "    âœ“ head_3: shape=torch.Size([12800, 24]), var=['0.447', '0.152', '0.120'], cum=0.719\n",
      "    âœ“ head_4: shape=torch.Size([12800, 24]), var=['0.372', '0.144', '0.122'], cum=0.639\n",
      "    âœ“ head_5: shape=torch.Size([12800, 24]), var=['0.241', '0.205', '0.116'], cum=0.562\n",
      "    âœ“ head_6: shape=torch.Size([12800, 24]), var=['0.303', '0.185', '0.100'], cum=0.589\n",
      "    âœ“ head_7: shape=torch.Size([12800, 24]), var=['0.468', '0.155', '0.081'], cum=0.704\n",
      "    âœ“ head_8: shape=torch.Size([12800, 24]), var=['0.479', '0.166', '0.099'], cum=0.744\n",
      "    âœ“ head_9: shape=torch.Size([12800, 24]), var=['0.307', '0.171', '0.106'], cum=0.584\n",
      "    âœ“ head_10: shape=torch.Size([12800, 24]), var=['0.419', '0.157', '0.106'], cum=0.681\n",
      "    âœ“ head_11: shape=torch.Size([12800, 24]), var=['0.257', '0.194', '0.152'], cum=0.603\n",
      "    âœ“ head_12: shape=torch.Size([12800, 24]), var=['0.364', '0.156', '0.107'], cum=0.627\n",
      "    âœ“ head_13: shape=torch.Size([12800, 24]), var=['0.265', '0.192', '0.178'], cum=0.635\n",
      "    âœ“ head_14: shape=torch.Size([12800, 24]), var=['0.304', '0.219', '0.131'], cum=0.654\n",
      "    âœ“ head_15: shape=torch.Size([12800, 24]), var=['0.258', '0.221', '0.121'], cum=0.601\n",
      "    âœ“ head_16: shape=torch.Size([12800, 24]), var=['0.300', '0.137', '0.114'], cum=0.550\n",
      "    âœ“ head_17: shape=torch.Size([12800, 24]), var=['0.294', '0.228', '0.131'], cum=0.653\n",
      "    âœ“ head_18: shape=torch.Size([12800, 24]), var=['0.261', '0.234', '0.141'], cum=0.636\n",
      "    âœ“ head_19: shape=torch.Size([12800, 24]), var=['0.301', '0.226', '0.129'], cum=0.656\n",
      "    âœ“ head_20: shape=torch.Size([12800, 24]), var=['0.267', '0.161', '0.138'], cum=0.566\n",
      "    âœ“ head_21: shape=torch.Size([12800, 24]), var=['0.303', '0.151', '0.091'], cum=0.546\n",
      "    âœ“ head_22: shape=torch.Size([12800, 24]), var=['0.269', '0.183', '0.128'], cum=0.580\n",
      "    âœ“ head_23: shape=torch.Size([12800, 24]), var=['0.354', '0.203', '0.079'], cum=0.636\n",
      "    âœ“ head_24: shape=torch.Size([12800, 24]), var=['0.306', '0.173', '0.093'], cum=0.571\n",
      "    âœ“ head_25: shape=torch.Size([12800, 24]), var=['0.284', '0.178', '0.125'], cum=0.586\n",
      "    âœ“ head_26: shape=torch.Size([12800, 24]), var=['0.348', '0.189', '0.093'], cum=0.630\n",
      "    âœ“ head_27: shape=torch.Size([12800, 24]), var=['0.521', '0.120', '0.094'], cum=0.735\n",
      "    âœ“ head_28: shape=torch.Size([12800, 24]), var=['0.263', '0.189', '0.134'], cum=0.586\n",
      "    âœ“ head_29: shape=torch.Size([12800, 24]), var=['0.820', '0.056', '0.032'], cum=0.908\n",
      "    âœ“ head_30: shape=torch.Size([12800, 24]), var=['0.336', '0.211', '0.106'], cum=0.653\n",
      "    âœ“ head_31: shape=torch.Size([12800, 24]), var=['0.337', '0.195', '0.103'], cum=0.635\n",
      "\n",
      "================================================================================\n",
      "âœ… Fitting completato!\n",
      "================================================================================\n",
      "\n",
      "\n",
      "ðŸ“Š PCA Variance Ratios:\n",
      "================================================================================\n",
      "\n",
      "layer_0:\n",
      "  block_0:\n",
      "    head_0: top3=['0.879', '0.061', '0.051'], cum=0.991\n",
      "    head_1: top3=['0.782', '0.090', '0.076'], cum=0.948\n",
      "    head_2: top3=['0.883', '0.072', '0.035'], cum=0.989\n",
      "    head_3: top3=['0.836', '0.070', '0.037'], cum=0.943\n",
      "  block_1:\n",
      "    head_0: top3=['0.345', '0.237', '0.149'], cum=0.730\n",
      "    head_1: top3=['0.750', '0.115', '0.042'], cum=0.907\n",
      "    head_2: top3=['0.620', '0.139', '0.116'], cum=0.875\n",
      "    head_3: top3=['0.538', '0.225', '0.105'], cum=0.868\n",
      "\n",
      "layer_1:\n",
      "  block_0:\n",
      "    head_0: top3=['0.434', '0.158', '0.113'], cum=0.706\n",
      "    head_1: top3=['0.241', '0.158', '0.117'], cum=0.515\n",
      "    head_2: top3=['0.243', '0.146', '0.121'], cum=0.511\n",
      "    head_3: top3=['0.620', '0.144', '0.089'], cum=0.854\n",
      "    head_4: top3=['0.576', '0.113', '0.062'], cum=0.751\n",
      "    head_5: top3=['0.254', '0.140', '0.112'], cum=0.506\n",
      "    head_6: top3=['0.495', '0.246', '0.119'], cum=0.860\n",
      "    head_7: top3=['0.279', '0.186', '0.091'], cum=0.557\n",
      "  block_1:\n",
      "    head_0: top3=['0.374', '0.278', '0.082'], cum=0.735\n",
      "    head_1: top3=['0.275', '0.225', '0.108'], cum=0.608\n",
      "    head_2: top3=['0.268', '0.154', '0.141'], cum=0.564\n",
      "    head_3: top3=['0.333', '0.198', '0.131'], cum=0.662\n",
      "    head_4: top3=['0.461', '0.152', '0.076'], cum=0.690\n",
      "    head_5: top3=['0.251', '0.165', '0.128'], cum=0.544\n",
      "    head_6: top3=['0.391', '0.188', '0.121'], cum=0.700\n",
      "    head_7: top3=['0.275', '0.250', '0.141'], cum=0.666\n",
      "\n",
      "layer_2:\n",
      "  block_0:\n",
      "    head_0: top3=['0.338', '0.208', '0.110'], cum=0.655\n",
      "    head_1: top3=['0.368', '0.145', '0.124'], cum=0.637\n",
      "    head_2: top3=['0.383', '0.156', '0.071'], cum=0.611\n",
      "    head_3: top3=['0.401', '0.160', '0.143'], cum=0.704\n",
      "    head_4: top3=['0.292', '0.230', '0.170'], cum=0.692\n",
      "    head_5: top3=['0.391', '0.229', '0.156'], cum=0.775\n",
      "    head_6: top3=['0.379', '0.243', '0.128'], cum=0.750\n",
      "    head_7: top3=['0.444', '0.267', '0.078'], cum=0.790\n",
      "    head_8: top3=['0.295', '0.151', '0.130'], cum=0.576\n",
      "    head_9: top3=['0.306', '0.147', '0.118'], cum=0.570\n",
      "    head_10: top3=['0.338', '0.190', '0.152'], cum=0.680\n",
      "    head_11: top3=['0.406', '0.178', '0.137'], cum=0.720\n",
      "    head_12: top3=['0.374', '0.178', '0.143'], cum=0.695\n",
      "    head_13: top3=['0.282', '0.238', '0.130'], cum=0.650\n",
      "    head_14: top3=['0.358', '0.142', '0.091'], cum=0.591\n",
      "    head_15: top3=['0.429', '0.140', '0.097'], cum=0.666\n",
      "  block_1:\n",
      "    head_0: top3=['0.327', '0.193', '0.116'], cum=0.636\n",
      "    head_1: top3=['0.328', '0.208', '0.083'], cum=0.619\n",
      "    head_2: top3=['0.178', '0.150', '0.106'], cum=0.434\n",
      "    head_3: top3=['0.258', '0.175', '0.133'], cum=0.566\n",
      "    head_4: top3=['0.357', '0.163', '0.123'], cum=0.643\n",
      "    head_5: top3=['0.316', '0.156', '0.141'], cum=0.613\n",
      "    head_6: top3=['0.269', '0.220', '0.111'], cum=0.599\n",
      "    head_7: top3=['0.372', '0.143', '0.085'], cum=0.600\n",
      "    head_8: top3=['0.240', '0.131', '0.100'], cum=0.470\n",
      "    head_9: top3=['0.462', '0.147', '0.090'], cum=0.699\n",
      "    head_10: top3=['0.278', '0.154', '0.123'], cum=0.555\n",
      "    head_11: top3=['0.258', '0.206', '0.148'], cum=0.612\n",
      "    head_12: top3=['0.275', '0.214', '0.143'], cum=0.631\n",
      "    head_13: top3=['0.322', '0.191', '0.101'], cum=0.614\n",
      "    head_14: top3=['0.286', '0.185', '0.141'], cum=0.612\n",
      "    head_15: top3=['0.270', '0.255', '0.154'], cum=0.679\n",
      "  block_2:\n",
      "    head_0: top3=['0.298', '0.207', '0.121'], cum=0.626\n",
      "    head_1: top3=['0.297', '0.182', '0.110'], cum=0.589\n",
      "    head_2: top3=['0.326', '0.111', '0.096'], cum=0.533\n",
      "    head_3: top3=['0.334', '0.175', '0.089'], cum=0.599\n",
      "    head_4: top3=['0.247', '0.133', '0.105'], cum=0.485\n",
      "    head_5: top3=['0.307', '0.242', '0.117'], cum=0.666\n",
      "    head_6: top3=['0.338', '0.307', '0.087'], cum=0.732\n",
      "    head_7: top3=['0.324', '0.126', '0.120'], cum=0.570\n",
      "    head_8: top3=['0.301', '0.136', '0.106'], cum=0.543\n",
      "    head_9: top3=['0.236', '0.166', '0.115'], cum=0.517\n",
      "    head_10: top3=['0.332', '0.187', '0.103'], cum=0.622\n",
      "    head_11: top3=['0.294', '0.206', '0.138'], cum=0.637\n",
      "    head_12: top3=['0.360', '0.135', '0.125'], cum=0.619\n",
      "    head_13: top3=['0.333', '0.125', '0.112'], cum=0.570\n",
      "    head_14: top3=['0.320', '0.155', '0.115'], cum=0.590\n",
      "    head_15: top3=['0.317', '0.140', '0.095'], cum=0.552\n",
      "  block_3:\n",
      "    head_0: top3=['0.360', '0.228', '0.104'], cum=0.692\n",
      "    head_1: top3=['0.253', '0.149', '0.111'], cum=0.512\n",
      "    head_2: top3=['0.271', '0.174', '0.129'], cum=0.573\n",
      "    head_3: top3=['0.258', '0.153', '0.115'], cum=0.527\n",
      "    head_4: top3=['0.212', '0.122', '0.101'], cum=0.436\n",
      "    head_5: top3=['0.289', '0.110', '0.101'], cum=0.501\n",
      "    head_6: top3=['0.225', '0.191', '0.152'], cum=0.568\n",
      "    head_7: top3=['0.204', '0.183', '0.158'], cum=0.544\n",
      "    head_8: top3=['0.241', '0.144', '0.122'], cum=0.508\n",
      "    head_9: top3=['0.332', '0.111', '0.096'], cum=0.539\n",
      "    head_10: top3=['0.197', '0.151', '0.114'], cum=0.462\n",
      "    head_11: top3=['0.224', '0.181', '0.118'], cum=0.523\n",
      "    head_12: top3=['0.350', '0.118', '0.083'], cum=0.552\n",
      "    head_13: top3=['0.190', '0.136', '0.112'], cum=0.437\n",
      "    head_14: top3=['0.278', '0.153', '0.103'], cum=0.534\n",
      "    head_15: top3=['0.171', '0.123', '0.102'], cum=0.395\n",
      "  block_4:\n",
      "    head_0: top3=['0.286', '0.169', '0.120'], cum=0.575\n",
      "    head_1: top3=['0.214', '0.164', '0.119'], cum=0.497\n",
      "    head_2: top3=['0.339', '0.140', '0.088'], cum=0.568\n",
      "    head_3: top3=['0.249', '0.110', '0.104'], cum=0.463\n",
      "    head_4: top3=['0.198', '0.144', '0.097'], cum=0.438\n",
      "    head_5: top3=['0.210', '0.124', '0.098'], cum=0.432\n",
      "    head_6: top3=['0.245', '0.176', '0.112'], cum=0.534\n",
      "    head_7: top3=['0.209', '0.181', '0.077'], cum=0.468\n",
      "    head_8: top3=['0.234', '0.149', '0.125'], cum=0.508\n",
      "    head_9: top3=['0.229', '0.152', '0.112'], cum=0.493\n",
      "    head_10: top3=['0.368', '0.114', '0.094'], cum=0.575\n",
      "    head_11: top3=['0.305', '0.161', '0.100'], cum=0.566\n",
      "    head_12: top3=['0.274', '0.114', '0.105'], cum=0.493\n",
      "    head_13: top3=['0.330', '0.148', '0.086'], cum=0.564\n",
      "    head_14: top3=['0.210', '0.152', '0.119'], cum=0.481\n",
      "    head_15: top3=['0.233', '0.162', '0.092'], cum=0.487\n",
      "  block_5:\n",
      "    head_0: top3=['0.175', '0.136', '0.095'], cum=0.406\n",
      "    head_1: top3=['0.199', '0.137', '0.111'], cum=0.447\n",
      "    head_2: top3=['0.158', '0.145', '0.112'], cum=0.414\n",
      "    head_3: top3=['0.274', '0.161', '0.136'], cum=0.571\n",
      "    head_4: top3=['0.265', '0.157', '0.112'], cum=0.535\n",
      "    head_5: top3=['0.261', '0.137', '0.103'], cum=0.502\n",
      "    head_6: top3=['0.296', '0.139', '0.097'], cum=0.532\n",
      "    head_7: top3=['0.193', '0.136', '0.114'], cum=0.442\n",
      "    head_8: top3=['0.336', '0.094', '0.091'], cum=0.522\n",
      "    head_9: top3=['0.227', '0.192', '0.105'], cum=0.524\n",
      "    head_10: top3=['0.306', '0.138', '0.105'], cum=0.549\n",
      "    head_11: top3=['0.235', '0.125', '0.099'], cum=0.459\n",
      "    head_12: top3=['0.224', '0.152', '0.106'], cum=0.483\n",
      "    head_13: top3=['0.330', '0.132', '0.097'], cum=0.558\n",
      "    head_14: top3=['0.196', '0.114', '0.097'], cum=0.407\n",
      "    head_15: top3=['0.188', '0.135', '0.099'], cum=0.423\n",
      "\n",
      "layer_3:\n",
      "  block_0:\n",
      "    head_0: top3=['0.319', '0.178', '0.108'], cum=0.606\n",
      "    head_1: top3=['0.304', '0.187', '0.091'], cum=0.583\n",
      "    head_2: top3=['0.364', '0.127', '0.125'], cum=0.616\n",
      "    head_3: top3=['0.248', '0.188', '0.114'], cum=0.550\n",
      "    head_4: top3=['0.331', '0.231', '0.107'], cum=0.669\n",
      "    head_5: top3=['0.613', '0.134', '0.066'], cum=0.812\n",
      "    head_6: top3=['0.207', '0.157', '0.136'], cum=0.499\n",
      "    head_7: top3=['0.381', '0.146', '0.079'], cum=0.606\n",
      "    head_8: top3=['0.320', '0.180', '0.109'], cum=0.610\n",
      "    head_9: top3=['0.518', '0.107', '0.076'], cum=0.701\n",
      "    head_10: top3=['0.424', '0.132', '0.119'], cum=0.675\n",
      "    head_11: top3=['0.284', '0.152', '0.133'], cum=0.568\n",
      "    head_12: top3=['0.469', '0.129', '0.080'], cum=0.679\n",
      "    head_13: top3=['0.264', '0.217', '0.098'], cum=0.578\n",
      "    head_14: top3=['0.317', '0.255', '0.100'], cum=0.672\n",
      "    head_15: top3=['0.252', '0.161', '0.102'], cum=0.515\n",
      "    head_16: top3=['0.485', '0.157', '0.104'], cum=0.745\n",
      "    head_17: top3=['0.232', '0.154', '0.114'], cum=0.500\n",
      "    head_18: top3=['0.341', '0.193', '0.128'], cum=0.662\n",
      "    head_19: top3=['0.333', '0.135', '0.118'], cum=0.586\n",
      "    head_20: top3=['0.323', '0.166', '0.161'], cum=0.650\n",
      "    head_21: top3=['0.253', '0.153', '0.119'], cum=0.526\n",
      "    head_22: top3=['0.373', '0.165', '0.086'], cum=0.624\n",
      "    head_23: top3=['0.274', '0.158', '0.128'], cum=0.560\n",
      "    head_24: top3=['0.318', '0.186', '0.074'], cum=0.578\n",
      "    head_25: top3=['0.306', '0.186', '0.109'], cum=0.600\n",
      "    head_26: top3=['0.265', '0.165', '0.131'], cum=0.562\n",
      "    head_27: top3=['0.277', '0.164', '0.092'], cum=0.533\n",
      "    head_28: top3=['0.366', '0.175', '0.123'], cum=0.664\n",
      "    head_29: top3=['0.268', '0.148', '0.136'], cum=0.552\n",
      "    head_30: top3=['0.373', '0.204', '0.148'], cum=0.726\n",
      "    head_31: top3=['0.300', '0.248', '0.088'], cum=0.636\n",
      "  block_1:\n",
      "    head_0: top3=['0.310', '0.190', '0.113'], cum=0.613\n",
      "    head_1: top3=['0.287', '0.169', '0.121'], cum=0.577\n",
      "    head_2: top3=['0.258', '0.181', '0.125'], cum=0.564\n",
      "    head_3: top3=['0.447', '0.152', '0.120'], cum=0.719\n",
      "    head_4: top3=['0.372', '0.144', '0.122'], cum=0.639\n",
      "    head_5: top3=['0.241', '0.205', '0.116'], cum=0.562\n",
      "    head_6: top3=['0.303', '0.185', '0.100'], cum=0.589\n",
      "    head_7: top3=['0.468', '0.155', '0.081'], cum=0.704\n",
      "    head_8: top3=['0.479', '0.166', '0.099'], cum=0.744\n",
      "    head_9: top3=['0.307', '0.171', '0.106'], cum=0.584\n",
      "    head_10: top3=['0.419', '0.157', '0.106'], cum=0.681\n",
      "    head_11: top3=['0.257', '0.194', '0.152'], cum=0.603\n",
      "    head_12: top3=['0.364', '0.156', '0.107'], cum=0.627\n",
      "    head_13: top3=['0.265', '0.192', '0.178'], cum=0.635\n",
      "    head_14: top3=['0.304', '0.219', '0.131'], cum=0.654\n",
      "    head_15: top3=['0.258', '0.221', '0.121'], cum=0.601\n",
      "    head_16: top3=['0.300', '0.137', '0.114'], cum=0.550\n",
      "    head_17: top3=['0.294', '0.228', '0.131'], cum=0.653\n",
      "    head_18: top3=['0.261', '0.234', '0.141'], cum=0.636\n",
      "    head_19: top3=['0.301', '0.226', '0.129'], cum=0.656\n",
      "    head_20: top3=['0.267', '0.161', '0.138'], cum=0.566\n",
      "    head_21: top3=['0.303', '0.151', '0.091'], cum=0.546\n",
      "    head_22: top3=['0.269', '0.183', '0.128'], cum=0.580\n",
      "    head_23: top3=['0.354', '0.203', '0.079'], cum=0.636\n",
      "    head_24: top3=['0.306', '0.173', '0.093'], cum=0.571\n",
      "    head_25: top3=['0.284', '0.178', '0.125'], cum=0.586\n",
      "    head_26: top3=['0.348', '0.189', '0.093'], cum=0.630\n",
      "    head_27: top3=['0.521', '0.120', '0.094'], cum=0.735\n",
      "    head_28: top3=['0.263', '0.189', '0.134'], cum=0.586\n",
      "    head_29: top3=['0.820', '0.056', '0.032'], cum=0.908\n",
      "    head_30: top3=['0.336', '0.211', '0.106'], cum=0.653\n",
      "    head_31: top3=['0.337', '0.195', '0.103'], cum=0.635\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Fitting PCA Components\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Fit PCA\n",
    "print(f\"Fitting PCA on {len(pca_dataset)} samples...\")\n",
    "variance_ratios = clap_residual.clap.audio_encoder.base.htsat.fit_spectral_layers(\n",
    "    pca_loader,\n",
    "    max_samples=PCA_SAMPLES\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š PCA Variance Ratios:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Gestione corretta della struttura gerarchica\n",
    "for layer_name, layer_data in variance_ratios.items():\n",
    "    print(f\"\\n{layer_name}:\")\n",
    "    \n",
    "    # Controlla se Ã¨ mode 'attention' (struttura annidata) o 'layer' (array diretto)\n",
    "    if isinstance(layer_data, dict):\n",
    "        # Mode ATTENTION: layer_data contiene blocchi\n",
    "        for block_name, block_data in layer_data.items():\n",
    "            print(f\"  {block_name}:\")\n",
    "            \n",
    "            # block_data contiene le teste\n",
    "            for head_name, head_variance in block_data.items():\n",
    "                # head_variance Ã¨ l'array numpy con le variance ratios\n",
    "                top3 = head_variance[:3]\n",
    "                cumulative = head_variance[:3].sum()\n",
    "                print(f\"    {head_name}: top3={[f'{v:.3f}' for v in top3]}, cum={cumulative:.3f}\")\n",
    "    else:\n",
    "        # Mode LAYER: layer_data Ã¨ direttamente l'array di variance ratios\n",
    "        top5 = layer_data[:5]\n",
    "        cumulative = layer_data[:5].sum()\n",
    "        print(f\"  Top 5 components: {[f'{v:.4f}' for v in top5]}\")\n",
    "        print(f\"  Cumulative variance (top 5): {cumulative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Text embeddings shape: torch.Size([14, 1024])\n",
      "\n",
      "ðŸ“Š Testing on 300 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9844a7d7f44e43a99bdf51b690ae8af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baseline:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Baseline Accuracy: 0.487 (48.7%)\n"
     ]
    }
   ],
   "source": [
    "# Get text embeddings ONCE for all classes\n",
    "text_embeddings = clap_standard.get_text_embeddings(text_labels)\n",
    "print(f\"   Text embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "# Test on subset first (use full dataset later)\n",
    "test_size = 300  # Start with 200 samples for speed\n",
    "print(f\"\\nðŸ“Š Testing on {test_size} samples...\")\n",
    "\n",
    "y_preds_baseline, y_labels = [], []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"Baseline\"):\n",
    "    # Get audio file path and label\n",
    "    audio_path, target, one_hot_target = dataset[-(i+1)]\n",
    "    \n",
    "    # Get audio embedding\n",
    "    audio_embedding = clap_standard.get_audio_embeddings([audio_path], resample=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = clap_standard.compute_similarity(audio_embedding, text_embeddings)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_baseline.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "y_labels_array = np.concatenate(y_labels, axis=0)\n",
    "y_preds_baseline_array = np.concatenate(y_preds_baseline, axis=0)\n",
    "\n",
    "baseline_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_baseline_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Baseline Accuracy: {baseline_acc:.3f} ({baseline_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acd5e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4866666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e60c8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Text embeddings shape: torch.Size([14, 1024])\n",
      "\n",
      "ðŸ“Š Testing on 300 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0452449ebc34486e9df640efbb8e290a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "residual:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Residual Accuracy: 0.477 (47.7%)\n"
     ]
    }
   ],
   "source": [
    "# Get text embeddings ONCE for all classes\n",
    "text_embeddings = clap_residual.get_text_embeddings(text_labels)\n",
    "print(f\"   Text embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "# Test on subset first (use full dataset later)\n",
    "test_size = 300  # Start with 200 samples for speed\n",
    "print(f\"\\nðŸ“Š Testing on {test_size} samples...\")\n",
    "\n",
    "y_preds_residual, y_labels = [], []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"residual\"):\n",
    "    # Get audio file path and label\n",
    "    audio_path, target, one_hot_target = dataset[-(i+1)]\n",
    "    \n",
    "    # Get audio embedding\n",
    "    audio_embedding = clap_residual.get_audio_embeddings([audio_path], resample=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = clap_residual.compute_similarity(audio_embedding, text_embeddings)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_residual.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "y_labels_array = np.concatenate(y_labels, axis=0)\n",
    "y_preds_residual_array = np.concatenate(y_preds_residual, axis=0)\n",
    "\n",
    "residual_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_residual_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Residual Accuracy: {residual_acc:.3f} ({residual_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4928d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4766666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e65ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6708739e-04, 1.2584196e-06, 2.9712135e-04, ..., 6.7006997e-03,\n",
       "        3.0785173e-04, 2.0462200e-04],\n",
       "       [2.2296207e-02, 3.8817632e-07, 9.7235944e-04, ..., 1.1185975e-01,\n",
       "        1.8533451e-02, 1.6015100e-03],\n",
       "       [3.2923691e-04, 1.4916168e-07, 2.2600570e-03, ..., 2.1775109e-03,\n",
       "        1.9798054e-04, 2.3463765e-05],\n",
       "       ...,\n",
       "       [4.1160925e-05, 5.4688858e-06, 2.3399117e-04, ..., 4.6371697e-03,\n",
       "        5.7084661e-04, 5.0900719e-04],\n",
       "       [8.4686953e-06, 2.0872583e-06, 8.4836545e-05, ..., 1.3730243e-04,\n",
       "        2.6141252e-05, 4.6615824e-05],\n",
       "       [2.4429901e-06, 1.2070299e-06, 1.6206970e-05, ..., 2.3242106e-05,\n",
       "        5.3767344e-06, 7.7631994e-06]], shape=(300, 14), dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_residual_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732a402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0666220e-03, 2.7926972e-06, 6.2200730e-04, ..., 1.8173505e-02,\n",
       "        9.1775961e-04, 6.3625700e-04],\n",
       "       [2.5382778e-03, 8.6734516e-08, 2.0553814e-03, ..., 1.6275084e-02,\n",
       "        1.5918226e-03, 1.3957666e-04],\n",
       "       [3.2923743e-04, 1.4916178e-07, 2.2600584e-03, ..., 2.1775123e-03,\n",
       "        1.9798067e-04, 2.3463779e-05],\n",
       "       ...,\n",
       "       [4.1160984e-05, 5.4688940e-06, 2.3399139e-04, ..., 4.6371715e-03,\n",
       "        5.7084742e-04, 5.0900766e-04],\n",
       "       [8.4687190e-06, 2.0872642e-06, 8.4836785e-05, ..., 1.3730268e-04,\n",
       "        2.6141302e-05, 4.6615911e-05],\n",
       "       [2.4429924e-06, 1.2070299e-06, 1.6206954e-05, ..., 2.3242106e-05,\n",
       "        5.3767399e-06, 7.7632076e-06]], shape=(300, 14), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_baseline_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fdc7130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ” Verifica Stato Fitting di TUTTI gli Spectral Layers\n",
      "================================================================================\n",
      "\n",
      "âœ… TUTTI i layer sono fittati correttamente con pesi = 1.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFICA: Tutti gli Spectral Layers sono stati fittati?\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ” Verifica Stato Fitting di TUTTI gli Spectral Layers\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "htsat = clap_residual.clap.audio_encoder.base.htsat\n",
    "all_fitted = True\n",
    "\n",
    "for layer_idx in residual_config['target_layers']:\n",
    "    layer_name = f'layer_{layer_idx}'\n",
    "    \n",
    "    if layer_name in htsat.spectral_layers:\n",
    "        block_spectral_layers = htsat.spectral_layers[layer_name]\n",
    "        \n",
    "        for block_idx, head_spectral_layers in enumerate(block_spectral_layers):\n",
    "            for head_idx, spectral_layer in enumerate(head_spectral_layers):\n",
    "                is_fitted = spectral_layer.is_fitted.item()\n",
    "                \n",
    "                if not is_fitted:\n",
    "                    print(f\"âŒ {layer_name}, Block {block_idx}, Head {head_idx}: NOT FITTED!\")\n",
    "                    all_fitted = False\n",
    "                else:\n",
    "                    # Verifica che i pesi siano effettivamente 1.0\n",
    "                    weights = spectral_layer.pc_weights.data\n",
    "                    all_ones = torch.allclose(weights, torch.ones_like(weights), atol=1e-6)\n",
    "                    \n",
    "                    if not all_ones:\n",
    "                        print(f\"âš ï¸  {layer_name}, Block {block_idx}, Head {head_idx}: \"\n",
    "                              f\"Fitted ma pesi NON sono 1.0!\")\n",
    "                        print(f\"    Primi 5 pesi: {weights[:5].tolist()}\")\n",
    "                        all_fitted = False\n",
    "\n",
    "if all_fitted:\n",
    "    print(\"\\nâœ… TUTTI i layer sono fittati correttamente con pesi = 1.0\")\n",
    "else:\n",
    "    print(\"\\nâŒ PROBLEMA: Alcuni layer non sono fittati correttamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726a89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path, target, one_hot_target = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d03d337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6079,  0.6576, -0.5101,  ...,  1.8574,  0.9557,  0.2268]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clap_residual.get_audio_embeddings([audio_path], resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2aa61e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7623,  0.2343, -0.5101,  ...,  1.8940,  0.9414, -0.0119]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clap_standard.get_audio_embeddings([audio_path], resample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c17b4e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m torch.allclose(\u001b[43mx\u001b[49m, y, atol=\u001b[32m1e-5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "torch.allclose(x, y, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5497e-06)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x - y).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9dda6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0003)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x - y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bf7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468c504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
