{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component — Label Alignment Analysis\n",
    "\n",
    "This notebook investigates whether the principal components (PCs) of HTS-AT attention head representations encode **task-relevant semantic information** about audio classes.\n",
    "\n",
    "**Hypothesis**: If PC directions in a head's representation space capture semantic structure, then projecting samples onto those directions should yield features that are more discriminative than random projections of equal dimensionality.\n",
    "\n",
    "**Method**: For each attention head, we:\n",
    "1. Compute PCA on the pooled head representations $\\mathbf{R} \\in \\mathbb{R}^{n \\times d_h}$\n",
    "2. Train a logistic regression classifier using only the top-$k$ PCs as features\n",
    "3. Compare accuracy against a random-projection baseline of equal dimensionality\n",
    "4. Aggregate results across heads, blocks, and layers to identify specialization patterns\n",
    "\n",
    "**Interpretation**: Heads where PC-based accuracy significantly exceeds the random baseline are those whose principal directions are semantically aligned with class structure — precisely the heads that are candidates for ResiDual spectral reweighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration loaded — 12 blocks, 184 total heads\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scientific computing\n",
    "from scipy import stats\n",
    "\n",
    "# ML & Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ── Palette & Style ──────────────────────────────────────────────────────────\n",
    "COLORS = {\n",
    "    'layer0': '#2d77a6',\n",
    "    'layer1': '#bf7b04',\n",
    "    'layer2': '#6ea66d',\n",
    "    'layer3': '#808080',\n",
    "    'accent':  '#d62728',\n",
    "    'neutral': '#7f7f7f'\n",
    "}\n",
    "LAYER_COLORS = [COLORS['layer0'], COLORS['layer1'], COLORS['layer2'], COLORS['layer3']]\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'mathtext.fontset': 'stix',\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.titlesize': 13,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'axes.axisbelow': True\n",
    "})\n",
    "\n",
    "# ── Architecture constants ───────────────────────────────────────────────────\n",
    "HTSAT_DEPTHS = [2, 2, 6, 2]\n",
    "HTSAT_HEADS  = [4, 8, 16, 32]\n",
    "HTSAT_EMBED  = 96\n",
    "HEAD_DIM     = 24\n",
    "\n",
    "SAVE_DIR     = 'heads_representations'\n",
    "FIGURES_DIR  = 'figures'\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "# ── Block index table ────────────────────────────────────────────────────────\n",
    "block_info = []\n",
    "global_block = 0\n",
    "for layer_idx, (depth, n_heads) in enumerate(zip(HTSAT_DEPTHS, HTSAT_HEADS)):\n",
    "    for block_idx in range(depth):\n",
    "        block_info.append({\n",
    "            'global_block':   global_block,\n",
    "            'layer':          layer_idx,\n",
    "            'block_in_layer': block_idx,\n",
    "            'n_heads':        n_heads,\n",
    "            'head_dim':       HEAD_DIM,\n",
    "        })\n",
    "        global_block += 1\n",
    "block_info_df = pd.DataFrame(block_info)\n",
    "\n",
    "print(f'✅ Configuration loaded — {len(block_info_df)} blocks, '\n",
    "      f'{sum(d*h for d,h in zip(HTSAT_DEPTHS, HTSAT_HEADS))} total heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Saved Head Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ESC50\n",
      "   Samples  : 2000\n",
      "   Classes  : 50\n",
      "   Heads    : 184\n",
      "   Head dim : 24\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'esc50'  # ← change to 'tinysol' or 'vocalsound' as needed\n",
    "\n",
    "load_path = f\"{SAVE_DIR}/{DATASET_NAME}_head_outputs_final.pt\"\n",
    "data = torch.load(load_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "head_outputs = data['head_outputs_final']   # dict: head_id → tensor [N, 24]\n",
    "labels       = data['labels']               # np.array [N]\n",
    "\n",
    "N_SAMPLES  = len(labels)\n",
    "N_CLASSES  = len(np.unique(labels))\n",
    "head_ids   = sorted(head_outputs.keys())\n",
    "N_HEADS    = len(head_ids)\n",
    "\n",
    "print(f'✅ Loaded {DATASET_NAME.upper()}')\n",
    "print(f'   Samples  : {N_SAMPLES}')\n",
    "print(f'   Classes  : {N_CLASSES}')\n",
    "print(f'   Heads    : {N_HEADS}')\n",
    "print(f'   Head dim : {HEAD_DIM}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Probe Analysis\n",
    "\n",
    "For each head $h$ with representation matrix $\\mathbf{R}_h \\in \\mathbb{R}^{n \\times d_h}$:\n",
    "\n",
    "1. Compute PCA: obtain eigenvectors $\\mathbf{V} = [\\mathbf{v}_1, \\ldots, \\mathbf{v}_{d_h}]$ ordered by explained variance\n",
    "2. Project: $\\mathbf{Z}^{(k)} = \\mathbf{R}_h \\mathbf{V}_{:,1:k} \\in \\mathbb{R}^{n \\times k}$\n",
    "3. Evaluate: 5-fold stratified cross-validation accuracy of logistic regression on $\\mathbf{Z}^{(k)}$\n",
    "4. Baseline: same procedure with $k$ random orthonormal directions (averaged over 10 seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51fc57607b04315985d949ec31b8ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Linear probe per head:   0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m     Q, _ = np.linalg.qr(rand_mat)\n\u001b[32m     47\u001b[39m     Z_rand = R_scaled @ Q[:, :k]\n\u001b[32m     48\u001b[39m     acc_rand_list.append(\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_rand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.mean()\n\u001b[32m     50\u001b[39m     )\n\u001b[32m     51\u001b[39m acc_rand = np.mean(acc_rand_list)\n\u001b[32m     52\u001b[39m std_rand = np.std(acc_rand_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:459\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    455\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    456\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    457\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    458\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    474\u001b[39m     solver,\n\u001b[32m    475\u001b[39m     opt_res,\n\u001b[32m    476\u001b[39m     max_iter,\n\u001b[32m    477\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    479\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:403\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/_lib/_util.py:590\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    593\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:316\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     weights, intercept = \u001b[38;5;28mself\u001b[39m.weight_intercept(coef)\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m loss, grad_pointwise = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m sw_sum = n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.sum(sample_weight)\n\u001b[32m    323\u001b[39m loss = loss.sum() / sw_sum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/GitHub/ResiDual-CLAP/.venv/lib/python3.11/site-packages/sklearn/_loss/loss.py:205\u001b[39m, in \u001b[36mBaseLoss.loss_gradient\u001b[39m\u001b[34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m.closs.loss(\n\u001b[32m    197\u001b[39m         y_true=y_true,\n\u001b[32m    198\u001b[39m         raw_prediction=raw_prediction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         n_threads=n_threads,\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_gradient\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     y_true,\n\u001b[32m    208\u001b[39m     raw_prediction,\n\u001b[32m    209\u001b[39m     sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    210\u001b[39m     loss_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    211\u001b[39m     gradient_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    212\u001b[39m     n_threads=\u001b[32m1\u001b[39m,\n\u001b[32m    213\u001b[39m ):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m \u001b[33;03m        Element-wise gradients.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "N_RANDOM_SEEDS = 10\n",
    "K_VALUES       = [1, 2, 3, 5]   # number of PCs to use\n",
    "CV_FOLDS       = 5\n",
    "MAX_ITER       = 1000\n",
    "\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for head_id in tqdm(head_ids, desc='Linear probe per head'):\n",
    "    # Parse metadata from head_id string e.g. 'L0_B1_H3'\n",
    "    parts      = head_id.split('_')\n",
    "    layer_idx  = int(parts[0][1:])\n",
    "    block_idx  = int(parts[1][1:])\n",
    "    head_idx   = int(parts[2][1:])\n",
    "    global_blk = block_info_df[\n",
    "        (block_info_df['layer'] == layer_idx) &\n",
    "        (block_info_df['block_in_layer'] == block_idx)\n",
    "    ]['global_block'].values[0]\n",
    "\n",
    "    R = head_outputs[head_id].numpy()   # [N, 24]\n",
    "\n",
    "    # Standardise before PCA (zero mean, unit variance per feature)\n",
    "    scaler = StandardScaler()\n",
    "    R_scaled = scaler.fit_transform(R)\n",
    "\n",
    "    # PCA decomposition\n",
    "    pca = PCA(n_components=HEAD_DIM, random_state=42)\n",
    "    pca.fit(R_scaled)\n",
    "    R_pca = pca.transform(R_scaled)   # [N, 24] — all PCs\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        clf = LogisticRegression(max_iter=MAX_ITER, random_state=42,\n",
    "                                  solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "        # ── PC-based probe ───────────────────────────────────────────────────\n",
    "        Z_pc  = R_pca[:, :k]\n",
    "        acc_pc = cross_val_score(clf, Z_pc, labels, cv=cv, scoring='accuracy').mean()\n",
    "\n",
    "        # ── Random baseline (averaged over seeds) ────────────────────────────\n",
    "        acc_rand_list = []\n",
    "        for seed in range(N_RANDOM_SEEDS):\n",
    "            rng = np.random.default_rng(seed)\n",
    "            # Random orthonormal basis via QR decomposition\n",
    "            rand_mat = rng.standard_normal((HEAD_DIM, k))\n",
    "            Q, _ = np.linalg.qr(rand_mat)\n",
    "            Z_rand = R_scaled @ Q[:, :k]\n",
    "            acc_rand_list.append(\n",
    "                cross_val_score(clf, Z_rand, labels, cv=cv, scoring='accuracy').mean()\n",
    "            )\n",
    "        acc_rand = np.mean(acc_rand_list)\n",
    "        std_rand = np.std(acc_rand_list)\n",
    "\n",
    "        # ── Delta: how much better than random ──────────────────────────────\n",
    "        delta = acc_pc - acc_rand\n",
    "\n",
    "        results.append({\n",
    "            'head_id':      head_id,\n",
    "            'layer':        layer_idx,\n",
    "            'global_block': global_blk,\n",
    "            'block':        block_idx,\n",
    "            'head':         head_idx,\n",
    "            'k':            k,\n",
    "            'acc_pc':       acc_pc,\n",
    "            'acc_rand':     acc_rand,\n",
    "            'std_rand':     std_rand,\n",
    "            'delta':        delta,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f'✅ Linear probe complete — {len(results_df)} rows')\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "RESULTS_DIR = 'probe_results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# ── 1. Full results dataframe ─────────────────────────────────────────────────\n",
    "results_df.to_csv(f'{RESULTS_DIR}/probe_{DATASET_NAME}.csv', index=False)\n",
    "\n",
    "# ── 2. Metadata needed by the analysis notebook ──────────────────────────────\n",
    "import json\n",
    "meta = {\n",
    "    'dataset_name': DATASET_NAME,\n",
    "    'n_samples':    int(N_SAMPLES),\n",
    "    'n_classes':    int(N_CLASSES),\n",
    "    'head_dim':     int(HEAD_DIM),\n",
    "    'k_values':     K_VALUES,\n",
    "    'cv_folds':     CV_FOLDS,\n",
    "    'n_random_seeds': N_RANDOM_SEEDS,\n",
    "    'htsat_depths': HTSAT_DEPTHS,\n",
    "    'htsat_heads':  HTSAT_HEADS,\n",
    "}\n",
    "with open(f'{RESULTS_DIR}/meta_{DATASET_NAME}.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# ── 3. Block info table ───────────────────────────────────────────────────────\n",
    "block_info_df.to_csv(f'{RESULTS_DIR}/block_info.csv', index=False)\n",
    "\n",
    "print(f'✅ Saved to {RESULTS_DIR}/')\n",
    "print(f'   probe_{DATASET_NAME}.csv      — {len(results_df)} rows')\n",
    "print(f'   meta_{DATASET_NAME}.json      — experiment metadata')\n",
    "print(f'   block_info.csv               — block/layer/head mapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on k=1 (PC1 alone) as primary indicator of semantic concentration\n",
    "results_df = pd.read_csv(f'{RESULTS_DIR}/probe_{DATASET_NAME}.csv')\n",
    "k1_df = results_df[results_df['k'] == 1].copy()\n",
    "\n",
    "layer_summary = k1_df.groupby('layer').agg(\n",
    "    acc_pc_mean   = ('acc_pc',   'mean'),\n",
    "    acc_pc_std    = ('acc_pc',   'std'),\n",
    "    acc_rand_mean = ('acc_rand', 'mean'),\n",
    "    acc_rand_std  = ('acc_rand', 'std'),\n",
    "    delta_mean    = ('delta',    'mean'),\n",
    "    delta_max     = ('delta',    'max'),\n",
    "    n_heads       = ('head_id',  'count')\n",
    ").reset_index()\n",
    "\n",
    "print('Layer-wise summary (k=1, PC1 only):')\n",
    "display(layer_summary.round(4))\n",
    "\n",
    "# Top-10 most semantically informative heads (by delta at k=1)\n",
    "print('\\nTop-10 heads by Δ accuracy (PC1 vs random):')\n",
    "display(\n",
    "    k1_df.nlargest(10, 'delta')[['head_id','layer','global_block','head','acc_pc','acc_rand','delta']]\n",
    "    .round(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation\n",
    "\n",
    "### Figure A — PC1 accuracy vs. random baseline across all heads, grouped by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(14, 4), sharey=True)\n",
    "fig.suptitle(\n",
    "    r'Linear Probe Accuracy: PC$_1$ vs. Random Baseline (k=1)',\n",
    "    fontsize=13, y=1.02\n",
    ")\n",
    "\n",
    "layer_labels = ['Stage 1 (L0)', 'Stage 2 (L1)', 'Stage 3 (L2)', 'Stage 4 (L3)']\n",
    "\n",
    "for layer_idx, ax in enumerate(axes):\n",
    "    sub = k1_df[k1_df['layer'] == layer_idx]\n",
    "    color = LAYER_COLORS[layer_idx]\n",
    "\n",
    "    x = np.arange(len(sub))\n",
    "    ax.bar(x, sub['acc_pc'].values,  color=color,             alpha=0.85,\n",
    "           label='PC$_1$', zorder=3)\n",
    "    ax.bar(x, sub['acc_rand'].values, color=COLORS['neutral'], alpha=0.45,\n",
    "           label='Random', zorder=2)\n",
    "\n",
    "    # Error bars for random baseline std\n",
    "    ax.errorbar(x, sub['acc_rand'].values, yerr=sub['std_rand'].values,\n",
    "                fmt='none', color='#333333', capsize=2, linewidth=0.8, zorder=4)\n",
    "\n",
    "    # Chance level\n",
    "    chance = 1.0 / N_CLASSES\n",
    "    ax.axhline(chance, color=COLORS['accent'], linewidth=1.0,\n",
    "               linestyle='--', label=f'Chance ({chance:.2f})', zorder=5)\n",
    "\n",
    "    ax.set_title(layer_labels[layer_idx], color=color, fontweight='bold')\n",
    "    ax.set_xlabel('Head index')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(sub['head'].values, fontsize=7)\n",
    "    if layer_idx == 0:\n",
    "        ax.set_ylabel('5-fold CV accuracy')\n",
    "    ax.set_ylim(0, min(1.05, k1_df['acc_pc'].max() * 1.25))\n",
    "\n",
    "# Shared legend\n",
    "handles = [\n",
    "    mpatches.Patch(color=LAYER_COLORS[0], alpha=0.85, label='PC$_1$ accuracy'),\n",
    "    mpatches.Patch(color=COLORS['neutral'], alpha=0.45, label='Random baseline'),\n",
    "    plt.Line2D([0],[0], color=COLORS['accent'], linestyle='--', label='Chance level'),\n",
    "]\n",
    "fig.legend(handles=handles, loc='lower center', ncol=3,\n",
    "           bbox_to_anchor=(0.5, -0.08), frameon=True, edgecolor='#cccccc')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{FIGURES_DIR}/pc1_probe_by_layer.pdf', bbox_inches='tight', dpi=300)\n",
    "fig.savefig(f'{FIGURES_DIR}/pc1_probe_by_layer.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "print('✅ Saved figure A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure B — Delta heatmap: Δ accuracy (PC vs random) across blocks × heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 2D matrix: rows = global blocks (0–11), cols = head index within block\n",
    "# Max heads per block is 32 (Stage 4); pad with NaN\n",
    "max_heads = max(HTSAT_HEADS)\n",
    "N_BLOCKS  = sum(HTSAT_DEPTHS)\n",
    "\n",
    "delta_matrix = np.full((N_BLOCKS, max_heads), np.nan)\n",
    "acc_matrix   = np.full((N_BLOCKS, max_heads), np.nan)\n",
    "\n",
    "for _, row in k1_df.iterrows():\n",
    "    b = int(row['global_block'])\n",
    "    h = int(row['head'])\n",
    "    delta_matrix[b, h] = row['delta']\n",
    "    acc_matrix[b, h]   = row['acc_pc']\n",
    "\n",
    "# ── Plot ─────────────────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "fig.suptitle(\n",
    "    r'Head-level Semantic Alignment: PC$_1$ Linear Probe on ' + DATASET_NAME.upper(),\n",
    "    fontsize=13\n",
    ")\n",
    "\n",
    "# --- Panel (a): Δ accuracy heatmap ---\n",
    "ax = axes[0]\n",
    "im = ax.imshow(delta_matrix, aspect='auto', cmap='RdYlGn',\n",
    "               vmin=-0.05, vmax=delta_matrix[~np.isnan(delta_matrix)].max())\n",
    "\n",
    "# Stage boundary lines\n",
    "stage_boundaries = np.cumsum(HTSAT_DEPTHS)[:-1] - 0.5\n",
    "for boundary in stage_boundaries:\n",
    "    ax.axhline(boundary, color='black', linewidth=1.5, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Annotate values\n",
    "for b in range(N_BLOCKS):\n",
    "    n_h = HTSAT_HEADS[block_info_df.loc[block_info_df['global_block']==b, 'layer'].values[0]]\n",
    "    for h in range(n_h):\n",
    "        val = delta_matrix[b, h]\n",
    "        if not np.isnan(val):\n",
    "            ax.text(h, b, f'{val:.2f}', ha='center', va='center',\n",
    "                    fontsize=6, color='black' if abs(val) < 0.08 else 'white')\n",
    "\n",
    "cb = plt.colorbar(im, ax=ax, fraction=0.03, pad=0.03)\n",
    "cb.set_label(r'$\\Delta$ accuracy (PC$_1$ − random)', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Head index within block')\n",
    "ax.set_ylabel('Global block index')\n",
    "ax.set_title(r'(a) $\\Delta$ accuracy: PC$_1$ vs. random baseline')\n",
    "ax.set_yticks(range(N_BLOCKS))\n",
    "ax.set_yticklabels([f'B{b}' for b in range(N_BLOCKS)], fontsize=8)\n",
    "\n",
    "# Stage annotations on the right\n",
    "stage_centers = []\n",
    "cum = 0\n",
    "for d in HTSAT_DEPTHS:\n",
    "    stage_centers.append(cum + d/2 - 0.5)\n",
    "    cum += d\n",
    "stage_names = ['S1','S2','S3','S4']\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.set_yticks(stage_centers)\n",
    "ax2.set_yticklabels(stage_names, fontsize=9, fontweight='bold',\n",
    "                    color=[LAYER_COLORS[i] for i in range(4)])\n",
    "ax2.tick_params(length=0)\n",
    "\n",
    "# --- Panel (b): PC1 accuracy heatmap ---\n",
    "ax = axes[1]\n",
    "chance = 1.0 / N_CLASSES\n",
    "im2 = ax.imshow(acc_matrix, aspect='auto', cmap='Blues',\n",
    "                vmin=chance, vmax=acc_matrix[~np.isnan(acc_matrix)].max())\n",
    "\n",
    "for boundary in stage_boundaries:\n",
    "    ax.axhline(boundary, color='black', linewidth=1.5, linestyle='--', alpha=0.7)\n",
    "\n",
    "for b in range(N_BLOCKS):\n",
    "    n_h = HTSAT_HEADS[block_info_df.loc[block_info_df['global_block']==b, 'layer'].values[0]]\n",
    "    for h in range(n_h):\n",
    "        val = acc_matrix[b, h]\n",
    "        if not np.isnan(val):\n",
    "            ax.text(h, b, f'{val:.2f}', ha='center', va='center',\n",
    "                    fontsize=6, color='white' if val > (chance + 0.15) else 'black')\n",
    "\n",
    "cb2 = plt.colorbar(im2, ax=ax, fraction=0.03, pad=0.03)\n",
    "cb2.set_label(r'PC$_1$ probe accuracy', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Head index within block')\n",
    "ax.set_ylabel('Global block index')\n",
    "ax.set_title(r'(b) Absolute PC$_1$ probe accuracy')\n",
    "ax.set_yticks(range(N_BLOCKS))\n",
    "ax.set_yticklabels([f'B{b}' for b in range(N_BLOCKS)], fontsize=8)\n",
    "\n",
    "ax3 = ax.twinx()\n",
    "ax3.set_ylim(ax.get_ylim())\n",
    "ax3.set_yticks(stage_centers)\n",
    "ax3.set_yticklabels(stage_names, fontsize=9, fontweight='bold',\n",
    "                    color=[LAYER_COLORS[i] for i in range(4)])\n",
    "ax3.tick_params(length=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{FIGURES_DIR}/pc1_alignment_heatmap.pdf', bbox_inches='tight', dpi=300)\n",
    "fig.savefig(f'{FIGURES_DIR}/pc1_alignment_heatmap.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "print('✅ Saved figure B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure C — Effect of k: accuracy vs. number of PCs retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(14, 4), sharey=True)\n",
    "fig.suptitle('Probe Accuracy vs. Number of PCs Retained, by Stage', fontsize=13, y=1.02)\n",
    "\n",
    "for layer_idx, ax in enumerate(axes):\n",
    "    sub = results_df[results_df['layer'] == layer_idx]\n",
    "    color = LAYER_COLORS[layer_idx]\n",
    "\n",
    "    # Aggregate over heads within layer for each k\n",
    "    agg = sub.groupby('k').agg(\n",
    "        acc_pc_mean   = ('acc_pc',   'mean'),\n",
    "        acc_pc_std    = ('acc_pc',   'std'),\n",
    "        acc_rand_mean = ('acc_rand', 'mean'),\n",
    "        acc_rand_std  = ('acc_rand', 'std'),\n",
    "    ).reset_index()\n",
    "\n",
    "    ax.plot(agg['k'], agg['acc_pc_mean'], color=color, marker='o',\n",
    "            linewidth=1.8, markersize=5, label='PC directions', zorder=4)\n",
    "    ax.fill_between(agg['k'],\n",
    "                    agg['acc_pc_mean'] - agg['acc_pc_std'],\n",
    "                    agg['acc_pc_mean'] + agg['acc_pc_std'],\n",
    "                    alpha=0.15, color=color)\n",
    "\n",
    "    ax.plot(agg['k'], agg['acc_rand_mean'], color=COLORS['neutral'],\n",
    "            marker='s', linewidth=1.4, markersize=4,\n",
    "            linestyle='--', label='Random dirs', zorder=3)\n",
    "    ax.fill_between(agg['k'],\n",
    "                    agg['acc_rand_mean'] - agg['acc_rand_std'],\n",
    "                    agg['acc_rand_mean'] + agg['acc_rand_std'],\n",
    "                    alpha=0.10, color=COLORS['neutral'])\n",
    "\n",
    "    ax.axhline(1.0/N_CLASSES, color=COLORS['accent'], linewidth=1.0,\n",
    "               linestyle=':', label='Chance', zorder=2)\n",
    "\n",
    "    ax.set_title(f'Stage {layer_idx+1} (L{layer_idx})', color=color, fontweight='bold')\n",
    "    ax.set_xlabel('Number of PCs ($k$)')\n",
    "    if layer_idx == 0:\n",
    "        ax.set_ylabel('Mean 5-fold CV accuracy')\n",
    "    ax.set_xticks(K_VALUES)\n",
    "\n",
    "handles, hlabels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, hlabels, loc='lower center', ncol=3,\n",
    "           bbox_to_anchor=(0.5, -0.10), frameon=True, edgecolor='#cccccc')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{FIGURES_DIR}/probe_vs_k.pdf', bbox_inches='tight', dpi=300)\n",
    "fig.savefig(f'{FIGURES_DIR}/probe_vs_k.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "print('✅ Saved figure C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure D — Distribution of Δ accuracy per layer (violin plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "layer_names = ['Stage 1\\n(L0)', 'Stage 2\\n(L1)', 'Stage 3\\n(L2)', 'Stage 4\\n(L3)']\n",
    "\n",
    "parts = ax.violinplot(\n",
    "    [k1_df[k1_df['layer'] == l]['delta'].values for l in range(4)],\n",
    "    positions=range(4),\n",
    "    showmedians=True,\n",
    "    showextrema=True,\n",
    ")\n",
    "\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(LAYER_COLORS[i])\n",
    "    pc.set_alpha(0.6)\n",
    "parts['cmedians'].set_color('black')\n",
    "parts['cmedians'].set_linewidth(1.5)\n",
    "parts['cmaxes'].set_color('#333333')\n",
    "parts['cmins'].set_color('#333333')\n",
    "parts['cbars'].set_color('#333333')\n",
    "\n",
    "# Overlay jittered scatter\n",
    "for l in range(4):\n",
    "    deltas = k1_df[k1_df['layer'] == l]['delta'].values\n",
    "    jitter = np.random.default_rng(42).uniform(-0.08, 0.08, len(deltas))\n",
    "    ax.scatter(l + jitter, deltas, s=18, color=LAYER_COLORS[l],\n",
    "               alpha=0.5, zorder=3, edgecolors='none')\n",
    "\n",
    "ax.axhline(0, color=COLORS['accent'], linewidth=1.0,\n",
    "           linestyle='--', label='No gain over random')\n",
    "\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels(layer_names)\n",
    "ax.set_ylabel(r'$\\Delta$ accuracy = PC$_1$ probe $-$ random baseline')\n",
    "ax.set_title(r'Distribution of Semantic Gain ($\\Delta$ accuracy) per Stage')\n",
    "ax.legend(frameon=True, edgecolor='#cccccc')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{FIGURES_DIR}/delta_violin.pdf', bbox_inches='tight', dpi=300)\n",
    "fig.savefig(f'{FIGURES_DIR}/delta_violin.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "print('✅ Saved figure D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('Statistical tests: PC1 accuracy vs. random baseline (k=1)')\n",
    "print('One-sample t-test: H0: mean(delta) = 0')\n",
    "print('=' * 60)\n",
    "\n",
    "for layer_idx in range(4):\n",
    "    deltas = k1_df[k1_df['layer'] == layer_idx]['delta'].values\n",
    "    t_stat, p_val = stats.ttest_1samp(deltas, popmean=0)\n",
    "    print(f'Stage {layer_idx+1} (L{layer_idx}): '\n",
    "          f'mean Δ={deltas.mean():.4f}, '\n",
    "          f't={t_stat:.3f}, p={p_val:.4f} '\n",
    "          f'{\"***\" if p_val<0.001 else \"**\" if p_val<0.01 else \"*\" if p_val<0.05 else \"ns\"}')\n",
    "\n",
    "print()\n",
    "print('── Top specialised heads (Δ > 2σ above mean Δ) ──')\n",
    "global_mean = k1_df['delta'].mean()\n",
    "global_std  = k1_df['delta'].std()\n",
    "threshold   = global_mean + 2 * global_std\n",
    "top_heads   = k1_df[k1_df['delta'] > threshold].sort_values('delta', ascending=False)\n",
    "display(top_heads[['head_id','layer','global_block','head','acc_pc','acc_rand','delta']].round(4))\n",
    "print(f'\\nThreshold (μ + 2σ) = {threshold:.4f}')\n",
    "print(f'Specialised heads  = {len(top_heads)} / {len(k1_df)} '\n",
    "      f'({100*len(top_heads)/len(k1_df):.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'{FIGURES_DIR}/pc_probe_results_{DATASET_NAME}.csv', index=False)\n",
    "print(f'✅ Results saved → {FIGURES_DIR}/pc_probe_results_{DATASET_NAME}.csv')\n",
    "\n",
    "print('\\n── Final summary ──')\n",
    "print(f'Dataset   : {DATASET_NAME.upper()}')\n",
    "print(f'Samples   : {N_SAMPLES}   Classes: {N_CLASSES}')\n",
    "print(f'Chance    : {1/N_CLASSES:.4f}')\n",
    "print()\n",
    "for l in range(4):\n",
    "    sub = k1_df[k1_df['layer']==l]\n",
    "    print(f'  Stage {l+1}: mean PC1 acc={sub[\"acc_pc\"].mean():.4f} '\n",
    "          f'rand={sub[\"acc_rand\"].mean():.4f} '\n",
    "          f'Δ={sub[\"delta\"].mean():.4f} '\n",
    "          f'(best head: {sub.loc[sub[\"delta\"].idxmax(),\"head_id\"]}, '\n",
    "          f'Δ={sub[\"delta\"].max():.4f})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
