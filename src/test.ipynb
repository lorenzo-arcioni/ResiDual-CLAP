{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486b20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Setup\n",
    "# ============================================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import from your codebase\n",
    "from CLAPWrapper import CLAPWrapper\n",
    "from datasets.esc50 import ESC50  # Adjust import path if needed\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5153f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Loading ESC50 Dataset\n",
      "==================================================\n",
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 16865.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: 2000 samples\n",
      "   Classes: 50 categories\n",
      "   Sample classes: ['airplane', 'breathing', 'brushing teeth', 'can opening', 'car horn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Loading ESC50 Dataset\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "root_path = \"./data\"\n",
    "dataset = ESC50(root=root_path, download=True)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded: {len(dataset)} samples\")\n",
    "print(f\"   Classes: {len(dataset.classes)} categories\")\n",
    "print(f\"   Sample classes: {dataset.classes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bd247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Text prompts prepared: 50 classes\n",
      "   Examples: ['this is the sound of airplane', 'this is the sound of breathing', 'this is the sound of brushing teeth']\n"
     ]
    }
   ],
   "source": [
    "prompt = 'this is the sound of '\n",
    "text_labels = [prompt + x for x in dataset.classes]\n",
    "print(f\"\\nüìù Text prompts prepared: {len(text_labels)} classes\")\n",
    "print(f\"   Examples: {text_labels[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5e2c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing BASELINE CLAP\n",
      "==================================================\n",
      "‚úÖ Baseline CLAP loaded\n",
      "   Text embeddings shape: torch.Size([50, 1024])\n",
      "\n",
      "üìä Testing on 200 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6201d4750e06478a8bb18e8b5b17184a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baseline:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Baseline Accuracy: 0.940 (94.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing BASELINE CLAP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize BASELINE using CLAPWrapper\n",
    "baseline_wrapper = CLAPWrapper(version='2023', use_cuda=torch.cuda.is_available())\n",
    "print(\"‚úÖ Baseline CLAP loaded\")\n",
    "\n",
    "# Get text embeddings ONCE for all classes\n",
    "text_embeddings = baseline_wrapper.get_text_embeddings(text_labels)\n",
    "print(f\"   Text embeddings shape: {text_embeddings.shape}\")\n",
    "\n",
    "# Test on subset first (use full dataset later)\n",
    "test_size = 200  # Start with 200 samples for speed\n",
    "print(f\"\\nüìä Testing on {test_size} samples...\")\n",
    "\n",
    "y_preds_baseline, y_labels = [], []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"Baseline\"):\n",
    "    # Get audio file path and label\n",
    "    audio_path, target, one_hot_target = dataset[i]\n",
    "    \n",
    "    # Get audio embedding\n",
    "    audio_embedding = baseline_wrapper.get_audio_embeddings([audio_path], resample=True)\n",
    "    \n",
    "    # Compute similarity\n",
    "    similarity = baseline_wrapper.compute_similarity(audio_embedding, text_embeddings)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_baseline.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "y_labels_array = np.concatenate(y_labels, axis=0)\n",
    "y_preds_baseline_array = np.concatenate(y_preds_baseline, axis=0)\n",
    "\n",
    "baseline_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_baseline_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline Accuracy: {baseline_acc:.3f} ({baseline_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9206372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Setting up RESIDUAL CLAP\n",
      "==================================================\n",
      "[2, 2, 6, 2]\n",
      "üîç Detecting layer dimensions...\n",
      "  ‚úì 0: torch.Size([1, 1024, 192])\n",
      "  ‚úì 1: torch.Size([1, 256, 384])\n",
      "  ‚úì 2: torch.Size([1, 64, 768])\n",
      "  ‚úì 3: torch.Size([1, 64, 768])\n",
      "  ‚úì layer_1: 384D ‚Üí 384 PCs\n",
      "  ‚úì layer_3: 768D ‚Üí 768 PCs\n",
      "‚úÖ ResiDual model initialized\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Setting up RESIDUAL CLAP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create residual config\n",
    "residual_config = {\n",
    "    'target_layers': [1, 3],        # Which transformer layers to modify\n",
    "    'n_components_ratio': 1.0,     # Use 25% of dims as PCA components\n",
    "    'reweight_factor': 1.0          # Amplification factor\n",
    "}\n",
    "\n",
    "# Initialize RESIDUAL CLAP wrapper (we need to modify CLAPWrapper)\n",
    "# For now, we'll load the model directly\n",
    "from models.residual_clap import ResiDualCLAP\n",
    "\n",
    "# Load config from baseline\n",
    "args = baseline_wrapper.args\n",
    "\n",
    "# Create ResiDual model\n",
    "residual_model = ResiDualCLAP(\n",
    "    audioenc_name=args.audioenc_name,\n",
    "    sample_rate=args.sampling_rate,\n",
    "    window_size=args.window_size,\n",
    "    hop_size=args.hop_size,\n",
    "    mel_bins=args.mel_bins,\n",
    "    fmin=args.fmin,\n",
    "    fmax=args.fmax,\n",
    "    classes_num=args.num_classes,\n",
    "    out_emb=args.out_emb,\n",
    "    text_model=args.text_model,\n",
    "    transformer_embed_dim=args.transformer_embed_dim,\n",
    "    d_proj=args.d_proj,\n",
    "    residual_config=residual_config\n",
    ")\n",
    "\n",
    "# Load pretrained weights from baseline\n",
    "residual_model.load_state_dict(baseline_wrapper.clap.state_dict(), strict=False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    residual_model = residual_model.cuda()\n",
    "\n",
    "residual_model.eval()\n",
    "print(\"‚úÖ ResiDual model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f4672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîç DIMENSION CHECK\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Testing BASELINE:\n",
      "   Audio embedding shape: torch.Size([2, 1024])\n",
      "   Classification output: torch.Size([2, 527])\n",
      "\n",
      "2Ô∏è‚É£ Testing RESIDUAL:\n",
      "   Audio embedding shape: torch.Size([2, 1024])\n",
      "   Classification output: torch.Size([2, 527])\n",
      "\n",
      "3Ô∏è‚É£ Comparison:\n",
      "   ‚úÖ Embedding dimensions MATCH!\n",
      "   Cosine similarity: 1.0000\n",
      "   ‚úÖ Embeddings are very similar - weights loaded correctly!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç DIMENSION CHECK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test audio\n",
    "test_audio = torch.randn(2, baseline_wrapper.args.sampling_rate * baseline_wrapper.args.duration)\n",
    "if torch.cuda.is_available():\n",
    "    test_audio = test_audio.cuda()\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Testing BASELINE:\")\n",
    "with torch.no_grad():\n",
    "    baseline_emb, baseline_cls = baseline_wrapper.clap.audio_encoder(test_audio)\n",
    "    print(f\"   Audio embedding shape: {baseline_emb.shape}\")\n",
    "    print(f\"   Classification output: {baseline_cls.shape if baseline_cls is not None else 'None'}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Testing RESIDUAL:\")\n",
    "with torch.no_grad():\n",
    "    residual_emb, residual_cls = residual_model.audio_encoder(test_audio)\n",
    "    print(f\"   Audio embedding shape: {residual_emb.shape}\")\n",
    "    print(f\"   Classification output: {residual_cls.shape if residual_cls is not None else 'None'}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Comparison:\")\n",
    "if baseline_emb.shape == residual_emb.shape:\n",
    "    print(\"   ‚úÖ Embedding dimensions MATCH!\")\n",
    "    \n",
    "    # Cosine similarity (dovrebbe essere alta se i pesi sono caricati correttamente)\n",
    "    cos_sim = F.cosine_similarity(baseline_emb, residual_emb, dim=1).mean().item()\n",
    "    print(f\"   Cosine similarity: {cos_sim:.4f}\")\n",
    "    \n",
    "    if cos_sim > 0.9:\n",
    "        print(\"   ‚úÖ Embeddings are very similar - weights loaded correctly!\")\n",
    "    elif cos_sim > 0.5:\n",
    "        print(\"   ‚ö†Ô∏è  Embeddings somewhat similar - some weights might be missing\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Embeddings very different - weight loading failed!\")\n",
    "else:\n",
    "    print(f\"   ‚ùå DIMENSION MISMATCH!\")\n",
    "    print(f\"      Baseline: {baseline_emb.shape}\")\n",
    "    print(f\"      ResiDual: {residual_emb.shape}\")\n",
    "    print(\"   üõë STOP - Fix this before continuing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6c8a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fitting PCA Components\n",
      "==================================================\n",
      "Using 100 samples for PCA fitting...\n",
      "Collecting head outputs for PCA fitting...\n",
      "Fitting PCA for layer_1 with 25600 samples...\n",
      "layer_1: Top 5 PC variance ratios: [0.44309655 0.08553774 0.04176068 0.03511701 0.02265158]\n",
      "Fitting PCA for layer_3 with 6400 samples...\n",
      "layer_3: Top 5 PC variance ratios: [0.32341182 0.0953413  0.04937391 0.03558723 0.0263464 ]\n",
      "‚úÖ PCA fitted!\n",
      "   layer_1: top 5 variance ratios = [0.44309655 0.08553774 0.04176068 0.03511701 0.02265158]\n",
      "   layer_3: top 5 variance ratios = [0.32341182 0.0953413  0.04937391 0.03558723 0.0263464 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Fitting PCA Components\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# We need to create a simple dataloader for fitting\n",
    "fit_size = 100  # Use 100 samples for PCA fitting\n",
    "print(f\"Using {fit_size} samples for PCA fitting...\")\n",
    "\n",
    "class FitDataLoader:\n",
    "    \"\"\"Simple dataloader for PCA fitting\"\"\"\n",
    "    def __init__(self, dataset, indices, wrapper):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.wrapper = wrapper\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for idx in self.indices:\n",
    "            audio_path, _, _ = self.dataset[idx]\n",
    "            # Load audio using wrapper's method\n",
    "            audio_tensor = self.wrapper.load_audio_into_tensor(\n",
    "                audio_path, \n",
    "                self.wrapper.args.duration, \n",
    "                resample=True\n",
    "            )\n",
    "            # Reshape to match expected format\n",
    "            audio_tensor = audio_tensor.reshape(1, -1)\n",
    "            if torch.cuda.is_available():\n",
    "                audio_tensor = audio_tensor.cuda()\n",
    "            yield {'audio': audio_tensor}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "fit_loader = FitDataLoader(dataset, list(range(fit_size)), baseline_wrapper)\n",
    "\n",
    "# Fit spectral components\n",
    "variance_ratios = residual_model.fit_spectral_components(fit_loader, max_samples=fit_size)\n",
    "\n",
    "print(\"‚úÖ PCA fitted!\")\n",
    "for layer_name, ratios in variance_ratios.items():\n",
    "    print(f\"   {layer_name}: top 5 variance ratios = {ratios[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6fae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Debug: Checking spectral layer dimensions\n",
      "layer_1:\n",
      "  embed_dim configurato: 384\n",
      "  n_components: 96\n",
      "  pca_mean shape: torch.Size([384])\n",
      "  pca_components shape: torch.Size([384, 96])\n",
      "  is_fitted: True\n",
      "layer_3:\n",
      "  embed_dim configurato: 768\n",
      "  n_components: 192\n",
      "  pca_mean shape: torch.Size([768])\n",
      "  pca_components shape: torch.Size([768, 192])\n",
      "  is_fitted: True\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Verifica dimensioni dei spectral layers\n",
    "print(\"\\nüîç Debug: Checking spectral layer dimensions\")\n",
    "for layer_name, spectral_layer in residual_model.audio_base.spectral_layers.items():\n",
    "    print(f\"{layer_name}:\")\n",
    "    print(f\"  embed_dim configurato: {spectral_layer.embed_dim}\")\n",
    "    print(f\"  n_components: {spectral_layer.n_components}\")\n",
    "    print(f\"  pca_mean shape: {spectral_layer.pca_mean.shape}\")\n",
    "    print(f\"  pca_components shape: {spectral_layer.pca_components.shape}\")\n",
    "    print(f\"  is_fitted: {spectral_layer.is_fitted.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99b2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing RESIDUAL CLAP\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168288227f1841dcae3b7e6d1fa95536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ResiDual:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ResiDual Accuracy: 0.005 (0.5%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing RESIDUAL CLAP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get text embeddings (using baseline's text encoder - it's the same)\n",
    "text_embeddings_res = baseline_wrapper.get_text_embeddings(text_labels)\n",
    "\n",
    "# Test on same samples\n",
    "y_preds_residual = []\n",
    "\n",
    "for i in tqdm(range(test_size), desc=\"ResiDual\"):\n",
    "    # Get audio file path\n",
    "    audio_path, _, _ = dataset[i]\n",
    "    \n",
    "    # Load and process audio\n",
    "    audio_tensor = baseline_wrapper.load_audio_into_tensor(\n",
    "        audio_path, \n",
    "        baseline_wrapper.args.duration, \n",
    "        resample=True\n",
    "    )\n",
    "    audio_tensor = audio_tensor.reshape(1, -1)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        audio_tensor = audio_tensor.cuda()\n",
    "    \n",
    "    # Get embedding using ResiDual model\n",
    "    with torch.no_grad():\n",
    "        audio_embedding, _ = residual_model.audio_encoder(audio_tensor)\n",
    "        \n",
    "        # Normalize\n",
    "        audio_embedding = audio_embedding / torch.norm(audio_embedding, dim=-1, keepdim=True)\n",
    "        text_embeddings_norm = text_embeddings_res / torch.norm(text_embeddings_res, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Compute similarity\n",
    "        similarity = torch.matmul(audio_embedding, text_embeddings_norm.T)\n",
    "    \n",
    "    # Get prediction\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "    y_preds_residual.append(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_preds_residual_array = np.concatenate(y_preds_residual, axis=0)\n",
    "\n",
    "residual_acc = accuracy_score(\n",
    "    np.argmax(y_labels_array, axis=1), \n",
    "    np.argmax(y_preds_residual_array, axis=1)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ ResiDual Accuracy: {residual_acc:.3f} ({residual_acc*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00305110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESULTS COMPARISON\n",
      "==================================================\n",
      "\n",
      "üìä Tested on 200 samples from ESC50\n",
      "\n",
      "Accuracy:\n",
      "  Baseline:    0.940 (94.0%)\n",
      "  ResiDual:    0.005 (0.5%)\n",
      "  Improvement: -99.47%\n",
      "\n",
      "üîç Detailed Analysis:\n",
      "  Samples corrected by ResiDual: 0\n",
      "  Samples broken by ResiDual:    187\n",
      "  Net improvement:               -187\n",
      "\n",
      "‚ö†Ô∏è  Performance decreased - try adjusting config\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Compare Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "improvement = ((residual_acc - baseline_acc) / baseline_acc) * 100 if baseline_acc > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä Tested on {test_size} samples from ESC50\")\n",
    "print(f\"\\nAccuracy:\")\n",
    "print(f\"  Baseline:    {baseline_acc:.3f} ({baseline_acc*100:.1f}%)\")\n",
    "print(f\"  ResiDual:    {residual_acc:.3f} ({residual_acc*100:.1f}%)\")\n",
    "print(f\"  Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "# Analyze confusion\n",
    "baseline_correct = np.argmax(y_labels_array, axis=1) == np.argmax(y_preds_baseline_array, axis=1)\n",
    "residual_correct = np.argmax(y_labels_array, axis=1) == np.argmax(y_preds_residual_array, axis=1)\n",
    "\n",
    "newly_correct = np.sum(~baseline_correct & residual_correct)\n",
    "newly_wrong = np.sum(baseline_correct & ~residual_correct)\n",
    "\n",
    "print(f\"\\nüîç Detailed Analysis:\")\n",
    "print(f\"  Samples corrected by ResiDual: {newly_correct}\")\n",
    "print(f\"  Samples broken by ResiDual:    {newly_wrong}\")\n",
    "print(f\"  Net improvement:               {newly_correct - newly_wrong}\")\n",
    "\n",
    "if improvement > 5:\n",
    "    print(\"\\nüéØ Excellent! ResiDual significantly improves performance\")\n",
    "elif improvement > 0:\n",
    "    print(\"\\n‚úÖ Good! ResiDual shows improvement\")\n",
    "elif improvement > -2:\n",
    "    print(\"\\n‚ûñ Marginal difference\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Performance decreased - try adjusting config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: Visualize Results\n",
    "# ============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "methods = ['Baseline\\nCLAP', 'ResiDual\\nCLAP']\n",
    "accuracies = [baseline_acc, residual_acc]\n",
    "colors = ['#3498db', '#2ecc71']\n",
    "bars = ax1.bar(methods, accuracies, color=colors, alpha=0.7, width=0.6)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('ESC50 Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1.0])\n",
    "ax1.axhline(y=baseline_acc, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{val:.3f}\\n({val*100:.1f}%)',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Prediction confidence distribution\n",
    "ax2 = axes[1]\n",
    "baseline_confidences = np.max(y_preds_baseline_array, axis=1)\n",
    "residual_confidences = np.max(y_preds_residual_array, axis=1)\n",
    "\n",
    "ax2.hist(baseline_confidences, alpha=0.5, bins=20, color='#3498db', label='Baseline')\n",
    "ax2.hist(residual_confidences, alpha=0.5, bins=20, color='#2ecc71', label='ResiDual')\n",
    "ax2.set_xlabel('Prediction Confidence', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error analysis\n",
    "ax3 = axes[2]\n",
    "categories = ['Baseline\\nCorrect', 'ResiDual\\nCorrect', 'Newly\\nCorrected']\n",
    "values = [\n",
    "    np.sum(baseline_correct),\n",
    "    np.sum(residual_correct),\n",
    "    newly_correct\n",
    "]\n",
    "colors_bar = ['#3498db', '#2ecc71', '#27ae60']\n",
    "bars = ax3.bar(categories, values, color=colors_bar, alpha=0.7)\n",
    "ax3.set_ylabel('Number of Samples', fontsize=12)\n",
    "ax3.set_title('Error Analysis', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=test_size, color='gray', linestyle='--', alpha=0.3, label=f'Total ({test_size})')\n",
    "\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{val}',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: Test on Full Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIONAL: Full Dataset Test\")\n",
    "print(\"=\"*50)\n",
    "print(f\"To test on full ESC50 dataset ({len(dataset)} samples),\")\n",
    "print(f\"change 'test_size = {test_size}' to 'test_size = len(dataset)'\")\n",
    "print(f\"and re-run from STEP 4.\")\n",
    "print(f\"\\nNote: Full dataset will take ~10-15 minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
