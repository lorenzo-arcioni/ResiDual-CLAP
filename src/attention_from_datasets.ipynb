{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fabed8",
   "metadata": {},
   "source": [
    "# Multi-Granularity Representation Extraction for HTS-AT\n",
    "\n",
    "This notebook extracts attention representations at three granularities:\n",
    "\n",
    "1. **Per-head**: $\\text{Attn} \\cdot V$ pre-projection $W^O$, for each of the 184 heads individually.\n",
    "2. **Per-block**: mean of head representations within the same Swin block.\n",
    "3. **Per-layer**: mean of block representations within the same HTS-AT stage.\n",
    "\n",
    "## Architecture Recap\n",
    "\n",
    "HTS-AT has 4 stages (layers), 12 blocks total, 184 heads total:\n",
    "\n",
    "| Stage | Blocks | Heads/block | $d_h$ | $D_\\ell = H_\\ell \\cdot d_h$ |\n",
    "|-------|--------|-------------|-------|---------------------------|\n",
    "| L0    | 2      | 4           | 24    | 96                        |\n",
    "| L1    | 2      | 8           | 24    | 192                       |\n",
    "| L2    | 6      | 16          | 24    | 384                       |\n",
    "| L3    | 2      | 32          | 24    | 768                       |\n",
    "\n",
    "Note that $d_h = 24$ is constant across all stages since $d_h = D_\\ell / H_\\ell = (96 \\cdot 2^\\ell) / (4 \\cdot 2^\\ell) = 24$.\n",
    "\n",
    "## What We Extract (Pre-Projection)\n",
    "\n",
    "For each head $h$ in block $b$ of layer $\\ell$, we capture:\n",
    "\n",
    "$$\\mathbf{H}_{\\ell,b,h} = \\text{Attn}_{\\ell,b,h} \\cdot V_{\\ell,b,h} \\in \\mathbb{R}^{N_W \\cdot B \\times M \\times d_h}$$\n",
    "\n",
    "where $N_W$ is the number of spatial windows and $M = w^2 = 64$ tokens per window.\n",
    "We then spatial mean-pool to obtain a single vector per sample:\n",
    "\n",
    "$$\\mathbf{r}_{\\ell,b,h} = \\frac{1}{N_W M} \\sum_{i=1}^{N_W} \\sum_{j=1}^{M} \\mathbf{H}_{\\ell,b,h}[i,j,:] \\in \\mathbb{R}^{24}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f238021",
   "metadata": {},
   "source": [
    "## Cell 0 ‚Äî Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c4b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from CLAPWrapper import CLAPWrapper\n",
    "from datasets.esc50 import ESC50\n",
    "from datasets.tinysol import TinySOL\n",
    "from datasets.vocalsound import VocalSound\n",
    "\n",
    "# ‚îÄ‚îÄ Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "DATASET     = ESC50          # ‚Üê change to TinySOL or VocalSound as needed\n",
    "DATA_ROOT   = '../data'\n",
    "BATCH_SIZE  = 1              # process one sample at a time (safest for hook logic)\n",
    "SAVE_DIR    = 'heads_representations'\n",
    "\n",
    "# HTS-AT constants (fixed by architecture)\n",
    "HTSAT_DEPTHS = [2, 2, 6, 2]   # blocks per stage\n",
    "HTSAT_HEADS  = [4, 8, 16, 32] # attention heads per stage\n",
    "HTSAT_EMBED  = 96             # base embedding dim\n",
    "HEAD_DIM     = 24             # head_dim = layer_dim / n_heads = constant = 24\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c174e",
   "metadata": {},
   "source": [
    "## Cell 1 ‚Äî Load Dataset & Model\n",
    "\n",
    "Access path through CLAP's module hierarchy:\n",
    "`CLAPWrapper` $\\to$ `CLAP` $\\to$ `AudioEncoder.base` $\\to$ `HTSATWrapper.htsat`\n",
    "\n",
    "We also build here the `block_info_df` table that maps every global block index\n",
    "$b \\in \\{0, \\ldots, 11\\}$ to its stage $\\ell$ and intra-stage position.\n",
    "This table is shared by all three extraction cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f2af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 11332.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset : 2000 samples, 50 classes\n",
      "   Classes  : ['airplane', 'breathing', 'brushing teeth', 'can opening', 'car horn']... (+45 more)\n",
      "Loading CLAP ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "\n",
      "‚úÖ CLAP model loaded in eval mode\n",
      "   Stages  : 4\n",
      "   Depths  : [2, 2, 6, 2]\n",
      "   Heads   : [4, 8, 16, 32]\n",
      "   Embed   : 96\n",
      "\n",
      "   Total blocks : 12\n",
      "   Total heads  : 184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_block</th>\n",
       "      <th>layer</th>\n",
       "      <th>block_in_layer</th>\n",
       "      <th>n_heads</th>\n",
       "      <th>layer_dim</th>\n",
       "      <th>head_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>768</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>768</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_block  layer  block_in_layer  n_heads  layer_dim  head_dim\n",
       "0              0      0               0        4         96        24\n",
       "1              1      0               1        4         96        24\n",
       "2              2      1               0        8        192        24\n",
       "3              3      1               1        8        192        24\n",
       "4              4      2               0       16        384        24\n",
       "5              5      2               1       16        384        24\n",
       "6              6      2               2       16        384        24\n",
       "7              7      2               3       16        384        24\n",
       "8              8      2               4       16        384        24\n",
       "9              9      2               5       16        384        24\n",
       "10            10      3               0       32        768        24\n",
       "11            11      3               1       32        768        24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Dataset\n",
    "dataset = DATASET(root=DATA_ROOT, download=False)\n",
    "print(f\"üìä Dataset : {len(dataset)} samples, {len(dataset.classes)} classes\")\n",
    "print(f\"   Classes  : {dataset.classes[:5]}... (+{len(dataset.classes)-5} more)\")\n",
    "\n",
    "# CLAP model\n",
    "print(\"\\nLoading CLAP ...\", end='')\n",
    "wrapper       = CLAPWrapper(version='2023', use_cuda=torch.cuda.is_available())\n",
    "clap_model    = wrapper.clap\n",
    "clap_model.eval()\n",
    "\n",
    "# The HTS-AT Swin transformer inside CLAP\n",
    "# Access path: CLAPWrapper.clap  ‚Üí  CLAP  ‚Üí  AudioEncoder.base  ‚Üí  HTSATWrapper.htsat\n",
    "audio_encoder = clap_model.audio_encoder.base.htsat\n",
    "audio_encoder.eval()\n",
    "\n",
    "print('OK')\n",
    "\n",
    "print(f\"\\n‚úÖ CLAP model loaded in eval mode\")\n",
    "print(f\"   Stages  : {audio_encoder.num_layers}\")\n",
    "print(f\"   Depths  : {audio_encoder.depths}\")\n",
    "print(f\"   Heads   : {audio_encoder.num_heads}\")\n",
    "print(f\"   Embed   : {audio_encoder.embed_dim}\")\n",
    "\n",
    "# Build global block index table (used by all three extractors)\n",
    "block_info = []\n",
    "global_block = 0\n",
    "for layer_idx, (depth, n_heads) in enumerate(zip(HTSAT_DEPTHS, HTSAT_HEADS)):\n",
    "    layer_dim = HTSAT_EMBED * (2 ** layer_idx)\n",
    "    for block_idx in range(depth):\n",
    "        block_info.append({\n",
    "            'global_block': global_block,\n",
    "            'layer': layer_idx,\n",
    "            'block_in_layer': block_idx,\n",
    "            'n_heads': n_heads,\n",
    "            'layer_dim': layer_dim,\n",
    "            'head_dim': HEAD_DIM,\n",
    "        })\n",
    "        global_block += 1\n",
    "\n",
    "block_info_df = pd.DataFrame(block_info)\n",
    "N_BLOCKS = len(block_info_df)\n",
    "N_HEADS_TOTAL = sum(d * h for d, h in zip(HTSAT_DEPTHS, HTSAT_HEADS))\n",
    "print(f\"\\n   Total blocks : {N_BLOCKS}\")\n",
    "print(f\"   Total heads  : {N_HEADS_TOTAL}\")\n",
    "display(block_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643c9ec",
   "metadata": {},
   "source": [
    "## Cell 2 ‚Äî Build Stratified Sample List\n",
    "\n",
    "We collect exactly $\\lfloor N / C \\rfloor$ samples per class, where $N$ is the total\n",
    "dataset size and $C$ the number of classes. Samples are sorted by class index to ensure\n",
    "a deterministic ordering that is consistent across all three extraction cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9336e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: 40\n",
      "‚úÖ 2000 samples collected, 50 classes covered\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling: equal samples per class\n",
    "samples_per_class = len(dataset) // len(dataset.classes)\n",
    "print(f\"Samples per class: {samples_per_class}\")\n",
    "\n",
    "class_buckets = defaultdict(list)\n",
    "for idx in range(len(dataset)):\n",
    "    audio_path, class_name, one_hot = dataset[idx]\n",
    "    class_idx = torch.argmax(one_hot).item()\n",
    "    if len(class_buckets[class_idx]) < samples_per_class:\n",
    "        class_buckets[class_idx].append((audio_path, class_idx))\n",
    "    if (len(class_buckets) == len(dataset.classes) and\n",
    "            all(len(v) >= samples_per_class for v in class_buckets.values())):\n",
    "        break\n",
    "\n",
    "# Flatten sorted by class index ‚Üí deterministic ordering\n",
    "sample_list = []\n",
    "\n",
    "for class_idx in sorted(class_buckets.keys()):\n",
    "    sample_list.extend(class_buckets[class_idx])\n",
    "\n",
    "sample_labels = np.array([label for _, label in sample_list])\n",
    "N_SAMPLES     = len(sample_list)\n",
    "\n",
    "print(f\"‚úÖ {N_SAMPLES} samples collected, {len(class_buckets)} classes covered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05159517",
   "metadata": {},
   "source": [
    "## Cell 3 ‚Äî Extractor 1: Per-Head Representations\n",
    "\n",
    "**What we capture.** For each head $h$ in block $b$ of layer $\\ell$:\n",
    "\n",
    "$$\\mathbf{r}_{\\ell,b,h} = \\frac{1}{N_W M}\\sum_{i,j} (\\text{Attn}_{\\ell,b,h} \\cdot V_{\\ell,b,h})[i,j,:] \\in \\mathbb{R}^{24}$$\n",
    "\n",
    "This is computed *before* the output projection $W^O$. After $W^O$ the $H_\\ell$ heads\n",
    "are linearly mixed into a single $D_\\ell$-dimensional vector, destroying individual\n",
    "head structure. Pre-projection is therefore the only point where per-head subspaces\n",
    "are still disentangled.\n",
    "\n",
    "**Hook target.** We register one `register_forward_hook` on `WindowAttention` inside\n",
    "each `SwinTransformerBlock`. The hook:\n",
    "\n",
    "1. Reads `input[0]` ‚Äî the windowed token sequence $\\in \\mathbb{R}^{N_W B \\times M \\times D_\\ell}$.\n",
    "2. Re-computes $Q, K, V$ by passing the input through `module.qkv` (no grad).\n",
    "3. Computes $\\text{Attn}_{h} \\cdot V_h$ for each head $h$ without going through `proj` or `proj_drop`.\n",
    "4. Mean-pools over $(N_W B, M)$ to obtain $\\mathbf{r}_{\\ell,b,h} \\in \\mathbb{R}^{24}$.\n",
    "\n",
    "**Output.** 184 tensors of shape $[N_{\\text{samples}},\\, 24]$, one per head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfb086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered 12 hooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7105c5636104a2b9928e4b671c7199f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting heads:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Head extraction complete\n",
      "   Heads extracted : 184\n",
      "   Shape per head  : torch.Size([2000, 24])  (N_samples √ó head_dim)\n",
      "   Saved ‚Üí heads_representations/esc50_head_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "class HeadLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per SwinTransformerBlock attention module.\n",
    "    Each hook:\n",
    "      1. Re-computes QKV from the attention input (no grad).\n",
    "      2. Computes attn @ V for each head ‚Üí shape [nW*B, N, head_dim].\n",
    "      3. Mean-pools over (nW*B, N) ‚Üí shape [head_dim].\n",
    "      4. Appends the pooled vector to head_outputs[head_id].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model       = model\n",
    "        self.head_outputs = defaultdict(list)  # head_id ‚Üí list of [head_dim] tensors\n",
    "        self.hooks        = []\n",
    "\n",
    "    # ‚îÄ‚îÄ hook factory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def _make_hook(self, layer_idx, block_idx, n_heads):\n",
    "        def hook(module, input, output):\n",
    "            # input[0]: [nW*B, N, C]  where C = layer_dim, N = window_size^2\n",
    "            x_in        = input[0]                          # [nW*B, N, C]\n",
    "            _, attn_w   = output                            # attn_w: [nW*B, n_heads, N, N]\n",
    "            nWB, N, C   = x_in.shape\n",
    "            head_dim    = C // n_heads\n",
    "\n",
    "            # Re-compute QKV (no grad, same weights as forward pass)\n",
    "            with torch.no_grad():\n",
    "                qkv = module.qkv(x_in)                     # [nW*B, N, 3*C]\n",
    "            qkv = qkv.reshape(nWB, N, 3, n_heads, head_dim).permute(2, 0, 3, 1, 4)\n",
    "            # q, k, v: [nW*B, n_heads, N, head_dim]\n",
    "            v = qkv[2]\n",
    "\n",
    "            for h in range(n_heads):\n",
    "                # attn_w[:, h]: [nW*B, N, N]\n",
    "                # v[:, h]:      [nW*B, N, head_dim]\n",
    "                head_out = torch.matmul(attn_w[:, h], v[:, h])  # [nW*B, N, head_dim]\n",
    "                # Global spatial mean-pool ‚Üí [head_dim]\n",
    "                pooled   = head_out.mean(dim=[0, 1]).detach().cpu()\n",
    "                head_id  = f\"L{layer_idx}_B{block_idx}_H{h}\"\n",
    "                self.head_outputs[head_id].append(pooled)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    # ‚îÄ‚îÄ registration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def register_hooks(self):\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            n_heads = self.model.num_heads[layer_idx]\n",
    "            for block_idx, block in enumerate(layer.blocks):\n",
    "                h = block.attn.register_forward_hook(\n",
    "                    self._make_hook(layer_idx, block_idx, n_heads)\n",
    "                )\n",
    "                self.hooks.append(h)\n",
    "        print(f\"‚úÖ Registered {len(self.hooks)} hooks\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def clear(self):\n",
    "        self.head_outputs.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-head lists ‚Üí dict of tensors [N_samples, head_dim].\"\"\"\n",
    "        return {hid: torch.stack(vecs) for hid, vecs in self.head_outputs.items()}\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Extraction loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "head_extractor = HeadLevelExtractor(audio_encoder)\n",
    "head_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting heads\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "head_extractor.remove_hooks()\n",
    "head_outputs_final = head_extractor.finalize()\n",
    "\n",
    "# ‚îÄ‚îÄ Verify ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "sample_shape = head_outputs_final[list(head_outputs_final.keys())[0]].shape\n",
    "print(f\"\\n‚úÖ Head extraction complete\")\n",
    "print(f\"   Heads extracted : {len(head_outputs_final)}\")\n",
    "print(f\"   Shape per head  : {sample_shape}  (N_samples √ó head_dim)\")\n",
    "assert sample_shape[0] == N_SAMPLES, \"Sample count mismatch!\"\n",
    "assert sample_shape[1] == HEAD_DIM,  \"Head dim mismatch!\"\n",
    "\n",
    "# ‚îÄ‚îÄ Save ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_head_outputs_final.pt\"\n",
    "torch.save({\"head_outputs_final\": head_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved ‚Üí {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd388404",
   "metadata": {},
   "source": [
    "## Cell 4 ‚Äî Extractor 2: Per-Block Representations\n",
    "\n",
    "**What we compute.** For each `SwinTransformerBlock`, we capture the residual stream\n",
    "at the point between the attention sub-layer and the MLP sub-layer. Concretely, from\n",
    "the block forward pass:\n",
    "\n",
    "```python\n",
    "shortcut = x\n",
    "x = self.norm1(x)\n",
    "# ... window partition, W-MSA/SW-MSA, window reverse ...\n",
    "x = shortcut + self.drop_path(x)   # ‚Üê we capture HERE\n",
    "x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "```\n",
    "\n",
    "This corresponds to:\n",
    "\n",
    "$$\\mathbf{z}_b = x_{b,\\text{in}} + \\text{DropPath}(W^O \\cdot \\text{concat}_h(\\text{Attn}_h \\cdot V_h)) \\in \\mathbb{R}^{B \\times N_\\ell \\times D_\\ell}$$\n",
    "\n",
    "where $W^O$ is the output projection, $\\text{DropPath}$ is identity in eval mode,\n",
    "and $N_\\ell$, $D_\\ell$ are the token count and embedding dimension of stage $\\ell$.\n",
    "After mean-pooling over tokens:\n",
    "\n",
    "$$\\mathbf{r}_b^{\\text{block}} = \\frac{1}{N_\\ell} \\sum_{n=1}^{N_\\ell} \\mathbf{z}_b[:, n, :] \\in \\mathbb{R}^{D_\\ell}$$\n",
    "\n",
    "This is the most informative block-level representation because it includes $W^O$ and\n",
    "the residual connection, but excludes the MLP contribution, isolating the attention\n",
    "sub-layer's effect on the residual stream.\n",
    "\n",
    "Note that like per-layer, per-block vectors have **different dimensionalities** per stage\n",
    "($D_0=96$, $D_1=192$, $D_2=384$, $D_3=768$).\n",
    "\n",
    "**Requires a second forward pass** with hooks on `SwinTransformerBlock`.\n",
    "\n",
    "**Output.** 12 tensors of shape $[N_{\\text{samples}},\\, D_\\ell]$, one per block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d84828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered 12 block hooks (on norm2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771fb47497674474bb460cbf9c276bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting blocks:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Block extraction complete\n",
      "   Blocks extracted : 12\n",
      "   B0_L0: shape (2000, 96)  (expected D=96)  ‚úÖ\n",
      "   B1_L0: shape (2000, 96)  (expected D=96)  ‚úÖ\n",
      "   B0_L1: shape (2000, 192)  (expected D=192)  ‚úÖ\n",
      "   B1_L1: shape (2000, 192)  (expected D=192)  ‚úÖ\n",
      "   B0_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B1_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B2_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B3_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B4_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B5_L2: shape (2000, 384)  (expected D=384)  ‚úÖ\n",
      "   B0_L3: shape (2000, 768)  (expected D=768)  ‚úÖ\n",
      "   B1_L3: shape (2000, 768)  (expected D=768)  ‚úÖ\n",
      "   ‚úÖ All shapes verified\n",
      "   Saved ‚Üí heads_representations/esc50_block_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Block-level extractor: hooks on SwinTransformerBlock ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# We need to capture x AFTER the first residual addition but BEFORE the MLP.\n",
    "# SwinTransformerBlock.forward does not expose this intermediate value as a\n",
    "# module output, so we use a register_forward_hook on the norm2 layer, which\n",
    "# receives x at exactly that point: norm2 is called as self.norm2(x) where x\n",
    "# is already shortcut + drop_path(attn_out).\n",
    "# norm2 input == residual stream after attention, before MLP.\n",
    "\n",
    "class BlockLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per SwinTransformerBlock, targeting self.norm2.\n",
    "    norm2 receives x = shortcut + drop_path(attn_windows), which is exactly the\n",
    "    residual stream after the attention sub-layer and before the MLP sub-layer.\n",
    "    Mean-pools over the token dimension to get one vector per sample.\n",
    "    Output shape per block: [D_ell] = [96 * 2^layer_idx]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model         = model\n",
    "        self.block_outputs = defaultdict(list)  # block_id ‚Üí list of [D_ell] tensors\n",
    "        self.hooks         = []\n",
    "\n",
    "    def _make_hook(self, layer_idx, block_idx):\n",
    "        def hook(module, input, output):\n",
    "            # norm2 input[0]: [B, N_ell, D_ell]\n",
    "            # This is x = shortcut + drop_path(attn_out), i.e. post-attention\n",
    "            # pre-MLP residual stream. In eval mode drop_path is identity.\n",
    "            x_pre_mlp = input[0]                          # [B, N_ell, D_ell]\n",
    "            pooled = x_pre_mlp.mean(dim=1).squeeze(0).detach().cpu()  # [D_ell]\n",
    "            block_id = f\"B{block_idx}_L{layer_idx}\"\n",
    "            self.block_outputs[block_id].append(pooled)\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        global_block = 0\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            for block_idx, block in enumerate(layer.blocks):\n",
    "                h = block.norm2.register_forward_hook(\n",
    "                    self._make_hook(layer_idx, block_idx)\n",
    "                )\n",
    "                self.hooks.append(h)\n",
    "                global_block += 1\n",
    "        print(f\"‚úÖ Registered {len(self.hooks)} block hooks (on norm2)\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-block lists ‚Üí dict of tensors [N_samples, D_ell].\"\"\"\n",
    "        return {bid: torch.stack(vecs) for bid, vecs in self.block_outputs.items()}\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Extraction loop (second forward pass) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "block_extractor = BlockLevelExtractor(audio_encoder)\n",
    "block_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting blocks\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "block_extractor.remove_hooks()\n",
    "block_outputs_final = block_extractor.finalize()\n",
    "\n",
    "# ‚îÄ‚îÄ Verify ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"\\n‚úÖ Block extraction complete\")\n",
    "print(f\"   Blocks extracted : {len(block_outputs_final)}\")\n",
    "for key, tensor in block_outputs_final.items():\n",
    "    layer_idx = int(key.split(\"_L\")[1])\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    ok = tensor.shape == (N_SAMPLES, expected_dim)\n",
    "    print(f\"   {key}: shape {tuple(tensor.shape)}  (expected D={expected_dim})  {'‚úÖ' if ok else '‚ùå'}\")\n",
    "    assert tensor.shape[0] == N_SAMPLES, f\"Sample count mismatch for {key}\"\n",
    "    assert tensor.shape[1] == expected_dim, f\"Dim mismatch: got {tensor.shape[1]}, expected {expected_dim}\"\n",
    "\n",
    "assert len(block_outputs_final) == N_BLOCKS\n",
    "print(\"   ‚úÖ All shapes verified\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_block_outputs_final.pt\"\n",
    "torch.save({\"block_outputs_final\": block_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved ‚Üí {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94239907",
   "metadata": {},
   "source": [
    "## Cell 5 ‚Äî Extractor 3: Per-Layer Representations\n",
    "\n",
    "**What we compute.** For stage $\\ell$, we capture the output of `BasicLayer.forward`\n",
    "*after* all blocks, residual additions, and patch merging have been applied:\n",
    "\n",
    "$$x_\\ell = \\text{BasicLayer}_\\ell(x_{\\ell-1}) \\in \\mathbb{R}^{B \\times N_\\ell \\times D_\\ell}$$\n",
    "\n",
    "where $N_\\ell$ is the number of tokens after patch merging and $D_\\ell = 96 \\cdot 2^\\ell$.\n",
    "We then mean-pool over the token dimension to get a single vector per sample:\n",
    "\n",
    "$$\\mathbf{r}_\\ell^{\\text{layer}} = \\frac{1}{N_\\ell} \\sum_{n=1}^{N_\\ell} x_\\ell[:, n, :] \\in \\mathbb{R}^{D_\\ell}$$\n",
    "\n",
    "Note that unlike the per-head and per-block representations, the per-layer vectors\n",
    "have **different dimensionalities** across stages ($D_0=96$, $D_1=192$, $D_2=384$, $D_3=768$),\n",
    "because they capture the full layer output including $W^O$, MLP, residuals, and patch merging.\n",
    "This is the only granularity that captures the actual residual stream flowing between stages.\n",
    "\n",
    "**Requires a second forward pass** with hooks on `BasicLayer`, not derivable from\n",
    "`head_outputs_final` or `block_outputs_final`.\n",
    "\n",
    "**Output.** 4 tensors of shape $[N_{\\text{samples}},\\, D_\\ell]$, one per stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e5a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered 4 layer hooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c179346fbb4784be2dc0b8464cbda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting layers:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Layer extraction complete\n",
      "   Layers extracted : 4\n",
      "   L0: shape (2000, 192)  (expected D=96)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dim mismatch for L0: got 192, expected 96",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(tensor.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  (expected D=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tensor.shape[\u001b[32m0\u001b[39m] == N_SAMPLES, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample count mismatch for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tensor.shape[\u001b[32m1\u001b[39m] == expected_dim, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDim mismatch for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_outputs_final) == \u001b[38;5;28mlen\u001b[39m(HTSAT_DEPTHS)\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   ‚úÖ All shapes verified\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: Dim mismatch for L0: got 192, expected 96"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Layer-level extractor: hooks on BasicLayer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# BasicLayer.forward signature (from htsat.py):\n",
    "#   def forward(self, x) -> (x, attn)\n",
    "# where x after the call has shape [B, N_ell, D_ell], already including:\n",
    "#   - all SwinTransformerBlock residual additions (attention + MLP)\n",
    "#   - patch merging (PatchMerging) if layer_idx < 3\n",
    "# We hook the output of each BasicLayer to get the true inter-stage residual.\n",
    "\n",
    "class LayerLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per BasicLayer (stage).\n",
    "    Each hook captures the layer output x after all blocks and patch merging,\n",
    "    mean-pools over the token dimension, and stores the result.\n",
    "    Output shape per layer: [D_ell] = [96 * 2^layer_idx]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model         = model\n",
    "        self.layer_outputs = defaultdict(list)  # layer_id ‚Üí list of [D_ell] tensors\n",
    "        self.hooks         = []\n",
    "\n",
    "    def _make_hook(self, layer_idx):\n",
    "        def hook(module, input, output):\n",
    "            # BasicLayer returns (x, attn); x: [B, N_ell, D_ell]\n",
    "            x_out, _ = output\n",
    "            # Mean pool over token dimension ‚Üí [B, D_ell]\n",
    "            # B=1 since we process one sample at a time ‚Üí squeeze ‚Üí [D_ell]\n",
    "            pooled = x_out.mean(dim=1).squeeze(0).detach().cpu()\n",
    "            self.layer_outputs[f\"L{layer_idx}\"].append(pooled)\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            h = layer.register_forward_hook(self._make_hook(layer_idx))\n",
    "            self.hooks.append(h)\n",
    "        print(f\"‚úÖ Registered {len(self.hooks)} layer hooks\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-layer lists ‚Üí dict of tensors [N_samples, D_ell].\"\"\"\n",
    "        return {lid: torch.stack(vecs) for lid, vecs in self.layer_outputs.items()}\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Extraction loop (second forward pass) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "layer_extractor = LayerLevelExtractor(audio_encoder)\n",
    "layer_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting layers\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "layer_extractor.remove_hooks()\n",
    "layer_outputs_final = layer_extractor.finalize()\n",
    "\n",
    "# ‚îÄ‚îÄ Verify ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"\\n‚úÖ Layer extraction complete\")\n",
    "print(f\"   Layers extracted : {len(layer_outputs_final)}\")\n",
    "for key, tensor in layer_outputs_final.items():\n",
    "    layer_idx = int(key[1])\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    print(f\"   {key}: shape {tuple(tensor.shape)}  (expected D={expected_dim})\")\n",
    "    assert tensor.shape[0] == N_SAMPLES, f\"Sample count mismatch for {key}\"\n",
    "    assert tensor.shape[1] == expected_dim, f\"Dim mismatch for {key}: got {tensor.shape[1]}, expected {expected_dim}\"\n",
    "\n",
    "assert len(layer_outputs_final) == len(HTSAT_DEPTHS)\n",
    "print(\"   ‚úÖ All shapes verified\")\n",
    "\n",
    "# ‚îÄ‚îÄ Save ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_layer_outputs_final.pt\"\n",
    "torch.save({\"layer_outputs_final\": layer_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved ‚Üí {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd470a31",
   "metadata": {},
   "source": [
    "## Cell 6 ‚Äî Summary & Sanity Checks\n",
    "\n",
    "We verify the following:\n",
    "\n",
    "1. **Shape correctness**: each layer tensor has the expected dimensionality\n",
    "   $D_\\ell = 96 \\cdot 2^\\ell$ ($96, 192, 384, 768$ for $\\ell = 0,1,2,3$).\n",
    "\n",
    "2. **Fisher discriminability**: a quick per-key Fisher score\n",
    "   $F = \\overline{S_B / (S_W + \\varepsilon)}$\n",
    "   confirms that the extracted representations carry class-discriminative information\n",
    "   at all three granularities. Note that layer Fisher scores are not directly comparable\n",
    "   to head/block scores since the feature spaces have different dimensionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d63ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset  : ESC50\n",
      "Samples  : 2000\n",
      "Classes  : 50\n",
      "Device   : cpu\n",
      "\n",
      "Granularity  Keys     Shape per key\n",
      "------------------------------------------\n",
      "Head         184      (2000, 24)\n",
      "Block        12       (2000, 24)\n",
      "Layer        4        (2000, 24)\n",
      "\n",
      "üîç Consistency checks (layer mean ‚âà mean of block means):\n",
      "   L0: max abs diff = 0.00e+00  ‚úÖ\n",
      "   L1: max abs diff = 0.00e+00  ‚úÖ\n",
      "   L2: max abs diff = 0.00e+00  ‚úÖ\n",
      "   L3: max abs diff = 0.00e+00  ‚úÖ\n",
      "\n",
      "üìä Quick Fisher discriminability (mean across keys per granularity):\n",
      "   Head  ‚Äî mean F = 0.8749  min=0.3093  max=2.7675\n",
      "   Block ‚Äî mean F = 0.8597  min=0.5664  max=1.4130\n",
      "   Layer ‚Äî mean F = 0.9850  min=0.6843  max=1.2716\n",
      "\n",
      "‚úÖ All files saved in 'heads_representations/':\n",
      "   esc50_head_outputs_final.pt\n",
      "   esc50_block_outputs_final.pt\n",
      "   esc50_layer_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset  : {DATASET.__name__}\")\n",
    "print(f\"Samples  : {N_SAMPLES}\")\n",
    "print(f\"Classes  : {len(dataset.classes)}\")\n",
    "print(f\"Device   : {device}\")\n",
    "\n",
    "print(f\"\\n{'Granularity':<12} {'Keys':<8} {'Shape per key'}\")\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'Head':<12} {len(head_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(head_outputs_final.values())).shape)}\")\n",
    "print(f\"{'Block':<12} {len(block_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(block_outputs_final.values())).shape)}\")\n",
    "print(f\"{'Layer':<12} {len(layer_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(layer_outputs_final.values())).shape)}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Shape checks for layer outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nüîç Layer output shape checks:\")\n",
    "for layer_idx in range(len(HTSAT_DEPTHS)):\n",
    "    key = f\"L{layer_idx}\"\n",
    "    tensor = layer_outputs_final[key]\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    ok = tensor.shape == (N_SAMPLES, expected_dim)\n",
    "    print(f\"   {key}: {tuple(tensor.shape)}  expected ({N_SAMPLES}, {expected_dim})  {'‚úÖ' if ok else '‚ùå'}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Quick Fisher score check across granularities ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def fisher_score(X, y):\n",
    "    \"\"\"Diagonal Fisher criterion: mean(S_B / (S_W + eps)).\"\"\"\n",
    "    classes   = np.unique(y)\n",
    "    mu_global = X.mean(axis=0)\n",
    "    S_B = np.zeros(X.shape[1])\n",
    "    S_W = np.zeros(X.shape[1])\n",
    "    for c in classes:\n",
    "        Xc   = X[y == c]\n",
    "        mu_c = Xc.mean(axis=0)\n",
    "        S_B += len(Xc) * (mu_c - mu_global) ** 2\n",
    "        S_W += ((Xc - mu_c) ** 2).sum(axis=0)\n",
    "    return float((S_B / (S_W + 1e-8)).mean())\n",
    "\n",
    "print(\"\\nüìä Quick Fisher discriminability per key:\")\n",
    "print(\"   Note: block/layer scores are not directly comparable to head scores\")\n",
    "print(\"   since they operate in different-dimensional spaces (D_ell vs 24).\\n\")\n",
    "\n",
    "print(f\"   {'Key':<20} {'F':>8}  {'dim':>6}\")\n",
    "print(\"   \" + \"-\" * 38)\n",
    "\n",
    "for hid in sorted(head_outputs_final.keys()):\n",
    "    f = fisher_score(head_outputs_final[hid].numpy(), sample_labels)\n",
    "    dim = head_outputs_final[hid].shape[1]\n",
    "    print(f\"   {hid:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print()\n",
    "for bk in sorted(block_outputs_final.keys()):\n",
    "    f = fisher_score(block_outputs_final[bk].numpy(), sample_labels)\n",
    "    dim = block_outputs_final[bk].shape[1]\n",
    "    print(f\"   {bk:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print()\n",
    "for lk in sorted(layer_outputs_final.keys()):\n",
    "    f = fisher_score(layer_outputs_final[lk].numpy(), sample_labels)\n",
    "    dim = layer_outputs_final[lk].shape[1]\n",
    "    print(f\"   {lk:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All files saved in '{SAVE_DIR}/':\")\n",
    "print(f\"   {DATASET.__name__.lower()}_head_outputs_final.pt\")\n",
    "print(f\"   {DATASET.__name__.lower()}_block_outputs_final.pt\")\n",
    "print(f\"   {DATASET.__name__.lower()}_layer_outputs_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac21ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
