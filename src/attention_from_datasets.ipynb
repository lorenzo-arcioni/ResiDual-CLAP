{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fabed8",
   "metadata": {},
   "source": [
    "# Multi-Granularity Representation Extraction for HTS-AT\n",
    "\n",
    "This notebook extracts attention representations at three granularities:\n",
    "\n",
    "1. **Per-head**: $\\text{Attn} \\cdot V$ pre-projection $W^O$, for each of the 184 heads individually.\n",
    "2. **Per-block**: mean of head representations within the same Swin block.\n",
    "3. **Per-layer**: mean of block representations within the same HTS-AT stage.\n",
    "\n",
    "## Architecture Recap\n",
    "\n",
    "HTS-AT has 4 stages (layers), 12 blocks total, 184 heads total:\n",
    "\n",
    "| Stage | Blocks | Heads/block | $d_h$ | $D_\\ell = H_\\ell \\cdot d_h$ |\n",
    "|-------|--------|-------------|-------|---------------------------|\n",
    "| L0    | 2      | 4           | 24    | 96                        |\n",
    "| L1    | 2      | 8           | 24    | 192                       |\n",
    "| L2    | 6      | 16          | 24    | 384                       |\n",
    "| L3    | 2      | 32          | 24    | 768                       |\n",
    "\n",
    "Note that $d_h = 24$ is constant across all stages since $d_h = D_\\ell / H_\\ell = (96 \\cdot 2^\\ell) / (4 \\cdot 2^\\ell) = 24$.\n",
    "\n",
    "## What We Extract (Pre-Projection)\n",
    "\n",
    "For each head $h$ in block $b$ of layer $\\ell$, we capture:\n",
    "\n",
    "$$\\mathbf{H}_{\\ell,b,h} = \\text{Attn}_{\\ell,b,h} \\cdot V_{\\ell,b,h} \\in \\mathbb{R}^{N_W \\cdot B \\times M \\times d_h}$$\n",
    "\n",
    "where $N_W$ is the number of spatial windows and $M = w^2 = 64$ tokens per window.\n",
    "We then spatial mean-pool to obtain a single vector per sample:\n",
    "\n",
    "$$\\mathbf{r}_{\\ell,b,h} = \\frac{1}{N_W M} \\sum_{i=1}^{N_W} \\sum_{j=1}^{M} \\mathbf{H}_{\\ell,b,h}[i,j,:] \\in \\mathbb{R}^{24}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f238021",
   "metadata": {},
   "source": [
    "## Cell 0 â€” Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c4b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from CLAPWrapper import CLAPWrapper\n",
    "from datasets.esc50 import ESC50\n",
    "from datasets.tinysol import TinySOL\n",
    "from datasets.vocalsound import VocalSound\n",
    "\n",
    "# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATASET     = ESC50          # â† change to TinySOL or VocalSound as needed\n",
    "DATA_ROOT   = '../data'\n",
    "BATCH_SIZE  = 1              # process one sample at a time (safest for hook logic)\n",
    "SAVE_DIR    = 'heads_representations'\n",
    "\n",
    "# HTS-AT constants (fixed by architecture)\n",
    "HTSAT_DEPTHS = [2, 2, 6, 2]   # blocks per stage\n",
    "HTSAT_HEADS  = [4, 8, 16, 32] # attention heads per stage\n",
    "HTSAT_EMBED  = 96             # base embedding dim\n",
    "HEAD_DIM     = 24             # head_dim = layer_dim / n_heads = constant = 24\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c174e",
   "metadata": {},
   "source": [
    "## Cell 1 â€” Load Dataset & Model\n",
    "\n",
    "Access path through CLAP's module hierarchy:\n",
    "`CLAPWrapper` $\\to$ `CLAP` $\\to$ `AudioEncoder.base` $\\to$ `HTSATWrapper.htsat`\n",
    "\n",
    "We also build here the `block_info_df` table that maps every global block index\n",
    "$b \\in \\{0, \\ldots, 11\\}$ to its stage $\\ell$ and intra-stage position.\n",
    "This table is shared by all three extraction cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83f2af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 13695.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset : 2000 samples, 50 classes\n",
      "   Classes  : ['airplane', 'breathing', 'brushing teeth', 'can opening', 'car horn']... (+45 more)\n",
      "\n",
      "Loading CLAP ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "\n",
      "âœ… CLAP model loaded in eval mode\n",
      "   Stages  : 4\n",
      "   Depths  : [2, 2, 6, 2]\n",
      "   Heads   : [4, 8, 16, 32]\n",
      "   Embed   : 96\n",
      "\n",
      "   Total blocks : 12\n",
      "   Total heads  : 184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_block</th>\n",
       "      <th>layer</th>\n",
       "      <th>block_in_layer</th>\n",
       "      <th>n_heads</th>\n",
       "      <th>layer_dim</th>\n",
       "      <th>head_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>768</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>768</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_block  layer  block_in_layer  n_heads  layer_dim  head_dim\n",
       "0              0      0               0        4         96        24\n",
       "1              1      0               1        4         96        24\n",
       "2              2      1               0        8        192        24\n",
       "3              3      1               1        8        192        24\n",
       "4              4      2               0       16        384        24\n",
       "5              5      2               1       16        384        24\n",
       "6              6      2               2       16        384        24\n",
       "7              7      2               3       16        384        24\n",
       "8              8      2               4       16        384        24\n",
       "9              9      2               5       16        384        24\n",
       "10            10      3               0       32        768        24\n",
       "11            11      3               1       32        768        24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Dataset\n",
    "dataset = DATASET(root=DATA_ROOT, download=False)\n",
    "print(f\"ğŸ“Š Dataset : {len(dataset)} samples, {len(dataset.classes)} classes\")\n",
    "print(f\"   Classes  : {dataset.classes[:5]}... (+{len(dataset.classes)-5} more)\")\n",
    "\n",
    "# CLAP model\n",
    "print(\"\\nLoading CLAP ...\", end='')\n",
    "wrapper       = CLAPWrapper(version='2023', use_cuda=torch.cuda.is_available())\n",
    "clap_model    = wrapper.clap\n",
    "clap_model.eval()\n",
    "\n",
    "# The HTS-AT Swin transformer inside CLAP\n",
    "# Access path: CLAPWrapper.clap  â†’  CLAP  â†’  AudioEncoder.base  â†’  HTSATWrapper.htsat\n",
    "audio_encoder = clap_model.audio_encoder.base.htsat\n",
    "audio_encoder.eval()\n",
    "\n",
    "print('OK')\n",
    "\n",
    "print(f\"\\nâœ… CLAP model loaded in eval mode\")\n",
    "print(f\"   Stages  : {audio_encoder.num_layers}\")\n",
    "print(f\"   Depths  : {audio_encoder.depths}\")\n",
    "print(f\"   Heads   : {audio_encoder.num_heads}\")\n",
    "print(f\"   Embed   : {audio_encoder.embed_dim}\")\n",
    "\n",
    "# Build global block index table (used by all three extractors)\n",
    "block_info = []\n",
    "global_block = 0\n",
    "for layer_idx, (depth, n_heads) in enumerate(zip(HTSAT_DEPTHS, HTSAT_HEADS)):\n",
    "    layer_dim = HTSAT_EMBED * (2 ** layer_idx)\n",
    "    for block_idx in range(depth):\n",
    "        block_info.append({\n",
    "            'global_block': global_block,\n",
    "            'layer': layer_idx,\n",
    "            'block_in_layer': block_idx,\n",
    "            'n_heads': n_heads,\n",
    "            'layer_dim': layer_dim,\n",
    "            'head_dim': HEAD_DIM,\n",
    "        })\n",
    "        global_block += 1\n",
    "\n",
    "block_info_df = pd.DataFrame(block_info)\n",
    "N_BLOCKS = len(block_info_df)\n",
    "N_HEADS_TOTAL = sum(d * h for d, h in zip(HTSAT_DEPTHS, HTSAT_HEADS))\n",
    "print(f\"\\n   Total blocks : {N_BLOCKS}\")\n",
    "print(f\"   Total heads  : {N_HEADS_TOTAL}\")\n",
    "display(block_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643c9ec",
   "metadata": {},
   "source": [
    "## Cell 2 â€” Build Stratified Sample List\n",
    "\n",
    "We collect exactly $\\lfloor N / C \\rfloor$ samples per class, where $N$ is the total\n",
    "dataset size and $C$ the number of classes. Samples are sorted by class index to ensure\n",
    "a deterministic ordering that is consistent across all three extraction cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9336e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: 40\n",
      "âœ… 2000 samples collected, 50 classes covered\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling: equal samples per class\n",
    "samples_per_class = len(dataset) // len(dataset.classes)\n",
    "print(f\"Samples per class: {samples_per_class}\")\n",
    "\n",
    "class_buckets = defaultdict(list)\n",
    "for idx in range(len(dataset)):\n",
    "    audio_path, class_name, one_hot = dataset[idx]\n",
    "    class_idx = torch.argmax(one_hot).item()\n",
    "    if len(class_buckets[class_idx]) < samples_per_class:\n",
    "        class_buckets[class_idx].append((audio_path, class_idx))\n",
    "    if (len(class_buckets) == len(dataset.classes) and\n",
    "            all(len(v) >= samples_per_class for v in class_buckets.values())):\n",
    "        break\n",
    "\n",
    "# Flatten sorted by class index â†’ deterministic ordering\n",
    "sample_list = []\n",
    "\n",
    "for class_idx in sorted(class_buckets.keys()):\n",
    "    sample_list.extend(class_buckets[class_idx])\n",
    "\n",
    "sample_labels = np.array([label for _, label in sample_list])\n",
    "N_SAMPLES     = len(sample_list)\n",
    "\n",
    "print(f\"âœ… {N_SAMPLES} samples collected, {len(class_buckets)} classes covered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05159517",
   "metadata": {},
   "source": [
    "## Cell 3 â€” Extractor 1: Per-Head Representations\n",
    "\n",
    "**What we capture.** For each head $h$ in block $b$ of layer $\\ell$:\n",
    "\n",
    "$$\\mathbf{r}_{\\ell,b,h} = \\frac{1}{N_W M}\\sum_{i,j} (\\text{Attn}_{\\ell,b,h} \\cdot V_{\\ell,b,h})[i,j,:] \\in \\mathbb{R}^{24}$$\n",
    "\n",
    "This is computed *before* the output projection $W^O$. After $W^O$ the $H_\\ell$ heads\n",
    "are linearly mixed into a single $D_\\ell$-dimensional vector, destroying individual\n",
    "head structure. Pre-projection is therefore the only point where per-head subspaces\n",
    "are still disentangled.\n",
    "\n",
    "**Hook target.** We register one `register_forward_hook` on `WindowAttention` inside\n",
    "each `SwinTransformerBlock`. The hook:\n",
    "\n",
    "1. Reads `input[0]` â€” the windowed token sequence $\\in \\mathbb{R}^{N_W B \\times M \\times D_\\ell}$.\n",
    "2. Re-computes $Q, K, V$ by passing the input through `module.qkv` (no grad).\n",
    "3. Computes $\\text{Attn}_{h} \\cdot V_h$ for each head $h$ without going through `proj` or `proj_drop`.\n",
    "4. Mean-pools over $(N_W B, M)$ to obtain $\\mathbf{r}_{\\ell,b,h} \\in \\mathbb{R}^{24}$.\n",
    "\n",
    "**Output.** 184 tensors of shape $[N_{\\text{samples}},\\, 24]$, one per head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfb086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Registered 12 hooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acefa7e6ceb24d15b5c0619a0419a536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting heads:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Head extraction complete\n",
      "   Heads extracted : 184\n",
      "   Shape per head  : torch.Size([2000, 24])  (N_samples Ã— head_dim)\n",
      "   Saved â†’ heads_representations/esc50_head_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "class HeadLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per SwinTransformerBlock attention module.\n",
    "    Each hook:\n",
    "      1. Re-computes QKV from the attention input (no grad).\n",
    "      2. Computes attn @ V for each head â†’ shape [nW*B, N, head_dim].\n",
    "      3. Mean-pools over (nW*B, N) â†’ shape [head_dim].\n",
    "      4. Appends the pooled vector to head_outputs[head_id].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model       = model\n",
    "        self.head_outputs = defaultdict(list)  # head_id â†’ list of [head_dim] tensors\n",
    "        self.hooks        = []\n",
    "\n",
    "    # â”€â”€ hook factory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def _make_hook(self, layer_idx, block_idx, n_heads):\n",
    "        def hook(module, input, output):\n",
    "            # input[0]: [nW*B, N, C]  where C = layer_dim, N = window_size^2\n",
    "            x_in        = input[0]                          # [nW*B, N, C]\n",
    "            _, attn_w   = output                            # attn_w: [nW*B, n_heads, N, N]\n",
    "            nWB, N, C   = x_in.shape\n",
    "            head_dim    = C // n_heads\n",
    "\n",
    "            # Re-compute QKV (no grad, same weights as forward pass)\n",
    "            with torch.no_grad():\n",
    "                qkv = module.qkv(x_in)                     # [nW*B, N, 3*C]\n",
    "            qkv = qkv.reshape(nWB, N, 3, n_heads, head_dim).permute(2, 0, 3, 1, 4)\n",
    "            # q, k, v: [nW*B, n_heads, N, head_dim]\n",
    "            v = qkv[2]\n",
    "\n",
    "            for h in range(n_heads):\n",
    "                # attn_w[:, h]: [nW*B, N, N]\n",
    "                # v[:, h]:      [nW*B, N, head_dim]\n",
    "                head_out = torch.matmul(attn_w[:, h], v[:, h])  # [nW*B, N, head_dim]\n",
    "                # Global spatial mean-pool â†’ [head_dim]\n",
    "                pooled   = head_out.mean(dim=[0, 1]).detach().cpu()\n",
    "                head_id  = f\"L{layer_idx}_B{block_idx}_H{h}\"\n",
    "                self.head_outputs[head_id].append(pooled)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    # â”€â”€ registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def register_hooks(self):\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            n_heads = self.model.num_heads[layer_idx]\n",
    "            for block_idx, block in enumerate(layer.blocks):\n",
    "                h = block.attn.register_forward_hook(\n",
    "                    self._make_hook(layer_idx, block_idx, n_heads)\n",
    "                )\n",
    "                self.hooks.append(h)\n",
    "        print(f\"âœ… Registered {len(self.hooks)} hooks\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def clear(self):\n",
    "        self.head_outputs.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-head lists â†’ dict of tensors [N_samples, head_dim].\"\"\"\n",
    "        return {hid: torch.stack(vecs) for hid, vecs in self.head_outputs.items()}\n",
    "\n",
    "\n",
    "# â”€â”€ Extraction loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "head_extractor = HeadLevelExtractor(audio_encoder)\n",
    "head_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting heads\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "head_extractor.remove_hooks()\n",
    "head_outputs_final = head_extractor.finalize()\n",
    "\n",
    "# â”€â”€ Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sample_shape = head_outputs_final[list(head_outputs_final.keys())[0]].shape\n",
    "print(f\"\\nâœ… Head extraction complete\")\n",
    "print(f\"   Heads extracted : {len(head_outputs_final)}\")\n",
    "print(f\"   Shape per head  : {sample_shape}  (N_samples Ã— head_dim)\")\n",
    "assert sample_shape[0] == N_SAMPLES, \"Sample count mismatch!\"\n",
    "assert sample_shape[1] == HEAD_DIM,  \"Head dim mismatch!\"\n",
    "\n",
    "# â”€â”€ Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_head_outputs_final.pt\"\n",
    "torch.save({\"head_outputs_final\": head_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved â†’ {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2175f",
   "metadata": {},
   "source": [
    "## Cell 3b â€” Extractor 1b: Per-Head Representations (Post-Projection $\\widehat{\\mathbf{H}}$)\n",
    "\n",
    " ### What we extract\n",
    "\n",
    " For each head $h$ in block $b$ of stage $\\ell$, we compute the\n",
    " **per-head projected contribution** to the residual stream:\n",
    "\n",
    " $$\\widehat{\\mathbf{H}}_{\\ell,b,h}\n",
    "   = \\mathbf{H}_{\\ell,b,h}\\,W^O_{\\ell,b,h} + \\frac{\\mathbf{b}^O_{\\ell,b}}{H_\\ell}\n",
    "   \\in \\mathbb{R}^{N_w^\\ell \\times M \\times D_\\ell}$$\n",
    "\n",
    " where:\n",
    " - $\\mathbf{H}_{\\ell,b,h} \\in \\mathbb{R}^{N_w^\\ell \\times M \\times d_h}$ is the raw\n",
    "   per-head attention output (same as in Cell 3, pre-$W^O$);\n",
    " - $W^O_{\\ell,b,h} \\in \\mathbb{R}^{d_h \\times D_\\ell}$ is the row slice of the output\n",
    "   projection `self.proj.weight` corresponding to head $h$, i.e. columns\n",
    "   $[h \\cdot d_h,\\; (h+1) \\cdot d_h)$ of `self.proj.weight` $\\in \\mathbb{R}^{D_\\ell \\times D_\\ell}$\n",
    "   (recall that `nn.Linear` stores weights as `[out, in]`, so the head slice is\n",
    "   `module.proj.weight[:, h*dh:(h+1)*dh]`, shape `[D_ell, dh]`);\n",
    " - $\\mathbf{b}^O_{\\ell,b} \\in \\mathbb{R}^{D_\\ell}$ is the bias of `self.proj`,\n",
    "   distributed equally over the $H_\\ell$ heads.\n",
    "\n",
    " We then spatial mean-pool to obtain one vector per sample:\n",
    "\n",
    " $$\\widehat{\\mathbf{r}}_{\\ell,b,h}\n",
    "   = \\frac{1}{N_w^\\ell M}\n",
    "     \\sum_{i=1}^{N_w^\\ell}\\sum_{j=1}^{M}\n",
    "     \\widehat{\\mathbf{H}}_{\\ell,b,h}[i,j,:]\n",
    "   \\in \\mathbb{R}^{D_\\ell}$$\n",
    "\n",
    " ### Why post-projection\n",
    "\n",
    " $\\widehat{\\mathbf{H}}_{\\ell,b,h}$ lives in the full residual-stream space\n",
    " $\\mathbb{R}^{D_\\ell}$ and is the quantity that additively contributes to\n",
    " $\\mathbf{Z}^{(\\ell,b)}$ (see Eq. (head_decomp) in the paper). This is the\n",
    " natural object for analysing how each head shapes the residual stream,\n",
    " and is the basis for the ResiDual reweighting strategy.\n",
    " Note that $D_\\ell$ varies across stages ($96, 192, 384, 768$), so\n",
    " $\\widehat{\\mathbf{r}}_{\\ell,b,h}$ from different stages live in spaces of\n",
    " different ambient dimension and are not directly comparable.\n",
    "\n",
    " ### Hook target\n",
    "\n",
    " Same as Cell 3: we register one hook on `block.attn` (`WindowAttention`).\n",
    " From the hook we reuse the same $\\mathbf{H}_{\\ell,b,h}$ computation\n",
    " (attn_w @ V per head), then immediately apply the head-slice projection\n",
    " using the stored `module.proj.weight` and `module.proj.bias`.\n",
    " No second forward pass is needed.\n",
    "\n",
    " ### Output\n",
    "\n",
    " 184 tensors of shape $[N_{\\text{samples}},\\, D_\\ell]$, one per head.\n",
    " Contrary to the pre-projection case (Cell 3), the feature dimension is\n",
    " **not constant**: it equals $D_\\ell = 96 \\cdot 2^\\ell$ for heads in stage $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93bfbc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Registered 12 post-projection hooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c178495494a497d8fae04b0b264c1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting post-proj heads:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Post-projection head extraction complete\n",
      "   Heads extracted : 184\n",
      "   âœ… All shapes verified  (D_ell per stage: [96, 192, 384, 768])\n",
      "   Saved â†’ heads_representations/esc50_postproj_head_outputs.pt\n"
     ]
    }
   ],
   "source": [
    "class PostProjHeadExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per WindowAttention module.\n",
    "    Each hook:\n",
    "      1. Reads attn_w from output[1]:  [nW, H, M, M]  (post-softmax, with mask).\n",
    "      2. Re-computes V from input[0] via module.qkv:  [nW, H, M, dh].\n",
    "      3. Computes H_{l,b,h} = attn_w[:, h] @ V[:, h]:  [nW, M, dh].\n",
    "      4. Projects via head slice of W^O:\n",
    "             Hhat = H_{l,b,h} @ W^O_{l,b,h}.T + b^O / H_ell\n",
    "         where W^O_{l,b,h} = module.proj.weight[:, h*dh:(h+1)*dh]  [D_ell, dh]\n",
    "         result shape: [nW, M, D_ell].\n",
    "      5. Mean-pools over (nW, M) -> [D_ell].\n",
    "      6. Appends to head_outputs[head_id].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model        = model\n",
    "        self.head_outputs = defaultdict(list)   # head_id -> list of [D_ell] tensors\n",
    "        self.hooks        = []\n",
    "\n",
    "    # â”€â”€ hook factory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def _make_hook(self, layer_idx, block_idx, n_heads):\n",
    "        def hook(module, input, output):\n",
    "            x_in      = input[0]                    # [nW, M, D_ell]  (windowed tokens)\n",
    "            attn_w    = output[1]                   # [nW, H, M, M]   (post-softmax)\n",
    "            nW, M, D  = x_in.shape\n",
    "            dh        = D // n_heads\n",
    "\n",
    "            # â”€â”€ Re-compute V (no grad, same weights as the forward pass) â”€â”€â”€â”€â”€â”€\n",
    "            with torch.no_grad():\n",
    "                qkv = module.qkv(x_in)             # [nW, M, 3*D]\n",
    "            qkv = qkv.reshape(nW, M, 3, n_heads, dh).permute(2, 0, 3, 1, 4)\n",
    "            # qkv[i]: [nW, H, M, dh]\n",
    "            v = qkv[2]                              # [nW, H, M, dh]\n",
    "\n",
    "            # â”€â”€ W^O slice and bias for this block â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            # module.proj is nn.Linear(D, D); .weight shape [D, D] (out x in).\n",
    "            # Head h occupies INPUT columns [h*dh : (h+1)*dh].\n",
    "            W_O   = module.proj.weight             # [D_ell, D_ell]\n",
    "            b_O   = module.proj.bias               # [D_ell]\n",
    "\n",
    "            # â”€â”€ Per-head projection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            for h in range(n_heads):\n",
    "                # Raw head output: [nW, M, dh]\n",
    "                H_h = torch.matmul(attn_w[:, h], v[:, h])  # [nW, M, dh]\n",
    "\n",
    "                # Head slice of W^O: columns [h*dh : (h+1)*dh] -> [D_ell, dh]\n",
    "                W_O_h = W_O[:, h * dh : (h + 1) * dh]      # [D_ell, dh]\n",
    "\n",
    "                # Ä¤_{l,b,h} = H_h @ W_O_h.T + b_O / H_ell  -> [nW, M, D_ell]\n",
    "                Hhat_h = H_h @ W_O_h.t() + b_O / n_heads   # broadcast over [nW, M]\n",
    "\n",
    "                # Spatial mean-pool: average over windows and token positions -> [D_ell]\n",
    "                pooled = Hhat_h.mean(dim=[0, 1]).detach().cpu()\n",
    "\n",
    "                head_id = f\"L{layer_idx}_B{block_idx}_H{h}\"\n",
    "                self.head_outputs[head_id].append(pooled)\n",
    "\n",
    "        return hook\n",
    "\n",
    "    # â”€â”€ registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def register_hooks(self):\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            n_heads = self.model.num_heads[layer_idx]\n",
    "            for block_idx, block in enumerate(layer.blocks):\n",
    "                h = block.attn.register_forward_hook(\n",
    "                    self._make_hook(layer_idx, block_idx, n_heads)\n",
    "                )\n",
    "                self.hooks.append(h)\n",
    "        print(f\"âœ… Registered {len(self.hooks)} post-projection hooks\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def clear(self):\n",
    "        self.head_outputs.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-head lists -> dict of tensors [N_samples, D_ell].\"\"\"\n",
    "        return {hid: torch.stack(vecs) for hid, vecs in self.head_outputs.items()}\n",
    "\n",
    "\n",
    "# â”€â”€ Extraction loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "postproj_extractor = PostProjHeadExtractor(audio_encoder)\n",
    "postproj_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting post-proj heads\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "postproj_extractor.remove_hooks()\n",
    "postproj_head_outputs = postproj_extractor.finalize()\n",
    "\n",
    "# â”€â”€ Verify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nâœ… Post-projection head extraction complete\")\n",
    "print(f\"   Heads extracted : {len(postproj_head_outputs)}\")\n",
    "assert len(postproj_head_outputs) == N_HEADS_TOTAL, \"Head count mismatch!\"\n",
    "\n",
    "for layer_idx, (depth, n_heads) in enumerate(zip(HTSAT_DEPTHS, HTSAT_HEADS)):\n",
    "    D_ell = HTSAT_EMBED * (2 ** layer_idx)\n",
    "    for block_idx in range(depth):\n",
    "        for h in range(n_heads):\n",
    "            head_id = f\"L{layer_idx}_B{block_idx}_H{h}\"\n",
    "            tensor  = postproj_head_outputs[head_id]\n",
    "            ok      = tensor.shape == (N_SAMPLES, D_ell)\n",
    "            if not ok:\n",
    "                print(f\"   âŒ {head_id}: shape {tuple(tensor.shape)}, \"\n",
    "                      f\"expected ({N_SAMPLES}, {D_ell})\")\n",
    "            assert ok, f\"Shape mismatch for {head_id}\"\n",
    "\n",
    "print(f\"   âœ… All shapes verified  \"\n",
    "      f\"(D_ell per stage: {[HTSAT_EMBED * 2**l for l in range(4)]})\")\n",
    "\n",
    "# â”€â”€ Quick sanity: sum of head contributions â‰ˆ W-MSA output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# For a random block, verify that sum_h Ä¤_{l,b,h} â‰ˆ A_{l,b}\n",
    "# by comparing against the block-level extraction from Cell 4.\n",
    "# (Optional check â€” comment out if block_outputs_final is not yet available.)\n",
    "\n",
    "# â”€â”€ Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_postproj_head_outputs.pt\"\n",
    "torch.save(\n",
    "    {\"postproj_head_outputs\": postproj_head_outputs, \"labels\": sample_labels},\n",
    "    save_path\n",
    ")\n",
    "print(f\"   Saved â†’ {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd388404",
   "metadata": {},
   "source": [
    "## Cell 4 â€” Extractors 2 & 3: Per-Block and Per-Layer Representations\n",
    "\n",
    "This cell defines both `BlockLevelExtractor` and `LayerLevelExtractor`, registers\n",
    "their hooks simultaneously, and runs **a single forward pass** to populate both.\n",
    "\n",
    "### Block-level\n",
    "\n",
    "For each `SwinTransformerBlock` we capture the residual stream at the point between\n",
    "the attention sub-layer and the MLP sub-layer. In the block forward pass:\n",
    "\n",
    "```python\n",
    "shortcut = x\n",
    "x = self.norm1(x)\n",
    "# ... window partition, W-MSA/SW-MSA, window reverse ...\n",
    "x = shortcut + self.drop_path(x)   # â† BLOCK hook: input to norm2 = this x\n",
    "x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "```\n",
    "\n",
    "Hook target: `block.norm2` â€” its `input[0]` is exactly the residual after\n",
    "attention and the first skip connection, before the MLP acts. This corresponds to:\n",
    "\n",
    "$$\\mathbf{z}_b = x_{b,\\text{in}} + \\text{DropPath}(W^O \\cdot \\text{concat}_h(\\text{Attn}_h \\cdot V_h)) \\in \\mathbb{R}^{B \\times N_\\ell \\times D_\\ell}$$\n",
    "\n",
    "After mean-pooling: $\\mathbf{r}_b^{\\text{block}} = \\frac{1}{N_\\ell} \\sum_n \\mathbf{z}_b[:, n, :] \\in \\mathbb{R}^{D_\\ell}$\n",
    "\n",
    "**Output.** 12 tensors of shape $[N_{\\text{samples}},\\, D_\\ell]$, one per block,\n",
    "with $D_\\ell \\in \\{96, 192, 384, 768\\}$ depending on the stage.\n",
    "\n",
    "### Layer-level\n",
    "\n",
    "For each stage $\\ell$ we capture the output of its **last** `SwinTransformerBlock`,\n",
    "after both sub-layers (attention + MLP) but **before** `PatchMerging`. Excluding\n",
    "`PatchMerging` is consistent with ResiDual (Basile et al., 2025): it is a spatial\n",
    "downsampling operation, not part of the residual stream, and would mix the signal\n",
    "with a spatial reorganisation. Hook target: `layer.blocks[-1]` â€” its `output[0]`\n",
    "is the full residual stream after all blocks of the stage:\n",
    "\n",
    "$$\\mathbf{r}_\\ell^{\\text{layer}} = \\frac{1}{N_\\ell} \\sum_{n=1}^{N_\\ell} \\mathbf{z}_\\ell[:, n, :] \\in \\mathbb{R}^{D_\\ell}$$\n",
    "\n",
    "**Output.** 4 tensors of shape $[N_{\\text{samples}},\\, D_\\ell]$, one per stage,\n",
    "with $D_\\ell \\in \\{96, 192, 384, 768\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d84828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Registered 12 block hooks (on norm2)\n",
      "âœ… Registered 4 layer hooks (on last block of each stage)\n",
      "   L0: hooked block 1 of 2 (depth=2)\n",
      "   L1: hooked block 1 of 2 (depth=2)\n",
      "   L2: hooked block 5 of 6 (depth=6)\n",
      "   L3: hooked block 1 of 2 (depth=2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a87c084ac42f8816a42e67d08ca6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting blocks + layers:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Block extraction complete\n",
      "   Blocks extracted : 12\n",
      "   B0_L0: shape (2000, 96)  (expected D=96)  âœ…\n",
      "   B1_L0: shape (2000, 96)  (expected D=96)  âœ…\n",
      "   B0_L1: shape (2000, 192)  (expected D=192)  âœ…\n",
      "   B1_L1: shape (2000, 192)  (expected D=192)  âœ…\n",
      "   B0_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B1_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B2_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B3_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B4_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B5_L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   B0_L3: shape (2000, 768)  (expected D=768)  âœ…\n",
      "   B1_L3: shape (2000, 768)  (expected D=768)  âœ…\n",
      "   âœ… All block shapes verified\n",
      "\n",
      "âœ… Layer extraction complete\n",
      "   Layers extracted : 4\n",
      "   L0: shape (2000, 96)  (expected D=96)  âœ…\n",
      "   L1: shape (2000, 192)  (expected D=192)  âœ…\n",
      "   L2: shape (2000, 384)  (expected D=384)  âœ…\n",
      "   L3: shape (2000, 768)  (expected D=768)  âœ…\n",
      "   âœ… All layer shapes verified\n",
      "   Saved â†’ heads_representations/esc50_block_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Block-level extractor: hooks on SwinTransformerBlock â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# We need to capture x AFTER the first residual addition but BEFORE the MLP.\n",
    "# SwinTransformerBlock.forward does not expose this intermediate value as a\n",
    "# module output, so we use a register_forward_hook on the norm2 layer, which\n",
    "# receives x at exactly that point: norm2 is called as self.norm2(x) where x\n",
    "# is already shortcut + drop_path(attn_out).\n",
    "# norm2 input == residual stream after attention, before MLP.\n",
    "\n",
    "class BlockLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per SwinTransformerBlock, targeting self.norm2.\n",
    "    norm2 receives x = shortcut + drop_path(attn_windows), which is exactly the\n",
    "    residual stream after the attention sub-layer and before the MLP sub-layer.\n",
    "    Mean-pools over the token dimension to get one vector per sample.\n",
    "    Output shape per block: [D_ell] = [96 * 2^layer_idx]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model         = model\n",
    "        self.block_outputs = defaultdict(list)  # block_id â†’ list of [D_ell] tensors\n",
    "        self.hooks         = []\n",
    "\n",
    "    def _make_hook(self, layer_idx, block_idx):\n",
    "        def hook(module, input, output):\n",
    "            # norm2 input[0]: [B, N_ell, D_ell]\n",
    "            # This is x = shortcut + drop_path(attn_out), i.e. post-attention\n",
    "            # pre-MLP residual stream. In eval mode drop_path is identity.\n",
    "            x_pre_mlp = input[0]                          # [B, N_ell, D_ell]\n",
    "            pooled = x_pre_mlp.mean(dim=1).squeeze(0).detach().cpu()  # [D_ell]\n",
    "            block_id = f\"B{block_idx}_L{layer_idx}\"\n",
    "            self.block_outputs[block_id].append(pooled)\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        global_block = 0\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            for block_idx, block in enumerate(layer.blocks):\n",
    "                h = block.norm2.register_forward_hook(\n",
    "                    self._make_hook(layer_idx, block_idx)\n",
    "                )\n",
    "                self.hooks.append(h)\n",
    "                global_block += 1\n",
    "        print(f\"âœ… Registered {len(self.hooks)} block hooks (on norm2)\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-block lists â†’ dict of tensors [N_samples, D_ell].\"\"\"\n",
    "        return {bid: torch.stack(vecs) for bid, vecs in self.block_outputs.items()}\n",
    "\n",
    "\n",
    "class LayerLevelExtractor:\n",
    "    \"\"\"\n",
    "    Registers one forward hook per stage, placed on the last SwinTransformerBlock\n",
    "    of each BasicLayer. Captures the residual stream after all blocks of the stage\n",
    "    but before PatchMerging, then mean-pools over the token dimension.\n",
    "    Output shape per layer: [D_ell] = [96 * 2^layer_idx]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model         = model\n",
    "        self.layer_outputs = defaultdict(list)  # layer_id â†’ list of [D_ell] tensors\n",
    "        self.hooks         = []\n",
    "\n",
    "    def _make_hook(self, layer_idx):\n",
    "        def hook(module, input, output):\n",
    "            # SwinTransformerBlock returns (x, attn); x: [B, N_ell, D_ell]\n",
    "            x_out, _ = output\n",
    "            # Mean pool over token dimension â†’ [B, D_ell] â†’ squeeze â†’ [D_ell]\n",
    "            pooled = x_out.mean(dim=1).squeeze(0).detach().cpu()\n",
    "            self.layer_outputs[f\"L{layer_idx}\"].append(pooled)\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            # Hook only the LAST block of this stage\n",
    "            last_block = layer.blocks[-1]\n",
    "            h = last_block.register_forward_hook(self._make_hook(layer_idx))\n",
    "            self.hooks.append(h)\n",
    "        print(f\"âœ… Registered {len(self.hooks)} layer hooks (on last block of each stage)\")\n",
    "        for layer_idx, layer in enumerate(self.model.layers):\n",
    "            n = len(layer.blocks)\n",
    "            print(f\"   L{layer_idx}: hooked block {n-1} of {n} (depth={n})\")\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks.clear()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Stack per-layer lists â†’ dict of tensors [N_samples, D_ell].\"\"\"\n",
    "        return {lid: torch.stack(vecs) for lid, vecs in self.layer_outputs.items()}\n",
    "\n",
    "\n",
    "# â”€â”€ Single forward pass for both block and layer extractors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Block hooks  : norm2 input of every SwinTransformerBlock  (pre-MLP)\n",
    "# Layer hooks  : output of last SwinTransformerBlock of each stage (post-MLP,\n",
    "#                pre-PatchMerging)\n",
    "# Both are registered here so only ONE forward pass is needed for both cells.\n",
    "\n",
    "block_extractor = BlockLevelExtractor(audio_encoder)\n",
    "layer_extractor = LayerLevelExtractor(audio_encoder)\n",
    "block_extractor.register_hooks()\n",
    "layer_extractor.register_hooks()\n",
    "\n",
    "for audio_path, _ in tqdm(sample_list, desc=\"Extracting blocks + layers\"):\n",
    "    audio_tensor = wrapper.load_audio_into_tensor(\n",
    "        audio_path, wrapper.args.duration, resample=True\n",
    "    ).reshape(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_encoder(audio_tensor)\n",
    "\n",
    "block_extractor.remove_hooks()\n",
    "layer_extractor.remove_hooks()\n",
    "block_outputs_final = block_extractor.finalize()\n",
    "layer_outputs_final = layer_extractor.finalize()\n",
    "\n",
    "# â”€â”€ Verify blocks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nâœ… Block extraction complete\")\n",
    "print(f\"   Blocks extracted : {len(block_outputs_final)}\")\n",
    "for key, tensor in block_outputs_final.items():\n",
    "    layer_idx = int(key.split(\"_L\")[1])\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    ok = tensor.shape == (N_SAMPLES, expected_dim)\n",
    "    print(f\"   {key}: shape {tuple(tensor.shape)}  (expected D={expected_dim})  {'âœ…' if ok else 'âŒ'}\")\n",
    "    assert tensor.shape[0] == N_SAMPLES, f\"Sample count mismatch for {key}\"\n",
    "    assert tensor.shape[1] == expected_dim, f\"Dim mismatch: got {tensor.shape[1]}, expected {expected_dim}\"\n",
    "assert len(block_outputs_final) == N_BLOCKS\n",
    "print(\"   âœ… All block shapes verified\")\n",
    "\n",
    "# â”€â”€ Verify layers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nâœ… Layer extraction complete\")\n",
    "print(f\"   Layers extracted : {len(layer_outputs_final)}\")\n",
    "for key, tensor in layer_outputs_final.items():\n",
    "    layer_idx = int(key[1])\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    ok = tensor.shape == (N_SAMPLES, expected_dim)\n",
    "    print(f\"   {key}: shape {tuple(tensor.shape)}  (expected D={expected_dim})  {'âœ…' if ok else 'âŒ'}\")\n",
    "    assert tensor.shape[0] == N_SAMPLES, f\"Sample count mismatch for {key}\"\n",
    "    assert tensor.shape[1] == expected_dim, f\"Dim mismatch: got {tensor.shape[1]}, expected {expected_dim}\"\n",
    "assert len(layer_outputs_final) == len(HTSAT_DEPTHS)\n",
    "print(\"   âœ… All layer shapes verified\")\n",
    "\n",
    "# â”€â”€ Save both â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_block_outputs_final.pt\"\n",
    "torch.save({\"block_outputs_final\": block_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved â†’ {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94239907",
   "metadata": {},
   "source": [
    "## Cell 5 â€” Save Per-Layer Representations\n",
    "\n",
    "Both `BlockLevelExtractor` and `LayerLevelExtractor` are defined and run in Cell 4\n",
    "in a single shared forward pass. `layer_outputs_final` is already fully populated\n",
    "by the time this cell executes. This cell only handles the save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e5a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved â†’ heads_representations/esc50_layer_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "# LayerLevelExtractor is defined in Cell 4 alongside BlockLevelExtractor.\n",
    "# Both extractors run in the same forward pass there, so layer_outputs_final\n",
    "# is already fully populated. This cell only handles the save.\n",
    "\n",
    "# â”€â”€ Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "save_path = f\"{SAVE_DIR}/{DATASET.__name__.lower()}_layer_outputs_final.pt\"\n",
    "torch.save({\"layer_outputs_final\": layer_outputs_final, \"labels\": sample_labels}, save_path)\n",
    "print(f\"   Saved â†’ {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd470a31",
   "metadata": {},
   "source": [
    "## Cell 6 â€” Summary & Sanity Checks\n",
    "\n",
    "We verify the following:\n",
    "\n",
    "1. **Shape correctness**: each layer tensor has the expected dimensionality\n",
    "   $D_\\ell = 96 \\cdot 2^\\ell$ ($96, 192, 384, 768$ for $\\ell = 0,1,2,3$).\n",
    "\n",
    "2. **Fisher discriminability**: a quick per-key Fisher score\n",
    "   $F = \\overline{S_B / (S_W + \\varepsilon)}$\n",
    "   confirms that the extracted representations carry class-discriminative information\n",
    "   at all three granularities. Note that layer Fisher scores are not directly comparable\n",
    "   to head/block scores since the feature spaces have different dimensionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d63ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Dataset  : ESC50\n",
      "Samples  : 2000\n",
      "Classes  : 50\n",
      "Device   : cpu\n",
      "\n",
      "Granularity  Keys     Shape per key\n",
      "------------------------------------------\n",
      "Head         184      (2000, 24)\n",
      "Block        12       (2000, 96)\n",
      "Layer        4        (2000, 96)\n",
      "\n",
      "ğŸ” Layer output shape checks:\n",
      "   L0: (2000, 96)  expected (2000, 96)  âœ…\n",
      "   L1: (2000, 192)  expected (2000, 192)  âœ…\n",
      "   L2: (2000, 384)  expected (2000, 384)  âœ…\n",
      "   L3: (2000, 768)  expected (2000, 768)  âœ…\n",
      "\n",
      "ğŸ“Š Quick Fisher discriminability per key:\n",
      "   Note: block/layer scores are not directly comparable to head scores\n",
      "   since they operate in different-dimensional spaces (D_ell vs 24).\n",
      "\n",
      "   Key                         F     dim\n",
      "   --------------------------------------\n",
      "   L0_B0_H0               0.9930      24\n",
      "   L0_B0_H1               0.9033      24\n",
      "   L0_B0_H2               0.8705      24\n",
      "   L0_B0_H3               0.8914      24\n",
      "   L0_B1_H0               0.9052      24\n",
      "   L0_B1_H1               1.1560      24\n",
      "   L0_B1_H2               1.1500      24\n",
      "   L0_B1_H3               0.9860      24\n",
      "   L1_B0_H0               0.5804      24\n",
      "   L1_B0_H1               0.7517      24\n",
      "   L1_B0_H2               0.5546      24\n",
      "   L1_B0_H3               0.6886      24\n",
      "   L1_B0_H4               0.6271      24\n",
      "   L1_B0_H5               0.5698      24\n",
      "   L1_B0_H6               1.0032      24\n",
      "   L1_B0_H7               0.9018      24\n",
      "   L1_B1_H0               0.9333      24\n",
      "   L1_B1_H1               0.6762      24\n",
      "   L1_B1_H2               0.6627      24\n",
      "   L1_B1_H3               0.7459      24\n",
      "   L1_B1_H4               0.6209      24\n",
      "   L1_B1_H5               0.6423      24\n",
      "   L1_B1_H6               0.9421      24\n",
      "   L1_B1_H7               0.7770      24\n",
      "   L2_B0_H0               0.5133      24\n",
      "   L2_B0_H1               0.8768      24\n",
      "   L2_B0_H10              0.7367      24\n",
      "   L2_B0_H11              0.9060      24\n",
      "   L2_B0_H12              0.6247      24\n",
      "   L2_B0_H13              0.7785      24\n",
      "   L2_B0_H14              0.8726      24\n",
      "   L2_B0_H15              0.8694      24\n",
      "   L2_B0_H2               0.7203      24\n",
      "   L2_B0_H3               0.5343      24\n",
      "   L2_B0_H4               0.7308      24\n",
      "   L2_B0_H5               0.9884      24\n",
      "   L2_B0_H6               0.8937      24\n",
      "   L2_B0_H7               0.5970      24\n",
      "   L2_B0_H8               0.5594      24\n",
      "   L2_B0_H9               0.7521      24\n",
      "   L2_B1_H0               0.7314      24\n",
      "   L2_B1_H1               0.5681      24\n",
      "   L2_B1_H10              0.5515      24\n",
      "   L2_B1_H11              0.9485      24\n",
      "   L2_B1_H12              0.5648      24\n",
      "   L2_B1_H13              0.7478      24\n",
      "   L2_B1_H14              1.1337      24\n",
      "   L2_B1_H15              0.9136      24\n",
      "   L2_B1_H2               0.4426      24\n",
      "   L2_B1_H3               0.5207      24\n",
      "   L2_B1_H4               0.4763      24\n",
      "   L2_B1_H5               0.4898      24\n",
      "   L2_B1_H6               0.6127      24\n",
      "   L2_B1_H7               0.6899      24\n",
      "   L2_B1_H8               0.3955      24\n",
      "   L2_B1_H9               0.5860      24\n",
      "   L2_B2_H0               0.5103      24\n",
      "   L2_B2_H1               0.6668      24\n",
      "   L2_B2_H10              0.5561      24\n",
      "   L2_B2_H11              0.4881      24\n",
      "   L2_B2_H12              0.5993      24\n",
      "   L2_B2_H13              0.5294      24\n",
      "   L2_B2_H14              0.7847      24\n",
      "   L2_B2_H15              0.5910      24\n",
      "   L2_B2_H2               0.7138      24\n",
      "   L2_B2_H3               0.4775      24\n",
      "   L2_B2_H4               0.6481      24\n",
      "   L2_B2_H5               0.6847      24\n",
      "   L2_B2_H6               0.5898      24\n",
      "   L2_B2_H7               0.6699      24\n",
      "   L2_B2_H8               0.6346      24\n",
      "   L2_B2_H9               0.5056      24\n",
      "   L2_B3_H0               0.5219      24\n",
      "   L2_B3_H1               0.4481      24\n",
      "   L2_B3_H10              0.5717      24\n",
      "   L2_B3_H11              0.4221      24\n",
      "   L2_B3_H12              0.5250      24\n",
      "   L2_B3_H13              0.4449      24\n",
      "   L2_B3_H14              0.5481      24\n",
      "   L2_B3_H15              0.5104      24\n",
      "   L2_B3_H2               0.4767      24\n",
      "   L2_B3_H3               0.6762      24\n",
      "   L2_B3_H4               0.3831      24\n",
      "   L2_B3_H5               0.5330      24\n",
      "   L2_B3_H6               0.8577      24\n",
      "   L2_B3_H7               0.5345      24\n",
      "   L2_B3_H8               0.4131      24\n",
      "   L2_B3_H9               0.5334      24\n",
      "   L2_B4_H0               0.7719      24\n",
      "   L2_B4_H1               0.6387      24\n",
      "   L2_B4_H10              0.6885      24\n",
      "   L2_B4_H11              0.8162      24\n",
      "   L2_B4_H12              0.4516      24\n",
      "   L2_B4_H13              0.7886      24\n",
      "   L2_B4_H14              1.0134      24\n",
      "   L2_B4_H15              0.6145      24\n",
      "   L2_B4_H2               0.5972      24\n",
      "   L2_B4_H3               0.9975      24\n",
      "   L2_B4_H4               0.5633      24\n",
      "   L2_B4_H5               0.6084      24\n",
      "   L2_B4_H6               0.4466      24\n",
      "   L2_B4_H7               0.3093      24\n",
      "   L2_B4_H8               0.6751      24\n",
      "   L2_B4_H9               0.6962      24\n",
      "   L2_B5_H0               0.4046      24\n",
      "   L2_B5_H1               0.5392      24\n",
      "   L2_B5_H10              0.6040      24\n",
      "   L2_B5_H11              0.9754      24\n",
      "   L2_B5_H12              0.5070      24\n",
      "   L2_B5_H13              0.5701      24\n",
      "   L2_B5_H14              0.3947      24\n",
      "   L2_B5_H15              0.6350      24\n",
      "   L2_B5_H2               0.6094      24\n",
      "   L2_B5_H3               0.7992      24\n",
      "   L2_B5_H4               0.9415      24\n",
      "   L2_B5_H5               1.0291      24\n",
      "   L2_B5_H6               0.8793      24\n",
      "   L2_B5_H7               1.3219      24\n",
      "   L2_B5_H8               0.7429      24\n",
      "   L2_B5_H9               0.7086      24\n",
      "   L3_B0_H0               1.1211      24\n",
      "   L3_B0_H1               1.3768      24\n",
      "   L3_B0_H10              0.7453      24\n",
      "   L3_B0_H11              1.1505      24\n",
      "   L3_B0_H12              0.5691      24\n",
      "   L3_B0_H13              1.2533      24\n",
      "   L3_B0_H14              1.5054      24\n",
      "   L3_B0_H15              1.0817      24\n",
      "   L3_B0_H16              0.7908      24\n",
      "   L3_B0_H17              0.3952      24\n",
      "   L3_B0_H18              1.8204      24\n",
      "   L3_B0_H19              0.6104      24\n",
      "   L3_B0_H2               1.0196      24\n",
      "   L3_B0_H20              0.7109      24\n",
      "   L3_B0_H21              0.4226      24\n",
      "   L3_B0_H22              0.6587      24\n",
      "   L3_B0_H23              0.8932      24\n",
      "   L3_B0_H24              0.4730      24\n",
      "   L3_B0_H25              1.9033      24\n",
      "   L3_B0_H26              1.3324      24\n",
      "   L3_B0_H27              0.7644      24\n",
      "   L3_B0_H28              1.0733      24\n",
      "   L3_B0_H29              0.6923      24\n",
      "   L3_B0_H3               1.1432      24\n",
      "   L3_B0_H30              2.4810      24\n",
      "   L3_B0_H31              1.3988      24\n",
      "   L3_B0_H4               1.0545      24\n",
      "   L3_B0_H5               1.1737      24\n",
      "   L3_B0_H6               1.1834      24\n",
      "   L3_B0_H7               0.6529      24\n",
      "   L3_B0_H8               1.5482      24\n",
      "   L3_B0_H9               1.5788      24\n",
      "   L3_B1_H0               0.6989      24\n",
      "   L3_B1_H1               1.7102      24\n",
      "   L3_B1_H10              0.8073      24\n",
      "   L3_B1_H11              1.2761      24\n",
      "   L3_B1_H12              0.9212      24\n",
      "   L3_B1_H13              1.5357      24\n",
      "   L3_B1_H14              1.1589      24\n",
      "   L3_B1_H15              1.7201      24\n",
      "   L3_B1_H16              2.1807      24\n",
      "   L3_B1_H17              1.3041      24\n",
      "   L3_B1_H18              1.2406      24\n",
      "   L3_B1_H19              2.0832      24\n",
      "   L3_B1_H2               0.6591      24\n",
      "   L3_B1_H20              2.7675      24\n",
      "   L3_B1_H21              1.3970      24\n",
      "   L3_B1_H22              0.4730      24\n",
      "   L3_B1_H23              0.5035      24\n",
      "   L3_B1_H24              1.1718      24\n",
      "   L3_B1_H25              2.4066      24\n",
      "   L3_B1_H26              0.5251      24\n",
      "   L3_B1_H27              1.2476      24\n",
      "   L3_B1_H28              2.0127      24\n",
      "   L3_B1_H29              1.5397      24\n",
      "   L3_B1_H3               1.6106      24\n",
      "   L3_B1_H30              1.1898      24\n",
      "   L3_B1_H31              1.3453      24\n",
      "   L3_B1_H4               1.1894      24\n",
      "   L3_B1_H5               0.8779      24\n",
      "   L3_B1_H6               1.9704      24\n",
      "   L3_B1_H7               0.5775      24\n",
      "   L3_B1_H8               2.5061      24\n",
      "   L3_B1_H9               1.5510      24\n",
      "\n",
      "   B0_L0                  1.1546      96\n",
      "   B0_L1                  0.9831     192\n",
      "   B0_L2                  0.6868     384\n",
      "   B0_L3                  1.1400     768\n",
      "   B1_L0                  1.1849      96\n",
      "   B1_L1                  0.8934     192\n",
      "   B1_L2                  0.6392     384\n",
      "   B1_L3                  1.6012     768\n",
      "   B2_L2                  0.6469     384\n",
      "   B3_L2                  0.6585     384\n",
      "   B4_L2                  0.7364     384\n",
      "   B5_L2                  0.8214     384\n",
      "\n",
      "   L0                     1.1728      96\n",
      "   L1                     0.8396     192\n",
      "   L2                     0.9821     384\n",
      "   L3                     1.7663     768\n",
      "\n",
      "âœ… All files saved in 'heads_representations/':\n",
      "   esc50_head_outputs_final.pt\n",
      "   esc50_block_outputs_final.pt\n",
      "   esc50_layer_outputs_final.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset  : {DATASET.__name__}\")\n",
    "print(f\"Samples  : {N_SAMPLES}\")\n",
    "print(f\"Classes  : {len(dataset.classes)}\")\n",
    "print(f\"Device   : {device}\")\n",
    "\n",
    "print(f\"\\n{'Granularity':<12} {'Keys':<8} {'Shape per key'}\")\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'Head':<12} {len(head_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(head_outputs_final.values())).shape)}\")\n",
    "print(f\"{'Block':<12} {len(block_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(block_outputs_final.values())).shape)}\")\n",
    "print(f\"{'Layer':<12} {len(layer_outputs_final):<8} \"\n",
    "      f\"{tuple(next(iter(layer_outputs_final.values())).shape)}\")\n",
    "\n",
    "# â”€â”€ Shape checks for layer outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ” Layer output shape checks:\")\n",
    "for layer_idx in range(len(HTSAT_DEPTHS)):\n",
    "    key = f\"L{layer_idx}\"\n",
    "    tensor = layer_outputs_final[key]\n",
    "    expected_dim = 96 * (2 ** layer_idx)\n",
    "    ok = tensor.shape == (N_SAMPLES, expected_dim)\n",
    "    print(f\"   {key}: {tuple(tensor.shape)}  expected ({N_SAMPLES}, {expected_dim})  {'âœ…' if ok else 'âŒ'}\")\n",
    "\n",
    "# â”€â”€ Quick Fisher score check across granularities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fisher_score(X, y):\n",
    "    \"\"\"Diagonal Fisher criterion: mean(S_B / (S_W + eps)).\"\"\"\n",
    "    classes   = np.unique(y)\n",
    "    mu_global = X.mean(axis=0)\n",
    "    S_B = np.zeros(X.shape[1])\n",
    "    S_W = np.zeros(X.shape[1])\n",
    "    for c in classes:\n",
    "        Xc   = X[y == c]\n",
    "        mu_c = Xc.mean(axis=0)\n",
    "        S_B += len(Xc) * (mu_c - mu_global) ** 2\n",
    "        S_W += ((Xc - mu_c) ** 2).sum(axis=0)\n",
    "    return float((S_B / (S_W + 1e-8)).mean())\n",
    "\n",
    "print(\"\\nğŸ“Š Quick Fisher discriminability per key:\")\n",
    "print(\"   Note: block/layer scores are not directly comparable to head scores\")\n",
    "print(\"   since they operate in different-dimensional spaces (D_ell vs 24).\\n\")\n",
    "\n",
    "print(f\"   {'Key':<20} {'F':>8}  {'dim':>6}\")\n",
    "print(\"   \" + \"-\" * 38)\n",
    "\n",
    "for hid in sorted(head_outputs_final.keys()):\n",
    "    f = fisher_score(head_outputs_final[hid].numpy(), sample_labels)\n",
    "    dim = head_outputs_final[hid].shape[1]\n",
    "    print(f\"   {hid:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print()\n",
    "for bk in sorted(block_outputs_final.keys()):\n",
    "    f = fisher_score(block_outputs_final[bk].numpy(), sample_labels)\n",
    "    dim = block_outputs_final[bk].shape[1]\n",
    "    print(f\"   {bk:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print()\n",
    "for lk in sorted(layer_outputs_final.keys()):\n",
    "    f = fisher_score(layer_outputs_final[lk].numpy(), sample_labels)\n",
    "    dim = layer_outputs_final[lk].shape[1]\n",
    "    print(f\"   {lk:<20} {f:>8.4f}  {dim:>6}\")\n",
    "\n",
    "print(f\"\\nâœ… All files saved in '{SAVE_DIR}/':\")\n",
    "print(f\"   {DATASET.__name__.lower()}_head_outputs_final.pt\")\n",
    "print(f\"   {DATASET.__name__.lower()}_block_outputs_final.pt\")\n",
    "print(f\"   {DATASET.__name__.lower()}_layer_outputs_final.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResiDual-CLAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
