Additional Submission Details:
REPORT. Your report is the most important evaluation tool for your project. It needs to be clear and concise, but still present in detail what you did and how. It should be structured as follows (section sizes are approximate guidelines):
- Introduction (~1/2 col): To avoid wasting space, please assume that we know the topic of the project and the preliminary knowledge required to understand your project. The introduction should be brief and highlight the MAIN SCIENTIFIC CONTRIBUTION presented in your project (i.e: the idea you implemented that you are proudest of).
- Related Work (~1/2 col):  Here, you should briefly summarise the current state of the art in your field. If someone else already solved the problem, it should be presented here. If not, you should find the scientific work that is closest to your field of interest and briefly present it.
- Method (>= 1 col) : This should be roughly divided in two sections.
	- BASELINES: here you present either (a) your implementation of previous work done by other researchers on the same topic, or (b) a very naive and simple solution that you can take as a starting point for your research. For example, if your project is on image super-resolution, the baselines could be (a) a naive UNet implementation, (b) the current state of the art model for the super-resolution task.
	- CONTRIBUTION: your own scientific contribution to the solution of the problem. Ideally, this should contain your implementation of your own innovative idea that could (and should) improve the results achieved by the baselines.
NOTE on method: This baseline/contribution is not a rigorous subdivision. Depending on the problem, baselines might be difficult to achieve, and could be skipped, or the entire project could consist of an implementation of a strong baseline, if particularly challenging. In any way, this METHOD section should include the explanation of the main thing you did for this project.
- Experiments/Result: (>= 1 col) this is just as important as the method. Your goal is to convince yourself first, and the reader secondly, that your method works, by testing it on carefully designed experiments. You should try to evaluate your method with a KNOWN metric whenever possible. Look at the related works: how did they evaluate their methods? Can you apply the same evaluation procedure? If so, you need to. Always assume that your results might be biased, and fight to prove the validity of your method. Remember: the numbers in your results don’t matter as much as you think. What matters is how fairly and thoroughly you evaluate your method and what knowledge you extracted from the research process.
- Conclusions (optional) (~ 1/2 col): if space allows, here you can discuss your results, presenting the considerations that arose from them. Please avoid filler content (“We can see that our method outperforms the baseline … and more research could be done with larger datasets / larger models …). Only include this if you have meaningful considerations that might impact future research on the topic. Otherwise, keep further considerations for the appendix.

APPENDIX. The report has to be very concise. The appendix is where you should include everything that you did but did not end up in the report. This is a fundamental tool for us to evaluate your project. What brought you to the final method you proposed? Did you try other methods that didn’t work? What didn’t work is just as valuable as what did, as long as you asked yourself why and how. We suggest including a brief summary of every single experiment you ran, including hyperparameter searches, different evaluation procedures, failed ideas. There isn’t a page limit on the appendix, but you should still try to get straight to the point. You can include as many tables, charts and plots as you’d like. Remember your main goal: taking us through the thought process that guided your research, helping us understand how you came to your ideas and conclusions.

CODE. We will read, run and evaluate your code. Please make sure that (a) it is clear which python files / bash scripts should be executed to reproduce your results (b) your environment is perfectly reproducible (either use UV, or include a well-made list of requirements, specifying versions of the core libraries). It is good practice to include a README.md file that explains the structure of your project folder. You can, and should include links to your checkpoints (if you have any worth sharing), and to download the data you used. While code quality is not the main evaluation factor for your project, it is still very much taken into account. We suggest not to structure your whole project into a giant unreadable Jupyter notebook. If you ran multiple experiments, it is good practice to keep track, inside your code, of all the experiments you ran (you could keep a python / bash script for each experiment you ran, or configure the experiments with YAML configuration files using hydra, or keep your hyperparameters in python dictionaries/dataclasses… ). Before submitting, run your code in a new environment and try to look at it with an external point of view: does it clearly convey what you did and how?

THE PROJECT: ResiDual for Audio — Spectral Alignment in CLAP Models
The ResiDual method introduces a spectral decomposition-based technique for enhancing performance in transformer models by reweighting principal components in the residual stream. It reveals that attention heads in vision transformers often specialize in distinct features and that selectively amplifying these task-relevant directions (while suppressing noise) leads to strong performance gains, even in zero-shot settings, without full model fine-tuning.
In this project, you will adapt the ResiDual method to the audio domain, specifically by applying it to CLAP-like (Contrastive Language-Audio Pretraining) models or similar audio-text transformers. The core goal is to explore whether residual specialization also occurs in audio transformers, and whether spectral reweighting of attention head components can boost performance in audio-language alignment tasks, such as audio caption retrieval, audio classification via text prompts (zero-shot), and cross-modal similarity evaluation.
A possible line of attack is the following:
Analyze the residual stream of CLAP’s transformer encoder to identify specialized heads and their low-dimensional structure.
Perform spectral PCA on head outputs and test if a subset of principal components captures task-relevant audio features.
Implement a ResiDual-style spectral reweighting layer to recompose the residual with task-aligned emphasis.
Compare your method with baseline CLAP inference and standard linear projection approaches.
This project calls for a solid understanding of transformer internals (residual stream, attention heads), PCA and spectral methods, and multimodal audio-text models (e.g., CLAP, AudioCLIP).
It’s ideal for students interested in representation analysis, audio ML, or efficient model adaptation.