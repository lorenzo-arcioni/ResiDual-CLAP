\section{Introduction}

Contemporary audio–text encoders excel at capturing multimodal correspondences~\cite{musicaudiolanguage, msclap}, yet the internal residual pathways—and in particular the spectral structure expressed through attention heads—remain comparatively under-analysed and under-utilised. Recent findings further indicate that attention heads give rise to highly low-dimensional residual subspaces~\cite{low-dimensionalresidual2025,residual2024}, suggesting the existence of latent geometric constraints that current audio-domain Transformers do not explicitly exploit. This motivates an investigation into whether analogous structures emerge in audio architectures such as HTS-AT~\cite{htsat} within Microsoft CLAP~\cite{msclap}, and whether spectral selectivity can serve as an effective inductive bias.

In response to these observations, this work introduces \textsc{ResiDual for Audio}, a spectral reweighting framework that applies the residual-subspace methodology to decompose and reweight residual streams in the spectral domain, extending the algebraic foundations of the original \textsc{ResiDual} technique~\cite{residual2024}. The proposed method (i) investigates the attention-head dimensionality within the Swin Transformer~\cite{swin} layers of HTS-AT, revealing a predominantly low-dimensional representation space—especially in the early stages—and (ii) yields measurable improvements in zero-shot classification and retrieval performance, without requiring any modification to the CLAP architecture or fine-tuning of the model.
