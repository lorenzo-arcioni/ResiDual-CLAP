\section{Method}
\label{sec:method}

Our approach consists of two components: (1) a systematic analysis of the
residual stream of CLAP's audio encoder to characterise the behaviour of
individual attention heads, and (2) the design of spectral reweighting
strategies---collectively referred to as \textbf{ResiDual}---that leverage
this characterisation to improve downstream performance. This section
describes the analysis framework; implementation details of the ResiDual
adaptation are deferred to Section~\ref{sec:residual_implementation}. Full
architectural details and notation are collected in
Appendix~\ref{app:architecture}.

% -------------------------------------------------------------
\subsection{Residual Stream Decomposition}
\label{sec:residual_decomp}
% -------------------------------------------------------------

We analyse the HTS-AT audio encoder~\cite{chen2022hts} inside
CLAP~\cite{elizalde2023clap}. HTS-AT is a hierarchical Swin-Transformer
with four stages of block depths $[2,2,6,2]$ and window size $w=8$.
The number of attention heads doubles at each stage, $H_\ell = 4\cdot2^\ell$,
while the per-head dimension $d_h = 24$ stays constant, so the total
embedding dimension $D_\ell = H_\ell \cdot d_h$ also doubles at each
transition. Full stage parameters are given in
Table~\ref{tab:architecture} in Appendix~\ref{app:architecture}.

\paragraph{Within-stage residual structure.}
Inside each stage $\ell$, both the attention and MLP sub-layers write
additively to the residual stream. Following the pre-norm
formulation~\cite{wang2019}, the stream after block $b$ is:
\begin{equation}
    \mathbf{Z}^{(\ell,b)}
    = \mathbf{Z}^{(\ell,0)}
    + \sum_{b'=1}^{b} \mathbf{A}_{\ell,b'}
    + \sum_{b'=1}^{b} \mathbf{M}_{\ell,b'},
    \quad \in \mathbb{R}^{S_\ell^2 \times D_\ell},
    \label{eq:residual_stream}
\end{equation}
where $\mathbf{Z}^{(\ell,0)}$ is the stage input, $\mathbf{A}_{\ell,b}$ is
the W-MSA output, $\mathbf{M}_{\ell,b}$ is the MLP output, and $S_\ell$ is
the spatial side length of the token grid at stage $\ell$.

This decomposition holds strictly \emph{within} a stage, where $D_\ell$ is
constant. Across stage boundaries, PatchMerging changes both spatial
resolution and embedding dimension ($S_\ell \to S_\ell/2$,
$D_\ell \to 2D_\ell$), breaking any global additive structure across the
full network, unlike in isotropic vision transformers~\cite{gandelsman2024}.

\paragraph{Per-head decomposition of the attention output.}
The W-MSA output $\mathbf{A}_{\ell,b}$ can itself be decomposed exactly over
individual attention heads. At block $(\ell, b)$, the raw output of head $h$
is (see Appendix~\ref{app:htsat} for derivation):
\begin{equation}
    \mathbf{H}_{\ell,b,h}
    = \mathrm{Softmax}\!\left(
        \frac{\mathbf{Q}_h\,\mathbf{K}_h^\top}{\sqrt{d_h}}
        + \mathbf{B}_{\ell,b,h}
      \right)\mathbf{V}_h
    \;\in\; \mathbb{R}^{N_w^\ell \times M \times d_h},
    \label{eq:raw_head}
\end{equation}
where $N_w^\ell = S_\ell^2/M$ is the number of attention windows, $M=64$
tokens per window, and $\mathbf{B}_{\ell,b,h} \in \mathbb{R}^{M\times M}$
is the learned relative position bias for head $h$ at block $(\ell,b)$
(shared across windows, independent per head and per block).

All $H_\ell$ head outputs are concatenated and projected through
$W^O_{\ell,b} \in \mathbb{R}^{D_\ell \times D_\ell}$ with bias
$\mathbf{b}^O_{\ell,b} \in \mathbb{R}^{D_\ell}$:
\begin{equation}
    \mathbf{A}_{\ell,b}
    = \bigl[\mathbf{H}_{\ell,b,1} \|\cdots\| \mathbf{H}_{\ell,b,H_\ell}\bigr]
      \,W^O_{\ell,b} + \mathbf{b}^O_{\ell,b}
    \;\in\; \mathbb{R}^{N_w^\ell \cdot M \times D_\ell}.
    \label{eq:wmsa_out}
\end{equation}
Because this operation is linear, we can distribute it over individual
heads. Denoting by $W^O_{\ell,b,h} \in \mathbb{R}^{d_h \times D_\ell}$ the
row slice of $W^O_{\ell,b}$ corresponding to head $h$ (rows
$[(h-1)d_h,\; hd_h)$), and distributing the bias equally, we obtain:
\begin{equation}
    \mathbf{A}_{\ell,b}
    = \sum_{h=1}^{H_\ell}
      \underbrace{%
        \mathbf{H}_{\ell,b,h}\,W^O_{\ell,b,h}
        + \frac{\mathbf{b}^O_{\ell,b}}{H_\ell}
      }_{\displaystyle\widehat{\mathbf{H}}_{\ell,b,h}
        \;\in\;\mathbb{R}^{N_w^\ell \times M \times D_\ell}}.
    \label{eq:head_decomp}
\end{equation}
Each $\widehat{\mathbf{H}}_{\ell,b,h}$ is the \emph{per-head projected
contribution}: it lives in the full residual-stream space $\mathbb{R}^{D_\ell}$
of stage $\ell$ and contributes additively to
$\mathbf{Z}^{(\ell,b)}$ via Eq.~\eqref{eq:residual_stream}. The
decomposition is exact, with no approximation.

\paragraph{Limits of cross-stage analysis.}
A key difference between HTS-AT and isotropic vision transformers such as
ViT~\cite{dosovitskiy2020vit} is that the ambient dimension of the residual
stream is not constant: $D_\ell \in \{96, 192, 384, 768\}$ grows with each
stage. As a consequence, the matrices $\widehat{\mathbf{R}}_{\ell,b,h}$ from
different stages live in spaces of different dimension, and any
dimensionality-reduction analysis---such as PCA---must be interpreted with
care. Specifically, the maximum number of non-trivial principal components
of $\widehat{\mathbf{R}}_{\ell,b,h}$ is bounded by $\min(n, D_\ell)$, so
a head at Stage~3 ($D_3 = 768$) has a strictly larger ambient ceiling than
a head at Stage~0 ($D_0 = 96$). Direct comparison of explained-variance
curves or intrinsic dimensionality estimates across stages is therefore
confounded by this varying ceiling, and must account for it explicitly.
Within a single stage, where $D_\ell$ is fixed, comparisons across blocks
and heads are well-defined and unambiguous.

% -------------------------------------------------------------
\subsection{Spatial Aggregation and Dataset Representations}
\label{sec:aggregation}
% -------------------------------------------------------------

Each per-head contribution $\widehat{\mathbf{H}}_{\ell,b,h}$ is a
three-dimensional tensor indexed by window, token position, and feature
dimension. To obtain a single fixed-size vector per audio sample, we
mean-pool over all windows and token positions:
\begin{equation}
    \widehat{\mathbf{r}}_{\ell,b,h}
    = \frac{1}{N_w^\ell\, M}
      \sum_{i=1}^{N_w^\ell}\sum_{j=1}^{M}
      \widehat{\mathbf{H}}_{\ell,b,h}[i,j,:]
    \;\in\; \mathbb{R}^{D_\ell}.
    \label{eq:aggregation}
\end{equation}
This yields one vector $\widehat{\mathbf{r}}_{\ell,b,h}$ per audio sample,
per head $h$, at every block $(\ell,b)$ of the network. Stacking these
vectors across the $n$ samples in the dataset gives the matrix
\begin{equation}
    \widehat{\mathbf{R}}_{\ell,b,h} \in \mathbb{R}^{n \times D_\ell},
\end{equation}
which is the primary object of our analysis. The total number of such
matrices across the model is $H_{\mathrm{tot}} = 184$ (one per head per
block; see Table~\ref{tab:architecture}).

Since $D_\ell \in \{96, 192, 384, 768\}$ varies across stages, the ambient
dimension of $\widehat{\mathbf{R}}_{\ell,b,h}$ differs between stages.
Cross-stage comparisons of dimensionality metrics must therefore account for
this varying ceiling.

\paragraph{Hook-based extraction.}
To obtain $\widehat{\mathbf{H}}_{\ell,b,h}$ without modifying the model, we
register forward hooks on the \texttt{WindowAttention} module of each block
$(\ell,b)$. The hook intercepts the tensor \texttt{(attn @ v)} immediately
after the per-head attention computation of Eq.~\eqref{eq:raw_head},
yielding the raw outputs $\mathbf{H}_{\ell,b,h}$ of shape
$(N_w^\ell,\, M,\, d_h)$. The projected contribution
$\widehat{\mathbf{H}}_{\ell,b,h}$ is then reconstructed by applying the
corresponding row slice $W^O_{\ell,b,h}$ retrieved from
\texttt{self.proj.weight}, and adding the distributed bias term
$\mathbf{b}^O_{\ell,b}/H_\ell$, as in Eq.~\eqref{eq:head_decomp}.

\paragraph{Dataset sampling.}
We extract representations from three audio classification benchmarks:
\begin{itemize}
    \item \textbf{ESC-50}~\cite{piczak2015dataset}: 50 environmental sound classes, 2{,}000 clips
          (5\,s, 44.1\,kHz).
    \item \textbf{TinySOL}~\cite{romani2018tinysol}: 14 orchestral instrument classes with varied
          articulations, 2{,}071 monophonic samples (1--16\,s, 44.1\,kHz).
    \item \textbf{VocalSound}~\cite{gong2022vocalsound}: 6 non-speech vocal categories, stratified
          subset of 1{,}200 samples.
\end{itemize}
Audio preprocessing follows the CLAP standard pipeline: 64-band log-mel spectrogram ($f_{\min} =
50$\,Hz, $f_{\max} = 8000$\,Hz, FFT window 1024, hop 320), padded or truncated to 7 seconds at
44.1\,kHz.

% -------------------------------------------------------------
\subsection{Intrinsic Dimensionality Analysis}
\label{sec:dimensionality_method}
% -------------------------------------------------------------

To characterize the effective complexity of the projected head representations
$\{\mathbf{r}_{\ell,b,h}^{(i)}\}_{i=1}^{n} \subset \mathbb{R}^{1024}$, we employ a battery of
linear and nonlinear dimensionality estimators.

\subsubsection{Linear Estimators}

\paragraph{PCA-based dimensionality.}
For each head, let $\mathbf{R}_{\ell,b,h} \in \mathbb{R}^{n \times 1024}$ stack all aggregated
representations. We compute the covariance matrix $\mathbf{C}_{\ell,b,h} =
\tfrac{1}{n-1}\mathbf{R}^\top\mathbf{R}$ and obtain ordered eigenvalues $\lambda_1 \geq \lambda_2
\geq \cdots$. Linear intrinsic dimensionality is:
\begin{equation}
    d_{\mathrm{PCA}}(\alpha)
    = \arg\min_{k}\left\{
        \frac{\sum_{i=1}^{k}\lambda_i}{\sum_{i}\lambda_i} \geq \alpha
      \right\},
    \label{eq:pca_dim}
\end{equation}
evaluated at $\alpha \in \{0.90, 0.95, 0.99\}$. We also report the \emph{Explained Variance Ratio}
of the first principal component, $\mathrm{EVR}_1 = \lambda_1 / \sum_i \lambda_i$.

\paragraph{Participation Ratio.}
\begin{equation}
    \mathrm{PR}
    = \frac{\left(\sum_{i}\lambda_i\right)^2}{\sum_{i}\lambda_i^2}.
    \label{eq:pr}
\end{equation}
High PR signals uniform variance distribution; low PR signals dominance of few directions.

\paragraph{Effective Rank.}
\begin{equation}
    \mathrm{EffRank} = \exp\!\left(-\sum_{i} p_i \log p_i\right),
    \quad p_i = \frac{\lambda_i}{\sum_j \lambda_j}.
    \label{eq:effrank}
\end{equation}

\subsubsection{Nonlinear Estimators}

\paragraph{TwoNN.}
\begin{equation}
    d_{\mathrm{TwoNN}}
    = \left(\frac{1}{n}\sum_{i=1}^{n}\log\frac{r_2^{(i)}}{r_1^{(i)}}\right)^{-1},
    \label{eq:twonn}
\end{equation}
where $r_1^{(i)}, r_2^{(i)}$ are Euclidean distances to the first and second nearest neighbours of
$\mathbf{r}_{\ell,b,h}^{(i)}$~\cite{facco2017twonearest}.

\paragraph{MLE.}
\begin{equation}
    \hat{d}_{\mathrm{MLE}}(\mathbf{r})
    = \left(\frac{1}{k-1}\sum_{j=1}^{k-1}\log\frac{r_k(\mathbf{r})}{r_j(\mathbf{r})}\right)^{-1},
    \label{eq:mle}
\end{equation}
averaged over all samples~\cite{levina2005mle}, with $k=20$.

\subsubsection{Linear-Nonlinear Ratio and Block-Level Aggregation}

For block $B$ containing heads $\mathcal{H}_B$:
\begin{equation}
    \bar{m}_B = \frac{1}{|\mathcal{H}_B|}\sum_{h \in \mathcal{H}_B} m_h,
    \label{eq:block_aggregation}
\end{equation}
and the \textbf{Linear-Nonlinear (L/N) Ratio}:
\begin{equation}
    \mathrm{Ratio}_B
    = \frac{\bar{d}_{\mathrm{PCA}_{99}}}{\bar{d}_{\mathrm{TwoNN}}}.
    \label{eq:ln_ratio}
\end{equation}
Values near 1 indicate near-linear manifolds; higher values signal nonlinear curvature beyond what
PCA captures, and serve as a diagnostic for selecting layer targets for spectral reweighting.

% -------------------------------------------------------------
\subsection{Statistical Validation}
\label{sec:statistical_method}
% -------------------------------------------------------------

To validate layer-wise progression and head heterogeneity we perform one-way ANOVA across stages,
followed by post-hoc pairwise comparisons with Bonferroni correction ($\alpha = 0.05$). Monotonic
trends are assessed via Spearman rank correlation and effect sizes via Cohen's $d$. All analyses
use \texttt{scipy.stats} and \texttt{scikit-learn} with random seed 42.

% -------------------------------------------------------------
\subsection{ResiDual Spectral Reweighting}
\label{sec:residual_implementation}
% -------------------------------------------------------------

\textcolor{red}{[TO BE COMPLETED. Will describe: PCA decomposition of selected projected head
outputs; spectral reweighting strategy; integration into the HTS-AT forward pass; training
protocol; hyperparameter selection.]}