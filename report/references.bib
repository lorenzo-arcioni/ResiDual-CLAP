@misc{residual2024,
  doi = {10.48550/ARXIV.2411.00246},
  url = {https://arxiv.org/abs/2411.00246},
  author = {Basile,  Lorenzo and Maiorca,  Valentino and Bortolussi,  Luca and Rodolà,  Emanuele and Locatello,  Francesco},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {ResiDual Transformer Alignment with Spectral Decomposition},
  publisher = {arXiv},
  year = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{low-dimensionalresidual2025,
  doi = {10.48550/ARXIV.2508.16929},
  url = {https://arxiv.org/abs/2508.16929},
  author = {Wang,  Junxuan and Ge,  Xuyang and Shu,  Wentao and He,  Zhengfu and Qiu,  Xipeng},
  keywords = {Machine Learning (cs.LG),  Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Attention Layers Add Into Low-Dimensional Residual Subspaces},
  publisher = {arXiv},
  year = {2025},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{htsat,
  doi = {10.48550/ARXIV.2202.00874},
  url = {https://arxiv.org/abs/2202.00874},
  author = {Chen,  Ke and Du,  Xingjian and Zhu,  Bilei and Ma,  Zejun and Berg-Kirkpatrick,  Taylor and Dubnov,  Shlomo},
  keywords = {Sound (cs.SD),  Artificial Intelligence (cs.AI),  Information Retrieval (cs.IR),  Machine Learning (cs.LG),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound Classification and Detection},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{msclap,
  doi = {10.48550/ARXIV.2206.04769},
  url = {https://arxiv.org/abs/2206.04769},
  author = {Elizalde,  Benjamin and Deshmukh,  Soham and Ismail,  Mahmoud Al and Wang,  Huaming},
  keywords = {Sound (cs.SD),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {CLAP: Learning Audio Concepts From Natural Language Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{musicaudiolanguage,
  doi = {10.48550/ARXIV.2208.12208},
  url = {https://arxiv.org/abs/2208.12208},
  author = {Manco,  Ilaria and Benetos,  Emmanouil and Quinton,  Elio and Fazekas,  Gy\"{o}rgy},
  keywords = {Sound (cs.SD),  Computation and Language (cs.CL),  Machine Learning (cs.LG),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Contrastive Audio-Language Learning for Music},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{swin,
  doi = {10.48550/ARXIV.2103.14030},
  url = {https://arxiv.org/abs/2103.14030},
  author = {Liu,  Ze and Lin,  Yutong and Cao,  Yue and Hu,  Han and Wei,  Yixuan and Zhang,  Zheng and Lin,  Stephen and Guo,  Baining},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{spectralfilters,
  doi = {10.48550/ARXIV.2402.09221},
  url = {https://arxiv.org/abs/2402.09221},
  author = {Cancedda,  Nicola},
  keywords = {Artificial Intelligence (cs.AI),  Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Spectral Filters,  Dark Signals,  and Attention Sinks},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{Voita2019,
  title = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting,  the Rest Can Be Pruned},
  url = {http://dx.doi.org/10.18653/v1/P19-1580},
  DOI = {10.18653/v1/p19-1580},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  author = {Voita,  Elena and Talbot,  David and Moiseev,  Fedor and Sennrich,  Rico and Titov,  Ivan},
  year = {2019},
  pages = {5797–5808}
}

@article{jain2021attention,
  title={Attention Is Not All You Need: Pure Attention Loses Rank Doubly Exponentially With Depth},
  author={Jain, Arnav and Wallace, Byron},
  journal={arXiv preprint arXiv:2103.14030},
  year={2021}
}

@misc{radford2021clip,
  doi = {10.48550/ARXIV.2103.00020},
  url = {https://arxiv.org/abs/2103.00020},
  author = {Radford,  Alec and Kim,  Jong Wook and Hallacy,  Chris and Ramesh,  Aditya and Goh,  Gabriel and Agarwal,  Sandhini and Sastry,  Girish and Askell,  Amanda and Mishkin,  Pamela and Clark,  Jack and Krueger,  Gretchen and Sutskever,  Ilya},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{gong2021ast,
  doi = {10.48550/ARXIV.2104.01778},
  url = {https://arxiv.org/abs/2104.01778},
  author = {Gong,  Yuan and Chung,  Yu-An and Glass,  James},
  keywords = {Sound (cs.SD),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {AST: Audio Spectrogram Transformer},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{audioembeddings,
  doi = {10.48550/ARXIV.2504.14076},
  url = {https://arxiv.org/abs/2504.14076},
  author = {Zhang,  Alice and Thomaz,  Edison and Lu,  Lie},
  keywords = {Sound (cs.SD),  Machine Learning (cs.LG),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Transformation of audio embeddings into interpretable,  concept-based representations},
  publisher = {arXiv},
  year = {2025},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@misc{attention-vision,
  doi = {10.48550/ARXIV.2303.13731},
  url = {https://arxiv.org/abs/2303.13731},
  author = {Li,  Yiran and Wang,  Junpeng and Dai,  Xin and Wang,  Liang and Yeh,  Chin-Chia Michael and Zheng,  Yan and Zhang,  Wei and Ma,  Kwan-Liu},
  keywords = {Machine Learning (cs.LG),  Computer Vision and Pattern Recognition (cs.CV),  Human-Computer Interaction (cs.HC),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {How Does Attention Work in Vision Transformers? A Visual Analytics Attempt},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{understandingselfattention,
  doi = {10.48550/ARXIV.2006.03265},
  url = {https://arxiv.org/abs/2006.03265},
  author = {Yang,  Shu-wen and Liu,  Andy T. and Lee,  Hung-yi},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Understanding Self-Attention of Self-Supervised Audio Transformers},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{studyofattention,
  doi = {10.48550/ARXIV.2006.05174},
  url = {https://arxiv.org/abs/2006.05174},
  author = {Wu,  Tsung-Han and Hsieh,  Chun-Chen and Chen,  Yen-Hao and Chi,  Po-Han and Lee,  Hung-yi},
  keywords = {Audio and Speech Processing (eess.AS),  Computation and Language (cs.CL),  Sound (cs.SD),  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Input-independent Attention Weights Are Expressive Enough: A Study of Attention in Self-supervised Audio Transformers},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{musicattention,
  doi = {10.48550/ARXIV.1906.04972},
  url = {https://arxiv.org/abs/1906.04972},
  author = {Won,  Minz and Chun,  Sanghyuk and Serra,  Xavier},
  keywords = {Sound (cs.SD),  Audio and Speech Processing (eess.AS),  FOS: Computer and information sciences,  FOS: Computer and information sciences,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering},
  title = {Toward Interpretable Music Tagging with Self-Attention},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{hua2021whitening,
  doi = {10.48550/ARXIV.2105.00470},
  url = {https://arxiv.org/abs/2105.00470},
  author = {Hua,  Tianyu and Wang,  Wenxiao and Xue,  Zihui and Ren,  Sucheng and Wang,  Yue and Zhao,  Hang},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Computer Vision and Pattern Recognition (cs.CV),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {On Feature Decorrelation in Self-Supervised Learning},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{allbutthetop,
  doi = {10.48550/ARXIV.1702.01417},
  url = {https://arxiv.org/abs/1702.01417},
  author = {Mu,  Jiaqi and Bhat,  Suma and Viswanath,  Pramod},
  keywords = {Computation and Language (cs.CL),  Machine Learning (stat.ML),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {All-but-the-Top: Simple and Effective Postprocessing for Word Representations},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{simpleeffective,
  doi = {10.48550/ARXIV.1708.03629},
  url = {https://arxiv.org/abs/1708.03629},
  author = {Raunak,  Vikas},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Simple and Effective Dimensionality Reduction for Word Embeddings},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@inproceedings{piczak2015dataset,
  title = {{ESC}: {Dataset} for {Environmental Sound Classification}},
  author = {Piczak, Karol J.},
  booktitle = {Proceedings of the 23rd {Annual ACM Conference} on {Multimedia}},
  date = {2015-10-13},
  url = {http://dl.acm.org/citation.cfm?doid=2733373.2806390},
  doi = {10.1145/2733373.2806390},
  location = {{Brisbane, Australia}},
  isbn = {978-1-4503-3459-4},
  publisher = {{ACM Press}},
  pages = {1015--1018}
}

@misc{tinysol,
  doi = {10.5281/ZENODO.3632192},
  url = {https://zenodo.org/record/3632192},
  author = {Emanuele,  Carmine and Ghisi,  Daniele and Lostanlen,  Vincent and Lévy,  Fabien and Fineberg,  Joshua and Maresz,  Yan},
  keywords = {music information retrieval,  computer music,  audio signal processing,  music cognition},
  title = {TinySOL: an audio dataset of isolated musical notes},
  publisher = {Zenodo},
  year = {2020},
  copyright = {Creative Commons Attribution 4.0 International}
}